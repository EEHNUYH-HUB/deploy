{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1b8e66",
   "metadata": {},
   "source": [
    "# 도구를 활용한 토론 에이전트(Agent Debates with Tools)\n",
    "\n",
    "이 예제는 에이전트가 도구에 접근할 수 있는 다중 에이전트 대화를 시뮬레이션하는 방법을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8633d",
   "metadata": {},
   "source": [
    "LangSmith 추적을 위하여 초기화 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f128b9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc40f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH15-Debate-Agent\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "# from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "# logging.langsmith(\"CH15-Debate-Agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c0f422",
   "metadata": {},
   "source": [
    "## `DialogueAgent` 및 `DialogueSimulator`\n",
    "\n",
    "이 노트북에서는 권한이 있는 에이전트가 발언할 사람을 결정하는 다중 에이전트 시뮬레이션을 구현하는 방법을 보여드립니다. 이는 다중 에이전트 분산형 화자 선택과 정반대의 선택 방식을 따릅니다.\n",
    "\n",
    "[Multi-Player Authoritarian Speaker Selection](https://python.langchain.com/en/latest/use_cases/agent_simulations/multiagent_authoritarian.html)에서 정의된 것과 동일한 `DialogueAgent`와 `DialogueSimulator` 클래스를 사용할 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d248d22",
   "metadata": {},
   "source": [
    "## `DialogueAgent`\n",
    "\n",
    "- `send` 메서드는 현재까지의 대화 기록과 에이전트의 접두사를 사용하여 채팅 모델에 메시지를 전달하고 응답을 반환합니다.\n",
    "- `receive` 메서드는 다른 에이전트가 보낸 메시지를 대화 기록에 추가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2090042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        # 에이전트의 이름을 설정합니다.\n",
    "        self.name = name\n",
    "        # 시스템 메시지를 설정합니다.\n",
    "        self.system_message = system_message\n",
    "        # LLM 모델을 설정합니다.\n",
    "        self.model = model\n",
    "        # 에이전트 이름을 지정합니다.\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        # 에이전트를 초기화합니다.\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        대화 내역을 초기화합니다.\n",
    "        \"\"\"\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        메시지에 시스템 메시지 + 대화내용과 마지막으로 에이전트의 이름을 추가합니다.\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join([self.prefix] + self.message_history)),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        name 이 말한 message 를 메시지 내역에 추가합니다.\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a058b5",
   "metadata": {},
   "source": [
    "## `DialogueSimulator`\n",
    "\n",
    "- `inject` 메서드는 주어진 이름(`name`)과 메시지(`message`)로 대화를 시작하고, 모든 에이전트가 해당 메시지를 받도록 합니다.\n",
    "- `step` 메서드는 다음 발언자를 선택하고, 해당 발언자가 메시지를 보내면 모든 에이전트가 메시지를 받도록 합니다. 그리고 현재 단계를 증가시킵니다.\n",
    "\n",
    "여러 에이전트 간의 대화를 시뮬레이션하는 기능을 제공합니다.\n",
    "\n",
    "`DialogueAgent`는 개별 에이전트를 나타내며, `DialogueSimulator`는 에이전트들 간의 대화를 조정하고 관리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560a69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        # 에이전트 목록을 설정합니다.\n",
    "        self.agents = agents\n",
    "        # 시뮬레이션 단계를 초기화합니다.\n",
    "        self._step = 0\n",
    "        # 다음 발언자를 선택하는 함수를 설정합니다.\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        # 모든 에이전트를 초기화합니다.\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        name 의 message 로 대화를 시작합니다.\n",
    "        \"\"\"\n",
    "        # 모든 에이전트가 메시지를 받습니다.\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # 시뮬레이션 단계를 증가시킵니다.\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. 다음 발언자를 선택합니다.\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. 다음 발언자에게 메시지를 전송합니다.\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. 모든 에이전트가 메시지를 받습니다.\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. 시뮬레이션 단계를 증가시킵니다.\n",
    "        self._step += 1\n",
    "\n",
    "        # 발언자의 이름과 메시지를 반환합니다.\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb63b506",
   "metadata": {},
   "source": [
    "## `DialogueAgentWithTools`\n",
    "\n",
    "`DialogueAgent`를 확장하여 도구를 사용할 수 있도록 `DialogueAgentWithTools` 클래스를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287f7c61",
   "metadata": {},
   "source": [
    "- `DialogueAgentWithTools` 클래스는 `DialogueAgent` 클래스를 상속받아 구현되었습니다.\n",
    "- `send` 메서드는 에이전트가 메시지를 생성하고 반환하는 역할을 합니다.\n",
    "- `create_openai_tools_agent` 함수를 사용하여 에이전트 체인을 초기화합니다.\n",
    "  - 초기화시 에이전트가 사용할 도구(tools) 를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb5bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "class DialogueAgentWithTools(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "        tools,\n",
    "    ) -> None:\n",
    "        # 부모 클래스의 생성자를 호출합니다.\n",
    "        super().__init__(name, system_message, model)\n",
    "        # 주어진 도구 이름과 인자를 사용하여 도구를 로드합니다.\n",
    "        self.tools = tools\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        메시지 기록에 챗 모델을 적용하고 메시지 문자열을 반환합니다.\n",
    "        \"\"\"\n",
    "        prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "        agent = create_openai_tools_agent(self.model, self.tools, prompt)\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=self.tools, verbose=False)\n",
    "        # AI 메시지를 생성합니다.\n",
    "        message = AIMessage(\n",
    "            content=agent_executor.invoke(\n",
    "                {\n",
    "                    \"input\": \"\\n\".join(\n",
    "                        [self.system_message.content]\n",
    "                        + [self.prefix]\n",
    "                        + self.message_history\n",
    "                    )\n",
    "                }\n",
    "            )[\"output\"]\n",
    "        )\n",
    "\n",
    "        # 생성된 메시지의 내용을 반환합니다.\n",
    "        return message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d34a5",
   "metadata": {},
   "source": [
    "## 도구 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e172418c",
   "metadata": {},
   "source": [
    "### 문서 검색 도구(Retrieval Tool)를 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464e2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, AzureOpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader1 = TextLoader(\"data/의대증원반대.txt\")\n",
    "loader2 = TextLoader(\"data/의대증원찬성.txt\")\n",
    "\n",
    "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# 문서를 로드하고 분할합니다.\n",
    "docs1 = loader1.load_and_split(text_splitter)\n",
    "docs2 = loader2.load_and_split(text_splitter)\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME'), # 사용할 Azure 배포 모델을 설정합니다.\n",
    "    openai_api_version=os.getenv('AZURE_OPENAI_API_VERSION'), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint =os.getenv('AZURE_OPENAI_ENDPOINT') # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    ")\n",
    "\n",
    "# VectorStore를 생성합니다.\n",
    "vector1 = FAISS.from_documents(docs1, embedding)\n",
    "vector2 = FAISS.from_documents(docs2, embedding)\n",
    "\n",
    "# Retriever를 생성합니다.\n",
    "doctor_retriever = vector1.as_retriever(search_kwargs={\"k\": 5})\n",
    "gov_retriever = vector2.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344fdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성하는 함수를 가져옵니다.\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "doctor_retriever_tool = create_retriever_tool(\n",
    "    doctor_retriever,\n",
    "    name=\"document_search\",\n",
    "    description=\"This is a document about the Korean Medical Association's opposition to the expansion of university medical schools. \"\n",
    "    \"Refer to this document when you want to present a rebuttal to the proponents of medical school expansion.\",\n",
    ")\n",
    "\n",
    "gov_retriever_tool = create_retriever_tool(\n",
    "    gov_retriever,\n",
    "    name=\"document_search\",\n",
    "    description=\"This is a document about the Korean government's support for the expansion of university medical schools. \"\n",
    "    \"Refer to this document when you want to provide a rebuttal to the opposition to medical school expansion.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128177d0",
   "metadata": {},
   "source": [
    "### 인터넷 검색 도구\n",
    "\n",
    "인터넷에서 검색할 수 있는 도구를 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816da2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
    "# k=6은 검색 결과를 6개까지 가져오겠다는 의미입니다\n",
    "search = TavilySearchResults(k=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e734047d",
   "metadata": {},
   "source": [
    "## 각 에이전트가 활용할 수 있는 도구를 설정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823ad2e",
   "metadata": {},
   "source": [
    "- `names` 딕셔너리는 토론자의 이름(prefix name) 과 각각의 토론 에이전트가 활용할 수 있는 도구를 정의합니다.\n",
    "- `topic` 토론의 주제를 선정합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d44b7a",
   "metadata": {},
   "source": [
    "### ① 문서에 기반한 도구\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5f896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"Doctor Union(의사협회)\": [doctor_retriever_tool],  # 의사협회 에이전트 도구 목록\n",
    "    \"Government(대한민국 정부)\": [gov_retriever_tool],  # 정부 에이전트 도구 목록\n",
    "}\n",
    "\n",
    "# 토론 주제 선정\n",
    "topic = \"2024 현재, 대한민국 대학교 의대 정원 확대 충원은 필요한가?\"\n",
    "\n",
    "# 토론자를 설명하는 문구의 단어 제한\n",
    "word_limit = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d550e",
   "metadata": {},
   "source": [
    "### ② 검색(Search) 기반 도구\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad1ae1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_search = {\n",
    "    \"Doctor Union(의사협회)\": [search],  # 의사협회 에이전트 도구 목록\n",
    "    \"Government(대한민국 정부)\": [search],  # 정부 에이전트 도구 목록\n",
    "}\n",
    "# 토론 주제 선정\n",
    "topic = \"2024년 현재, 대한민국 대학교 의대 정원 확대 충원은 필요한가?\"\n",
    "word_limit = 50  # 작업 브레인스토밍을 위한 단어 제한"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880994c6",
   "metadata": {},
   "source": [
    "## LLM을 활용하여 주제 설명에 세부 내용 추가하기\n",
    "\n",
    "LLM(Large Language Model)을 사용하여 주어진 주제에 대한 설명을 보다 상세하게 만들 수 있습니다.\n",
    "\n",
    "이를 위해서는 먼저 주제에 대한 간단한 설명이나 개요를 LLM에 입력으로 제공합니다. 그런 다음 LLM에게 해당 주제에 대해 더 자세히 설명해줄 것을 요청합니다.\n",
    "\n",
    "LLM은 방대한 양의 텍스트 데이터를 학습했기 때문에, 주어진 주제와 관련된 추가적인 정보와 세부 사항을 생성해낼 수 있습니다. 이를 통해 초기의 간단한 설명을 보다 풍부하고 상세한 내용으로 확장할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f655d4e",
   "metadata": {},
   "source": [
    "- 주어진 대화 주제(topic)와 참가자(names)를 기반으로 대화에 대한 설명(`conversation_description`)을 생성합니다.\n",
    "- `agent_descriptor_system_message` 는 대화 참가자에 대한 설명을 추가할 수 있다는 내용의 SystemMessage입니다.\n",
    "- `generate_agent_description` 함수는 각 참가자(name)에 대하여 LLM 이 생성한 설명을 생성합니다.\n",
    "  - `agent_specifier_prompt` 는 대화 설명과 참가자 이름, 단어 제한(`word_limit`)을 포함하는 HumanMessage로 구성됩니다.\n",
    "  - ChatOpenAI 모델을 사용하여 `agent_specifier_prompt` 를 기반으로 참가자에 대한 설명(agent_description)을 생성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b70f82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhkim\\AppData\\Local\\Temp\\ipykernel_30200\\2024543050.py:34: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent_description = llm(agent_specifier_prompt).content\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Doctor Union(의사협회)': '의사협회는 의료 현장의 전문성과 환자 안전을 최우선으로 고려하며, 무분별한 의대 정원 확대가 의료 질 저하와 의료인력 과잉 공급 문제를 초래할 수 있음을 우려합니다. 신중한 접근과 체계적 인력 수급 계획이 필요합니다.',\n",
       " 'Government(대한민국 정부)': '대한민국 정부는 국민 건강 증진과 의료 접근성 강화를 위해 의대 정원 확대를 신중히 검토해야 합니다. 의료 인력 부족 문제를 해결하되, 교육 질 저하와 의료 서비스 균형 발전을 고려하여 체계적이고 지속 가능한 정책을 추진해야 합니다.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "\n",
    "conversation_description = f\"\"\"Here is the topic of conversation: {topic}\n",
    "The participants are: {', '.join(names.keys())}\"\"\"\n",
    "\n",
    "agent_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of the conversation participant.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_agent_description(name):\n",
    "    agent_specifier_prompt = [\n",
    "        agent_descriptor_system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"{conversation_description}\n",
    "            Please reply with a description of {name}, in {word_limit} words or less in expert tone. \n",
    "            Speak directly to {name}.\n",
    "            Give them a point of view.\n",
    "            Do not add anything else. Answer in KOREAN.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    "    # ChatOpenAI를 사용하여 에이전트 설명을 생성합니다.\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "        api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "        model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "        # streaming=False, # 스트리밍\n",
    "        temperature=0,\n",
    "        # max_tokens=4096,\n",
    "    )\n",
    "\n",
    "    agent_description = llm(agent_specifier_prompt).content\n",
    "    return agent_description\n",
    "\n",
    "\n",
    "# 각 참가자의 이름에 대한 에이전트 설명을 생성합니다.\n",
    "agent_descriptions = {name: generate_agent_description(name) for name in names}\n",
    "\n",
    "# 생성한 에이전트 설명을 출력합니다.\n",
    "agent_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6317b4",
   "metadata": {},
   "source": [
    "직접 각 토론자의 간략한 입장에 대하여 설명하는 문구를 작성할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cfc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_descriptions = {\n",
    "    \"Doctor Union(의사협회)\": \"의사협회는 의료계의 권익을 보호하고 의사들의 이해관계를 대변하는 기관입니다. 의사들의 업무 환경과 안전을 중시하며, 환자 안전과 질 높은 의료 서비스를 제공하기 위해 노력합니다. \"\n",
    "    \"지금도 의사의 수는 충분하다는 입장이며, 의대 증원은 필수 의료나 지방 의료 활성화에 대한 실효성이 떨어집니다. 의대 증원을 감행할 경우, 의료 교육 현장의 인프라가 갑작스러운 증원을 감당하지 못할 것이란 우려를 표합니다.\",\n",
    "    \"Government(대한민국 정부)\": \"대한민국 정부는 국가의 행정을 책임지는 주체로서, 국민의 복지와 발전을 책임져야 합니다. \"\n",
    "    \"우리나라는 의사수가 절대 부족한 상황이며, 노인인구가 늘어나면서 의료 수요가 급증하고 있습니다. OECD 국가들도 최근 의사수를 늘렸습니다. 또한, 증원된 의사 인력이 필수의료와 지역 의료로 갈 수있도록 튼튼한 의료사고 안정망 구축 및 보상 체계의 공정성을 높이고자 합니다.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474a9cc",
   "metadata": {},
   "source": [
    "## 전역 System Message 설정\n",
    "\n",
    "System message는 대화형 AI 시스템에서 사용자의 입력에 앞서 시스템이 생성하는 메시지입니다.\n",
    "\n",
    "이러한 메시지는 대화의 맥락을 설정하고, 사용자에게 각 에이전트의 **입장과 목적** 을 알려주는 역할을 합니다.\n",
    "\n",
    "효과적인 system message를 작성하면 사용자와의 상호작용을 원활하게 하고, 대화의 질을 높일 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16e28d",
   "metadata": {},
   "source": [
    "**프롬프트 설명**\n",
    "\n",
    "- 에이전트의 이름과 설명을 알립니다.\n",
    "- 에이전트는 도구를 사용하여 정보를 찾고 대화 상대방의 주장을 반박해야 합니다.\n",
    "- 에이전트는 출처를 인용해야 하며, 가짜 인용을 하거나 찾아보지 않은 출처를 인용해서는 안 됩니다.\n",
    "- 에이전트는 자신의 관점에서 말을 마치는 즉시 대화를 중단해야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b6bc285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_system_message(name, description, tools):\n",
    "    return f\"\"\"{conversation_description}\n",
    "    \n",
    "Your name is {name}.\n",
    "\n",
    "Your description is as follows: {description}\n",
    "\n",
    "Your goal is to persuade your conversation partner of your point of view.\n",
    "\n",
    "DO look up information with your tool to refute your partner's claims.\n",
    "DO cite your sources.\n",
    "\n",
    "DO NOT fabricate fake citations.\n",
    "DO NOT cite any source that you did not look up.\n",
    "\n",
    "DO NOT restate something that has already been said in the past.\n",
    "DO NOT add anything else.\n",
    "\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\n",
    "Answer in KOREAN.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent_system_messages = {\n",
    "    name: generate_system_message(name, description, tools)\n",
    "    for (name, tools), description in zip(names.items(), agent_descriptions.values())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f8fed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doctor Union(의사협회)\n",
      "Here is the topic of conversation: 2024년 현재, 대한민국 대학교 의대 정원 확대 충원은 필요한가?\n",
      "The participants are: Doctor Union(의사협회), Government(대한민국 정부)\n",
      "    \n",
      "Your name is Doctor Union(의사협회).\n",
      "\n",
      "Your description is as follows: 의사협회는 의료계의 권익을 보호하고 의사들의 이해관계를 대변하는 기관입니다. 의사들의 업무 환경과 안전을 중시하며, 환자 안전과 질 높은 의료 서비스를 제공하기 위해 노력합니다. 지금도 의사의 수는 충분하다는 입장이며, 의대 증원은 필수 의료나 지방 의료 활성화에 대한 실효성이 떨어집니다. 의대 증원을 감행할 경우, 의료 교육 현장의 인프라가 갑작스러운 증원을 감당하지 못할 것이란 우려를 표합니다.\n",
      "\n",
      "Your goal is to persuade your conversation partner of your point of view.\n",
      "\n",
      "DO look up information with your tool to refute your partner's claims.\n",
      "DO cite your sources.\n",
      "\n",
      "DO NOT fabricate fake citations.\n",
      "DO NOT cite any source that you did not look up.\n",
      "\n",
      "DO NOT restate something that has already been said in the past.\n",
      "DO NOT add anything else.\n",
      "\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "\n",
      "Answer in KOREAN.\n",
      "\n",
      "Government(대한민국 정부)\n",
      "Here is the topic of conversation: 2024년 현재, 대한민국 대학교 의대 정원 확대 충원은 필요한가?\n",
      "The participants are: Doctor Union(의사협회), Government(대한민국 정부)\n",
      "    \n",
      "Your name is Government(대한민국 정부).\n",
      "\n",
      "Your description is as follows: 대한민국 정부는 국가의 행정을 책임지는 주체로서, 국민의 복지와 발전을 책임져야 합니다. 우리나라는 의사수가 절대 부족한 상황이며, 노인인구가 늘어나면서 의료 수요가 급증하고 있습니다. OECD 국가들도 최근 의사수를 늘렸습니다. 또한, 증원된 의사 인력이 필수의료와 지역 의료로 갈 수있도록 튼튼한 의료사고 안정망 구축 및 보상 체계의 공정성을 높이고자 합니다.\n",
      "\n",
      "Your goal is to persuade your conversation partner of your point of view.\n",
      "\n",
      "DO look up information with your tool to refute your partner's claims.\n",
      "DO cite your sources.\n",
      "\n",
      "DO NOT fabricate fake citations.\n",
      "DO NOT cite any source that you did not look up.\n",
      "\n",
      "DO NOT restate something that has already been said in the past.\n",
      "DO NOT add anything else.\n",
      "\n",
      "Stop speaking the moment you finish speaking from your perspective.\n",
      "\n",
      "Answer in KOREAN.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 에이전트 시스템 메시지를 순회합니다.\n",
    "for name, system_message in agent_system_messages.items():\n",
    "    # 에이전트의 이름을 출력합니다.\n",
    "    print(name)\n",
    "    # 에이전트의 시스템 메시지를 출력합니다.\n",
    "    print(system_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073390d8",
   "metadata": {},
   "source": [
    "`topic_specifier_prompt`를 정의하여 주어진 주제를 더 구체화하는 프롬프트를 생성합니다.\n",
    "\n",
    "- `temperature` 를 조절하여 더 다양한 주제를 생성할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ea39a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original topic:\n",
      "2024년 현재, 대한민국 대학교 의대 정원 확대 충원은 필요한가?\n",
      "\n",
      "Detailed topic:\n",
      "의사협회와 대한민국 정부에 묻습니다. 2024년 현재, 대한민국의 의료 인력 부족 문제를 해결하기 위해 의과대학 정원 확대가 실제로 필요한지, 그리고 확대 시 지역별 의료 불균형 해소와 의료 서비스 질 향상에 어떤 구체적 효과가 있을지 논의해 주시기 바랍니다. 또한, 정원 확대가 의료계의 직업 환경과 국민 건강에 미칠 장기적 영향에 대해 양측의 입장을 명확히 밝혀 주십시오.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_specifier_prompt = [\n",
    "    # 주제를 더 구체적으로 만들 수 있습니다.\n",
    "    SystemMessage(content=\"You can make a topic more specific.\"),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"{topic}\n",
    "        \n",
    "        You are the moderator. \n",
    "        Please make the topic more specific.\n",
    "        Please reply with the specified quest in 100 words or less.\n",
    "        Speak directly to the participants: {*names,}.  \n",
    "        Do not add anything else.\n",
    "        Answer in Korean.\"\"\"  # 다른 것은 추가하지 마세요.\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "    model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "    # streaming=False, # 스트리밍\n",
    "    temperature=0,\n",
    "    # max_tokens=4096,\n",
    ")\n",
    "\n",
    "# 구체화된 주제를 생성합니다.\n",
    "specified_topic = llm(topic_specifier_prompt).content\n",
    "\n",
    "print(f\"Original topic:\\n{topic}\\n\")  # 원래 주제를 출력합니다.\n",
    "print(f\"Detailed topic:\\n{specified_topic}\\n\")  # 구체화된 주제를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fab2a1",
   "metadata": {},
   "source": [
    "혹은 아래와 같이 직접 지정할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ba31217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 세부 주제 설정\n",
    "specified_topic = \"정부는 2025년 입시부터 의대 입학정원을 2000명 늘린다고 발표했습니다. 이에 의사단체는 전국에서 규탄집회를 열어 반발하고 있습니다. 의대 정원 확대를 둘러싼 논란 쟁점을 짚어보고, 필수 의료와 지역 의료 해법에 대해서 토론해주세요.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01071f75",
   "metadata": {},
   "source": [
    "## 토론 Loop\n",
    "\n",
    "토론 루프는 프로그램의 핵심 실행 부분으로, 주요 작업이 반복적으로 수행되는 곳입니다.\n",
    "\n",
    "- 여기서 주요 작업은 각 에이전트의 메시지 청취 -> 도구를 활용하여 근거 탐색 -> 반박 의견 제시 등을 포함합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00c5396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.DialogueAgentWithTools at 0x26b52435e20>,\n",
       " <__main__.DialogueAgentWithTools at 0x26bbf6679b0>,\n",
       " <__main__.DialogueAgentWithTools at 0x26bbf2aaba0>,\n",
       " <__main__.DialogueAgentWithTools at 0x26bbf669610>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이는 결과가 컨텍스트 제한을 초과하는 것을 방지하기 위함입니다.\n",
    "agents = [\n",
    "    DialogueAgentWithTools(\n",
    "        name=name,\n",
    "        system_message=SystemMessage(content=system_message),\n",
    "        model=llm,\n",
    "        tools=tools,\n",
    "    )\n",
    "    for (name, tools), system_message in zip(\n",
    "        names.items(), agent_system_messages.values()\n",
    "    )\n",
    "]\n",
    "\n",
    "agents_with_search = [\n",
    "    DialogueAgentWithTools(\n",
    "        name=name,\n",
    "        system_message=SystemMessage(content=system_message),\n",
    "        model=llm,\n",
    "        tools=tools,\n",
    "    )\n",
    "    for (name, tools), system_message in zip(\n",
    "        names_search.items(), agent_system_messages.values()\n",
    "    )\n",
    "]\n",
    "\n",
    "agents.extend(agents_with_search)\n",
    "agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26385550",
   "metadata": {},
   "source": [
    "`select_next_speaker` 함수는 다음 발언자를 선택하는 역할을 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f79892bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    # 다음 발언자를 선택합니다.\n",
    "    # step을 에이전트 수로 나눈 나머지를 인덱스로 사용하여 다음 발언자를 순환적으로 선택합니다.\n",
    "    idx = (step) % len(agents)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532744d",
   "metadata": {},
   "source": [
    "여기서는 최대 6번의 토론을 실행합니다.(`max_iters=6`)\n",
    "\n",
    "- `DialogueSimulator` 클래스의 인스턴스인 `simulator`를 생성하며, `agents`와 `select_next_speaker` 함수를 매개변수로 전달합니다.\n",
    "- `simulator.reset()` 메서드를 호출하여 시뮬레이터를 초기화합니다.\n",
    "- `simulator.inject()` 메서드를 사용하여 \"Moderator\" 에이전트에게 `specified_topic`을 주입합니다.\n",
    "- \"Moderator\"가 말한 `specified_topic`을 출력합니다.\n",
    "- `n`이 `max_iters`보다 작은 동안 반복합니다:\n",
    "  - `simulator.step()` 메서드를 호출하여 다음 에이전트의 이름(`name`)과 메시지(`message`)를 가져옵니다.\n",
    "  - 에이전트의 이름과 메시지를 출력합니다.\n",
    "  - `n`을 1 증가시킵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6110a4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Moderator): 정부는 2025년 입시부터 의대 입학정원을 2000명 늘린다고 발표했습니다. 이에 의사단체는 전국에서 규탄집회를 열어 반발하고 있습니다. 의대 정원 확대를 둘러싼 논란 쟁점을 짚어보고, 필수 의료와 지역 의료 해법에 대해서 토론해주세요.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': True, 'detected': True}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m<\u001b[39m max_iters:  \u001b[38;5;66;03m# 최대 반복 횟수까지 반복합니다.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     name, message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 21\u001b[0m         \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     )  \u001b[38;5;66;03m# 시뮬레이터의 다음 단계를 실행하고 발언자와 메시지를 받아옵니다.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 발언자와 메시지를 출력합니다.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m, in \u001b[0;36mDialogueSimulator.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m speaker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[speaker_idx]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 2. 다음 발언자에게 메시지를 전송합니다.\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 3. 모든 에이전트가 메시지를 받습니다.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m receiver \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m, in \u001b[0;36mDialogueAgentWithTools.send\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# AI 메시지를 생성합니다.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m message \u001b[38;5;241m=\u001b[39m AIMessage(\n\u001b[1;32m---> 27\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_history\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# 생성된 메시지의 내용을 반환합니다.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain\\agents\\agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1639\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain\\agents\\agent.py:1335\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1345\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain\\agents\\agent.py:1363\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1362\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1363\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain\\agents\\agent.py:580\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3438\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3431\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   3432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[0;32m   3433\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3436\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3437\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3438\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3424\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3417\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   3418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   3419\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3422\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   3423\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 3424\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[0;32m   3425\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3426\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[0;32m   3427\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m   3428\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2215\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[1;34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2214\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 2215\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2216\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m   2217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3386\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[1;34m(self, inputs, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   3383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3384\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[1;32m-> 3386\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1429\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1426\u001b[0m final: Input\n\u001b[0;32m   1427\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1429\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1430\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[0;32m   1431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[0;32m   1432\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[0;32m   1433\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[0;32m   1434\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[0;32m   1435\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[0;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[0;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5646\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5639\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[0;32m   5641\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5644\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   5645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m-> 5646\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   5647\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5648\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5649\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5650\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1447\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   1444\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[1;32m-> 1447\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:499\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m _normalize_messages(messages)\n\u001b[0;32m    498\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((_LC_ID_PREFIX, \u001b[38;5;28mstr\u001b[39m(run_manager\u001b[38;5;241m.\u001b[39mrun_id)))\n\u001b[1;32m--> 499\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:634\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m     base_generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m response:\n\u001b[0;32m    636\u001b[0m     is_first_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\openai\\_base_client.py:1265\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1253\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1262\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1263\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1264\u001b[0m     )\n\u001b[1;32m-> 1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1055\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': True, 'detected': True}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}"
     ]
    }
   ],
   "source": [
    "max_iters = 30  # 최대 반복 횟수를 6으로 설정합니다.\n",
    "n = 0  # 반복 횟수를 추적하는 변수를 0으로 초기화합니다.\n",
    "\n",
    "# DialogueSimulator 객체를 생성하고, agents와 select_next_speaker 함수를 전달합니다.\n",
    "simulator = DialogueSimulator(\n",
    "    agents=agents_with_search, selection_function=select_next_speaker\n",
    ")\n",
    "\n",
    "# 시뮬레이터를 초기 상태로 리셋합니다.\n",
    "simulator.reset()\n",
    "\n",
    "# Moderator가 지정된 주제를 제시합니다.\n",
    "simulator.inject(\"Moderator\", specified_topic)\n",
    "\n",
    "# Moderator가 제시한 주제를 출력합니다.\n",
    "print(f\"(Moderator): {specified_topic}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while n < max_iters:  # 최대 반복 횟수까지 반복합니다.\n",
    "    name, message = (\n",
    "        simulator.step()\n",
    "    )  # 시뮬레이터의 다음 단계를 실행하고 발언자와 메시지를 받아옵니다.\n",
    "    print(f\"({name}): {message}\")  # 발언자와 메시지를 출력합니다.\n",
    "    print(\"\\n\")\n",
    "    n += 1  # 반복 횟수를 1 증가시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d160c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
