{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=uZoz3T3Z6-w&t=634s\n",
    "- https://github.com/Coding-Crashkurse/LangGraph-Tutorial/blob/main/crag.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Corrective RAG with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 개요\n",
    "- 소개: \n",
    "    - LangGraph를 사용하여 자가 교정 RAG를 수행하는 방법을 소개합니다.\n",
    "- 필요성: \n",
    "    - 사용자 질문이 벡터 데이터베이스에서 검색되었을 때, 항상 상위 K개의 문서(예: 4개)를 검색하게 됩니다. 하지만 이 문서들이 실제로 질문에 적합한지는 알 수 없습니다. 이를 해결하기 위해 자가 교정 RAG 시스템을 도입합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 자가 교정 RAG 시스템\n",
    "- 개념: \n",
    "    - 각 문서를 LLM이 이진 점수(예/아니오)로 평가하여 질문에 적합한지 여부를 판단합니다. 이 정보를 바탕으로 질문을 재작성하거나 검색된 문서 수를 줄일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 설정\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"ls__708b8970829247d1a055f33c434aad1d\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"edu-langchain-0326\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 단계별 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "def Get_LLM():    \n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = '352a6bee97b5451ab5866993a7ef4ce4'\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://aoai-spn-krc.openai.azure.com/'\n",
    "    model = AzureChatOpenAI(  \n",
    "      api_version = '2024-02-01',\n",
    "      azure_deployment = 'gpt-4o-kr-spn',\n",
    "      temperature = 0.0\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def Get_Embedding():\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = '5acedf2738034ef4be0cd6f075a8e4a3'\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://aoaibhkim2.openai.azure.com/'\n",
    "    return AzureOpenAIEmbeddings(\n",
    "      azure_deployment='txt-embed-ada-002-au',\n",
    "      openai_api_version='2024-03-01-preview',     \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터 데이터베이스 생성\n",
    "- 사용 도구: Chroma를 벡터 저장소로 사용, AzureOpenAI 임베딩을 문서 임베딩에 사용.\n",
    "- 문서 예시: 가상의 레스토랑 'Bel Vista'에 대한 정보를 포함한 4개의 문서."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"벨라비스타는 요리 업계에서 20년 이상의 경력을 보유한 유명한 셰프인 Antonio Rossi가 소유하고 있습니다. 그는 지역 사회에 정통 이탈리아 맛을 선사하기 위해 벨라비스타를 시작했습니다.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"벨라비스타는 다양한 예산에 맞는 가격으로 다양한 요리를 제공합니다. 애피타이저 가격은 8달러부터, 메인 코스 가격은 15달러~35달러, 디저트 가격은 6달러~12달러입니다.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"벨라비스타는 월요일부터 일요일까지 영업합니다. 평일은 오전 11시부터 오후 10시까지, 주말은 오전 11시부터 오후 11시까지 연장 운영됩니다.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"벨라비스타는 점심 메뉴, 저녁 메뉴, 주말 특별 브런치 메뉴 등 다양한 메뉴를 선보이고 있습니다. 점심 메뉴에는 가벼운 이탈리아 요리가 포함되어 있으며, 저녁 메뉴에는 더욱 다양한 전통 요리와 현대 요리가 제공되며, 브런치 메뉴에는 고전적인 아침 식사 항목과 이탈리아 특선 요리가 모두 포함되어 있습니다.\",\n",
    "        metadata={\"source\": \"restaurant_info.txt\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터 저장소 생성 및 검색기 변환\n",
    "- from_documents 클래스 메서드를 사용하여 벡터 저장소를 생성하고, 문서와 임베딩 함수를 전달.\n",
    "- 표준화된 인터페이스를 제공하여 문서 검색을 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = Get_Embedding()\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에이전트 상태 관리:\n",
    "- 속성: 질문, 점수(예/아니오), LLM 출력, 문서, 주제 적합 여부를 저장.\n",
    "- 조건: 질문이 주제와 관련 없는 경우, 검색을 수행하지 않고 사용자에게 알림."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str # 질문\n",
    "    grades: list[str] # 점수 (yes/no)\n",
    "    llm_output: str # LLM 출력\n",
    "    documents: list[str] # 문서\n",
    "    on_topic: bool # 주제 적합 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 검색 함수:\n",
    "- 상태에서 질문을 추출하고 검색기의 get_relevant_documents 메서드에 전달.\n",
    "- 문서의 페이지 내용을 추출하여 LLM이 평가하도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(state: AgentState):\n",
    "    print(f\"NODE: retrieve_docs START!\")\n",
    "    question = state[\"question\"]\n",
    "    print(f\"NODE: retrieve_docs QUESTION : {question}\")\n",
    "    documents = retriever.get_relevant_documents(query=question)\n",
    "    state[\"documents\"] = [doc.page_content for doc in documents]\n",
    "    print(f\"NODE: retrieve_docs DOCUMENT : {state[\"documents\"]}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기 질문 분류기:\n",
    "- 목적: 질문이 레스토랑과 관련이 있는지 여부를 판단.\n",
    "- 방법: 커스텀 출력 클래스 생성, LLM에게 질문이 주제와 관련이 있는지 여부를 평가하도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 질문 관련성 판단 결과 출력 클래스\n",
    "class GradeQuestion(BaseModel): \n",
    "    \"\"\"벨라비스타 레스토랑과 관련된 질문인지 확인하는 이진 점수\"\"\"\n",
    "\n",
    "    score: str = Field(\n",
    "        description=\"질문은 벨라비스타 레스토랑에 관한 것입니다. -> 'Yes' 또는 'No'\"\n",
    "    )\n",
    "\n",
    "# 질문 관련성 판단 함수\n",
    "def question_classifier(state: AgentState):\n",
    "    print(f\"NODE: question_classifier START!\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    system = \"\"\"귀하는 검색된 문서와 사용자 질문의 관련성을 평가하는 채점자입니다. \\n\n",
    "        질문이 다음 주제 중 하나에 관한 경우에만 대답하십시오:\n",
    "        1. 벨라비스타 소유자(Antonio Rossi)에 대한 정보.\n",
    "        2. 벨라비스타의 요리 가격.\n",
    "        3. 벨라비스타 영업시간\n",
    "        4. 벨라비스타에서 이용 가능한 메뉴입니다.\n",
    "\n",
    "        이러한 주제에 관한 질문인 것인지 ('yes' 또는 'no')\n",
    "        \"\"\"\n",
    "\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"User question: {question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = Get_LLM()\n",
    "    structured_llm = llm.with_structured_output(GradeQuestion)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "    result = grader_llm.invoke({\"question\": question})\n",
    "    print(f\"NODE: question_classifier RESULT : {result}\")\n",
    "    state[\"on_topic\"] = result.score\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문 관련성 분류 라우터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 관련성 결과 반환 함수\n",
    "def on_topic_router(state: AgentState):\n",
    "    print(f\"NODE: on_topic_router START!\")\n",
    "    on_topic = state[\"on_topic\"]\n",
    "    print(f\"NODE: on_topic_router ON TOPIC : {on_topic}\")\n",
    "    if on_topic.lower() == \"yes\":\n",
    "        return \"on_topic\"\n",
    "    return \"off_topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 관련성 없음 처리 함수\n",
    "def off_topic_response(state: AgentState):\n",
    "    print(f\"NODE: off_topic_response START!\")\n",
    "    state[\"llm_output\"] = \"그 질문에는 답변할 수 없습니다!\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 평가기:\n",
    "- 목적: 검색된 문서가 질문과 관련이 있는지 여부를 평가.\n",
    "- 방법: 커스텀 팬데틱 클래스 생성, LLM이 각 문서를 평가하도록 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 검색 결과의 관련성 평가 결과 출력 클래스\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"검색된 문서의 관련성을 확인하기 위한 이진 점수\"\"\"\n",
    "\n",
    "    score: str = Field(\n",
    "        description=\"문서는 질문과 관련이 있습니다, 'Yes' or 'No'\"\n",
    "    )\n",
    "\n",
    "# 질문과 검색 결과의 관련성 평가 함수\n",
    "def document_grader(state: AgentState):\n",
    "    print(f\"NODE: document_grader START!\")\n",
    "    docs = state[\"documents\"]\n",
    "    print(f\"NODE: document_grader DOCS : {docs}\")\n",
    "    question = state[\"question\"]\n",
    "    print(f\"NODE: document_grader QUESTION : {question}\")\n",
    "\n",
    "    # 시스템 프롬프트:\n",
    "    # 귀하는 검색된 문서와 사용자 질문의 관련성을 평가하는 채점자입니다.\n",
    "    # 문서에 질문과 관련된 키워드나 의미론적 의미가 포함되어 있는 경우 관련성 등급을 매깁니다.\n",
    "    # 문서가 질문과 관련이 있는지 여부를 나타내기 위해 이진 점수 '예' 또는 '아니요' 점수를 부여합니다.\n",
    "\n",
    "    system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "        Give a binary score 'Yes' or 'No' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = Get_LLM()\n",
    "    structured_llm = llm.with_structured_output(GradeDocuments)\n",
    "    grader_llm = grade_prompt | structured_llm\n",
    "    scores = []\n",
    "    for doc in docs:\n",
    "        result = grader_llm.invoke({\"document\": doc, \"question\": question})\n",
    "        scores.append(result.score)\n",
    "    state[\"grades\"] = scores\n",
    "    print(f\"NODE: document_grader GRADES : {scores}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성 라우터:\n",
    "- 모든 문서가 '예'인 경우 최종 답변 생성.\n",
    "- '아니오'인 문서가 있는 경우 질문을 재작성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성 라우터 함수\n",
    "def gen_router(state: AgentState):\n",
    "    print(f\"NODE: gen_router START!\")\n",
    "    grades = state[\"grades\"]\n",
    "    print(f\"NODE: gen_router GRADES : {grades}\")\n",
    "    if any(grade.lower() == \"yes\" for grade in grades): # 최종 답변 생성\n",
    "        filtered_grades = [grade for grade in grades if grade.lower() == \"yes\"]\n",
    "        print(f\"NODE: gen_router RETURN : generate\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(f\"NODE: gen_router RETURN : rewrite_query\")\n",
    "        return \"rewrite_query\" # 질문 재 생성\n",
    "    \n",
    "# def gen_router(state: AgentState):\n",
    "#     grades = state[\"grades\"]\n",
    "#     print(\"Document Grades:\", grades)\n",
    "#     if all(grade.lower() == \"yes\" for grade in grades):\n",
    "#         return \"generate\"\n",
    "#     else:\n",
    "#         return \"rewrite_query\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "질문 재 작성기:\n",
    "- 질문을 웹 검색에 최적화된 버전으로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 질문 재 작성 함수\n",
    "def rewriter(state: AgentState):\n",
    "    print(f\"NODE: rewriter START!\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 시스템 프롬프트:\n",
    "    # 당신은 입력 질문을 최적화된 더 나은 버전으로 변환하는 질문 재작성자입니다.\n",
    "    # 웹 검색용. 입력을 보고 기본 의미론적 의도/의미에 대해 추론해 보세요.    \n",
    "\n",
    "    system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "        for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "    re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                # 초기 질문은 다음과 같습니다. \\n\\n {question} \\n 개선된 질문을 작성하세요.\n",
    "                \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    llm = Get_LLM()\n",
    "    question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "    output = question_rewriter.invoke({\"question\": question})\n",
    "    print(f\"NODE: rewriter QUESTION : {output}\")\n",
    "    state[\"question\"] = output\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 답변 생성:\n",
    "- 재작성된 질문과 문서를 바탕으로 최종 답변을 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# 최종 답변 생성 함수\n",
    "def generate_answer(state: AgentState):\n",
    "    print(f\"NODE: generate_answer START!\")\n",
    "    llm = Get_LLM()\n",
    "    question = state[\"question\"]\n",
    "    print(f\"NODE: generate_answer QUESTION : {question}\")\n",
    "    docs = state[\"documents\"]\n",
    "    print(f\"NODE: generate_answer DOCUMENTS : {docs}\")\n",
    "\n",
    "    template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template=template,\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    result = chain.invoke({\"question\": question, \"context\": docs})\n",
    "    state[\"llm_output\"] = result\n",
    "    print(f\"NODE: generate_answer LLM OUTPUT : {result}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 워크플로우 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노드:\n",
    "- 주제 결정: 질문 분류기 사용.\n",
    "- 문서 검색: 문서 검색 함수 실행.\n",
    "- 문서 평가: 문서 평가 함수 실행.\n",
    "- 질문 재작성: 질문 재작성 함수 실행.\n",
    "- 답변 생성: 최종 답변 생성 함수 실행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"topic_decision\", question_classifier) # 주제 결정: on_topic_router 사용.\n",
    "workflow.add_node(\"retrieve_docs\", retrieve_docs) # 문서 검색: 문서 검색 함수 실행\n",
    "workflow.add_node(\"document_grader\", document_grader) # 문서 평가: 문서 평가 함수 실행.\n",
    "workflow.add_node(\"rewrite_query\", rewriter) # 질문 재작성: 질문 재작성 함수 실행.\n",
    "workflow.add_node(\"generate_answer\", generate_answer) # 답변 생성: 최종 답변 생성 함수 실행.\n",
    "\n",
    "workflow.add_node(\"off_topic_response\", off_topic_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에지:\n",
    "- 주제 결정 결과에 따라 검색 또는 오프 토픽 응답.\n",
    "- 문서 평가 결과에 따라 최종 답변 생성 또는 질문 재작성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주제 결정 결과에 따라 검색 또는 오프 토픽 응답.\n",
    "workflow.add_conditional_edges(\n",
    "    \"topic_decision\",\n",
    "    on_topic_router,\n",
    "    {\n",
    "        \"on_topic\": \"retrieve_docs\",\n",
    "        \"off_topic\": \"off_topic_response\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"retrieve_docs\", \"document_grader\")\n",
    "\n",
    "# 문서 평가 결과에 따라 최종 답변 생성 또는 질문 재작성.\n",
    "workflow.add_conditional_edges(\n",
    "    \"document_grader\",\n",
    "    gen_router,\n",
    "    {\n",
    "        \"generate\": \"generate_answer\",\n",
    "        \"rewrite_query\": \"rewrite_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"rewrite_query\", \"retrieve_docs\")\n",
    "\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"off_topic_response\", END)\n",
    "\n",
    "workflow.set_entry_point(\"topic_decision\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"question\": \"날씨가 어때?\"})\n",
    "result[\"llm_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"question\": \"벨라비스타 주인은 누구야?\"})\n",
    "result[\"llm_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"question\": \"벨라비스타 메뉴에 자장면도 있어?\"})\n",
    "result[\"llm_output\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_analy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
