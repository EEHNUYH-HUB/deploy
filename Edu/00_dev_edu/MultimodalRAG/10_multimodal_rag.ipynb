{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API 키 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZURE_OPENAI_ENDPOINT: https://aoai-spn-estus2.openai.azure.com/\n",
      "AZURE_OPENAI_API_KEY: 9f84277eccac458186c0f6a50e508223\n",
      "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_GPT4O: gpt-4o\n",
      "AZURE_OPENAI_API_VERSION: 2024-06-01\n",
      "OPENAI_API_VERSION: 2024-06-01\n",
      "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT: https://docu-intellegence-estus.cognitiveservices.azure.com/\n",
      "AZURE_DOCUMENT_INTELLIGENCE_KEY: a83db99ae0364c4fb473fe242b2cf7c0\n",
      "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION: 2024-07-31-preview\n"
     ]
    }
   ],
   "source": [
    "import os # 운영체제와 상호작용하기 위한 os 모듈을 가져옵니다.\n",
    "from dotenv import load_dotenv # .env 파일에서 환경 변수를 로드하기 위한 dotenv 모듈의 load_dotenv 함수를 가져옵니다.\n",
    "load_dotenv('..\\\\.env',override = True) # '.env' 파일을 로드하며, 기존 환경 변수를 덮어씁니다. 00_dev_edu\\.env\n",
    "\n",
    "# Azure OpenAI API 관련 설정을 정의합니다.\n",
    "aoai_api_base = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "aoai_api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "aoai_deployment_name = os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_GPT4O')\n",
    "aoai_api_version = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "openai_api_version = os.getenv('OPENAI_API_VERSION')\n",
    "\n",
    "doc_intelligence_endpoint = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT')\n",
    "doc_intelligence_api_key = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_KEY')\n",
    "doc_intelligence_api_version = os.getenv('AZURE_DOCUMENT_INTELLIGENCE_API_VERSION')\n",
    "\n",
    "print(f'AZURE_OPENAI_ENDPOINT: {aoai_api_base}')\n",
    "print(f'AZURE_OPENAI_API_KEY: {aoai_api_key}')\n",
    "print(f'AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_GPT4O: {aoai_deployment_name}')\n",
    "print(f'AZURE_OPENAI_API_VERSION: {aoai_api_version}')\n",
    "print(f'OPENAI_API_VERSION: {openai_api_version}')\n",
    "print(f'AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT: {doc_intelligence_endpoint}')\n",
    "print(f'AZURE_DOCUMENT_INTELLIGENCE_KEY: {doc_intelligence_api_key}')\n",
    "print(f'AZURE_DOCUMENT_INTELLIGENCE_API_VERSION: {doc_intelligence_api_version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG를 수행할 문서 경로와 언어 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\[HIF 월간 산업이슈] 24년 10월호.pdf\n"
     ]
    }
   ],
   "source": [
    "_SAMPLE = '[HIF 월간 산업이슈] 24년 10월호.pdf' # RAG를 수행할 문서 설정\n",
    "_index_name: str = \"idx120301\" # 생성할 azure ai search 인덱스 이름 설정\n",
    "\n",
    "_filePath = os.path.join(\"data\", _SAMPLE) # 문서 경로 설정\n",
    "print(_filePath)\n",
    "\n",
    "_language = \"Korean\" # 주요 언어 설정\n",
    "\n",
    "_file_name = _SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature # Azure 문서 인텔리전스 분석 기능을 임포트합니다.\n",
    "from langchain_community.document_loaders.blob_loaders import Blob # Blob 로더를 가져옵니다.\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "azure document intelligence를 호출하여 문서 레이아웃 분석 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "kwargs[\"api_version\"] = doc_intelligence_api_version\n",
    "\n",
    "docIntelligenceClient = DocumentIntelligenceClient(\n",
    "    endpoint=doc_intelligence_endpoint,\n",
    "    credential=AzureKeyCredential(doc_intelligence_api_key),\n",
    "    headers={\"x-ms-useragent\": \"langchain-parser/1.0.0\"},\n",
    "    features=[DocumentAnalysisFeature.OCR_HIGH_RESOLUTION], # 고해상도 이미지 OCR 옵션 - 추가 비용이 든다.\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "api_model=\"prebuilt-layout\" # 레이아웃 분석 모델, 일반적인 모델 사용\n",
    "contenttype=\"application/octet-stream\"\n",
    "output_contentformat=\"markdown\" # 레이아웃 분석 결과에서 페이지 내용을 markdown 형식으로 반환\n",
    "\n",
    "blob = Blob.from_path(_filePath)\n",
    "with blob.as_bytes_io() as file_obj:\n",
    "    poller = docIntelligenceClient.begin_analyze_document(\n",
    "        model_id = api_model,\n",
    "        analyze_request=file_obj,\n",
    "        content_type = contenttype,\n",
    "        output_content_format = output_contentformat,\n",
    "    )\n",
    "\n",
    "# 작업 완료 대기 및 결과 받기\n",
    "try:\n",
    "    docAnalyzeResult: AnalyzeResult = poller.result()  # 작업이 완료될 때까지 대기\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"문서 분석 중 오류가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이아웃 분석 결과에 대한 serialize 테스트 및 레이아웃 분석 정보 생성\n",
    "- analyze_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'str'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_obj = docAnalyzeResult.as_dict() # 분석 결과를 json으로 변환\n",
    "print(type(json_obj))\n",
    "\n",
    "json_str = json.dumps(json_obj, ensure_ascii=False) # json을 string으로 변환\n",
    "print(type(json_str))\n",
    "\n",
    "con_json_obj = json.loads(json_str) # string을 다시 json으로 변환\n",
    "print(type(con_json_obj))\n",
    "\n",
    "analyze_result = AnalyzeResult(con_json_obj) # json 객체를 다시 azure document intelligence 객체로 변환\n",
    "# analyze_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 페이지 번호와 페이지 텍스트를 라인 기준으로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'HIF 월간 산업 이슈\\nMonthly Industrial Issue.\\n2024년 8월 30일 제39호\\n연\\n구 원이\\n예\\n린\\n연구 원 김종 현\\n연구 위 원\\n김\\n문\\n태\\n하나로여겨된\\n모두의ㄱㅇ.\\nHIF 월간 산업 이슈(10월)\\nMonthly Industrial Issue\\n산업별 주요 이슈\\n철강\\n철강업, 원가 부담 가중되고 업황 정체에 따른 실적 회복 시기 지연\\n• 건설업 등 전방 수요 부진이 지속되는 가운데, 중국 경기 침체에 따른 밀어내기 수출 등으로 철강업\\n불황이 장기화되며 철강사들의 3분기 실적도 저하된 것으로 파악\\n• 산업용 전기료 상승으로 철강사의 비용 부담이 증가하고 중국 정부의 경기 부양책에도 전방 산업\\n회복이 지연되며 \\'25년 철강사의 실적 개선폭은 제한적일 전망\\n조선\\n3Q 양호한 성장세, 그러나 중국 생산능력 확대에 따른 영향 우려\\n• \\'24년 대량 수주에 의한 기저효과로 인해 내년 신조 수주는 둔화될 것으로 예상되는 가운데 중국\\n조선소의 증설로 글로벌 수주 경쟁이 심화되며 선가가 하락할 전망\\n• 선가 하락으로 인해 \\'27년 이후 인도될 물량의 수익성 악화가 예상되며, 증설을 바탕으로 한 중국\\n조선소의 가격 우위 전략으로 인해 국내 조선소의 영업환경이 악화될 우려\\n유통\\n\"불황기, 고객은 떠나도 팬은 떠나지 않는다.\"\\', 팬덤 경제 확산과 영향\\n• \\'팬덤 경제\\'는 특정 대상을 향한 유대감과 열정이 창출하는 경제적 가치를 의미하며, 최근 디지털\\n플랫폼 및 인프라 발달, 가치 소비 확산, 모바일 보편화, 팬덤의 집단적 소비 행태 등에 따라 확대\\n• 팬덤 경제 기반의 커머스 플랫폼은 팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스 등이 존재하며, 팬덤\\n경제는 경기에 비교적 둔감한 특성을 지녀 소비 위축 시기에 새로운 성장 기회를 제공할 것으로 기대\\nㅎ 하나은행 하나금융연구소\\n',\n",
       " 2: '산업 이슈\\n철강\\n철강업, 원가 부담 가중되고 업황 정체에 따른 실적 회복 시기 지연\\n조선\\n3Q 양호한 성장세, 그러나 중국 생산능력 확대에 따른 영향 우려\\n유통\\n\"불황기, 고객은 떠나도 팬은 떠나지 않는다.\"\\n팬덤 경제 확산과 영향\\n',\n",
       " 3: \"하나 산업정보\\nHana Industry Info.\\nC24. 철강\\n철강업, 원가 부담 가중되고 업황 정체에 따른 실적 회복 시기 지연\\n연구원 이예린\\n※ Summary : 장기화되는 건설 경기 침체와 중국발 철강 공급 과잉 문제가 지속되며 철강사들의\\n3분기 실적도 여전히 부진할 것으로 예상. 철강업의 대내외 리스크 요인이 해소되지 않은 가운데,\\n산업용 전기 요금 인상 조치로 전기로 투자를 확대해 운영하고 있는 철강사들의 재무 부담이 가중되며\\n4분기에도 수익성 개선은 어려울 것으로 예상. 자동차·건설업의 수요 둔화와 중국 정부의 적극적인 경기\\n부양책에도 중국 내수 수요 회복이 지연되며 공급 과잉이 지속될 것으로 예상되어 '25년 철강사의 실적\\n개선폭은 제한적일 전망\\n■ 건설업 등 전방 수요 부진 및 중국 경기 침체로 철강업 불황 장기화되며 3분기 실적 저하\\n● 건설 시장 침체가 지속되는 가운데, 중국 내수 부진 및 글로벌 대중 보호무역주의\\n확산 등으로 중국산 철강의 국내 시장 잠식이 심화되며 철강업 실적 회복이 지연\\n- '24.3Q 기준 중국 철강 수입량은 전년동기대비 4.8% 증가하며 국내 철강 가격 약세가 지속\\n● 포스코, 현대제철 등 주요 철강 4개사의 3분기 합산 매출액은 전년 동기대비 7.4%\\n하락하였고 합산 영업이익률은 3%p 하락한 3.4%로 추정\\n- 포스코홀딩스 철강 사업 부문의 3분기 영업이익은 전년동기대비 45.5% 하락하였고\\n현대제철의 영업이익은 전년동기대비 64%가 하락\\n● 중국發 밀어내기 수출 영향이 지속되고 중국의 경기부양책에 따른 철광석 등 원자재\\n가격 상승과 산업용 전기 요금 인상 조치까지 더해지며 철강사의 재무 부담이 확대\\n그림1 | 글로벌 철강 수요 추이 및 전망\\n19\\n(억톤)\\n철강 수요(좌)\\n(YoY, %)\\n4\\n2.8\\nQ\\n증가율(우)\\n1.2\\n2\\n18\\nO\\n-0.8\\n-0.9\\n0\\n·\\n.\\n17\\n-3.1\\n-2\\nO\\n16\\n-4\\n'21\\n'22\\n'23\\n'24P\\n'25E\\n자료 : WSA\\n그림2 | 주요 철강 3개사의 3분기 실적\\n12,000\\n(십억원)\\n매출액(좌)\\n영업이익률(우)\\n(%)\\n12\\n10,000\\n9.8\\nO\\n10\\n8,000\\n7.5\\n8\\n6,000\\n4.6\\n6\\n4,000\\n3.6\\n2.6\\n4\\n2,000\\n0.7\\n2\\n0\\n0\\n23.3Q\\n24.3Q\\n23.3Q\\n24.3Q\\n23.3Q\\n24.3Q\\n포스코\\n현대제철\\n동국제강\\n자료 : 각 사 IR 자료\\nHana Bank Hana institute of Finance\\n\",\n",
       " 4: \"하나 산업정보\\nHana Industry Info.\\n■ 철강업계, 전기료 인상으로 비용 부담 증가하며 4분기 수익성 개선도 어려울 것으로 예상\\n● 10월 24일부터 산업용 전기 평균 요금이 9.7% 인상되며 그린 철강 전환을 위해 전기로\\n투자를 확대·운영하고 있는 철강업계의 원가 부담이 크게 증가\\n- 대기업 기준 전기요금이 16.9/1kWh 인상되며 철강업의 원가 부담은 약 3,400억원 증가할 것으로 예상\\n● 4분기 전기료 인상으로 11월 철근 기준가격은 전월대비 1만원 상승할 예정이나 소폭\\n상승했던 유통시세 가격은 10월 하락하며 전기로 제강사들의 실적 부담이 가중\\n- 철근 유통 가격이 철스크랩보다 큰 폭으로 하락하며 스프레드가 축소되어 제강사 수익성이 더욱 악화\\n- 철근 유통가(원/kg): 855('23.10) → 784('24.1) → 743('24.4) → 804('24.9) → 754('24.10)\\n● 전기료 인상에 따른 생산비 부담이 제품 가격으로 전이되면 중국산 저가 철강재와의 가격 경쟁력이\\n하락해 철강사들의 수익성이 더욱 악화될 가능성도 존재\\n■ 수요 산업 부진 및 중국발 리스크 요인이 해소되지 않으며 실적 정체가 '25년에도 지속될 전망\\n● 미국, 유럽 등 주요국의 철강 수요 증가에도 철강 최대 소비국인 중국의 수요\\n역성장이 지속되며 '25년 세계 철강 산업은 1.2%의 저성장에 그칠 전망\\n- 국가별 철강 수요 증가율 전망: (중국)-1.0% (미국)2.0% (한국)-0.6% (일본)1.7% (EU&UK)3.5%\\n● 中정부가 잇달아 경기 부양책을 발표하고 있으나, 철강업의 구조적 문제와 부양 정책\\n규모(2.7조위안) 등을 고려할 때 실질적인 전방 수요 회복 효과는 제한적일 것으로 예상\\n- 철강 수요 회복에 대한 기대감으로 철광석 및 철강재 가격이 반등했으나 단기 상승으로 그침\\n● 견조한 조선향 후판 수요에도 불구하고 건설·자동차향 내수 부진과 중국 공급 과잉\\n이슈 지속 등으로 인해 '25년 철강사의 실적 개선폭은 매우 제한적 ㅎ\\n그림3 | 철근 기준가격 및 유통가격 추이\\n1,400\\n(원/kg)\\n기준가격\\n유통가격\\n1,200\\n1,000\\n800\\n600\\n400\\n'20\\n'21\\n'22\\n'23\\n'24\\n주 : 철근SD400 가격 기준, 유통가격은 도매 즉시현금가 기준\\n자료 : 스틸데일리\\n그림4 | 국내 철강업체 실적 전망\\n150\\n(조원)\\n11.0\\n––매출액(좌)\\n(%)\\n12\\n영업이익률(우)\\n130\\n10\\n8\\n110\\n6.3\\n5.2\\n5.4\\n6\\n4.4\\n90\\n2.7\\n4\\n70\\n2\\n'20\\n'21\\n'22\\n'23\\n'24P\\n'25E\\n주 : 1차 철강 제조업 외감 이상 합산 기준\\n자료 : Value Search, 하나금융연구소\\nㅎ 하나은행 하나금융연구소\\n\",\n",
       " 5: \"HIF 월간 산업 이슈\\nMonthly Industrial Issue.\\nC31. 조선\\n3Q 양호한 성장세, 그러나 중국 생산능력 확대에 따른 영향 우려\\n연구원 김종현\\n※ Summary : 환경규제에 따른 노후선 교체 수요로 인해 전 세계 '24년 9월 누적 신조선 수주\\n실적은 '08년 이후 최대치를 기록. '24년 대량 수주에 의한 기저효과로 인해 내년 신조 수주는 둔화될\\n것으로 예상되는 가운데 중국 조선소의 증설로 글로벌 수주 경쟁이 심화되며 선가가 하락할 전망. 수주 시점의\\n선가는 선박 인도시기의 실적에 영향을 미치므로 선가 하락이 단기 실적에 미칠 영향은 미미한 상황. 그러나\\n'27년 이후 중국 조선소의 가격 우위 전략으로 인해 수주 경쟁이 심화되며 국내 조선소의 영업 경쟁력이\\n하락할 우려가 있어 이에 대한 국내 조선소의 대응 전략을 모니터링할 필요\\n■ 환경규제에 따른 노후선 교체 수요로 인해 '24년 9월 누적 수주 실적은 '08년 이후 최대치\\n● 환경규제에 따른 노후선 교체 수요를 바탕으로 '24년 9월 누적 수주 실적은 전년 동기\\n대비 40.4% 증가하였으며 '08년 이후 최대 수주 실적을 기록\\n- '24년 9월 누적 선종별 수주 증가율 (%, YOY) : LNG선 96.3%, 컨테이너 84.3%, 탱커 48.7%\\n● 동기간 중국은 조선소 설비 확장 및 저가 수주를 바탕으로 한 공격적 영업 활동을 통해\\n수주 점유율이 69.0%에 달하였고 한국은 LNG선을 중심으로 수주하며 점유율 18.6% 기록\\n- '24년 9월 누적 국가별 수주 증가율 (%, YOY) : 중국 68.4%, 한국 26.6%, 일본 - 53.1%\\n● 한편, 국내 주요 조선사의 수주 점유율은 다소 약화되었으나 '24년 3분기 실적은 旣\\n수주 물량의 인도를 바탕으로 양호한 실적을 기록하였으며 내년도 실적도 긍정적일 전망\\n- 대형 조선3사의 '24년 3분기 누적 합산 실적은 YOY 기준 매출액 23.5%, 영업이익률은 1.5%p 증가\\n그림5 | 글로벌 신조선 수주량 추이\\n80\\n(백만CGT)\\n70\\n'08.9\\n'24.9\\n60\\n5,361만CGT\\n4,976만CGT\\n50\\nㅇ\\n40\\n30\\n20\\n10\\n0\\n04.9\\n'09.9\\n'14.9\\n'19.9\\n'24.9\\n주 : YTD 기준\\n자료 : Clarkson, 하나금융연구소\\n그림6 | 국내 조선사 실적 추이\\n13\\n(조원)\\n매출액(좌)\\n(%)\\n6\\n영업이익률(우)\\n5\\n11\\n4\\n3\\n9\\n2\\n7\\n1\\n0\\n5\\n-1\\n'23.1Q '23.2Q '23.3Q '23.4Q '24.1Q '24.2Q '24.3Q\\n주:한국조선해양, 삼성중공업, 한화오션 합산 실적\\n자료 : Valuesearch, 각사 IR, 하나금융연구소\\n5\\nHana Bank Hana Institute of Finance\\n\",\n",
       " 6: \"HIF 월간 산업 이슈\\nMonthly Industrial Issue.\\n■ 기저효과에 따른 신조 수주 둔화와 中 조선소 증설로 수주 경쟁이 심화되며 선가 하락 전망\\n● '24년 대량 수주에 따른 기저효과로 인해 수주 둔화가 예상되며 이에 더하여 신조선\\n대량 유입에 따른 선박 공급 과잉과 환경규제 영향으로 인해 향후 선가 하락이 불가피할 전망\\n- 신조선보다 중고선의 가격 변동성이 더 큰 가운데 신조가 하락은 중고가 하락으로 이어지\\n면서 중고선가 낙폭이 확대됨에 따라 중고선의 담보가치가 하락할 우려\\n● '21년부터 '24년 3분기까지 발표된 글로벌 조선사들의 캐파 확대 계획 규모는 총 820만\\nCGT로, 이 중 재가동은 약 390만 CGT, 신규 증설은 약 440만 CGT (Clarksons)\\n- '20년 글로벌 조선소 총 캐파는 약 4천만 CGT로, '30년까지 '20년 대비 약 11% 확대 예정\\n● 이 중 중국이 약 77%를 차지하며 글로벌 조선소 증설의 대부분을 견인할 예정이며,\\n중국의 신규 증설 규모는 약 340만 CGT, 재가동 규모는 약 290만 CGT로 추정\\n■ 선가 하락의 단기 영향은 미미하나 '27년부터 중국과의 가격 경쟁 심화로 국내 조선소의 영업환경 악화 우려\\n● 현재 국내 조선소의 수주잔량을 살펴보면 '25, '26년 물량은 모두 확보한 상황이므로\\n선가 하락에 따른 수익성 약화는 '27년도 수주 물량부터 본격화될 전망\\n- 국내 조선소의 연도별 수주잔량 (백만CGT) : 12.4('25) → 10.2('26) → 9.0+α ('27) → 3.0+α ('28)\\n● 국내 조선소의 핵심 수주 선종은 컨테이너선과 LNG선으로 기술 우위 전략을 통해 시장을\\n선점하였으나 최근 중국과의 기술 격차 축소로 인해 해당 선종에서도 경쟁이 심화\\n● 기술 격차 축소로 가격 경쟁력이 더욱 부각되며 中 조선소의 증설과 이에 따른 韓-中 간\\n가격 경쟁력 격차가 확대되면서 국내 조선소의 영업력 악화가 고착화될 우려\\n● 국내 조선사의 주요 수주 선종인 LNG선, LPG선 등에 미치는 영향은 다소 제한적이나\\n중국의 주요 증설 계획이 집중된 벌크선, 탱커, 컨테이너선에서 영향이 클 전망\\nっ\\n표1 | 중국 조선소의 증설 동향\\n조선소\\n가동\\n예상일\\n생산규모\\n(CGT)\\n주요 선종\\nHengli SB\\n2026\\n831,000\\n벌크, 탱커\\nWison Qidong\\n2026\\n-\\n해양플랜트\\nYangzijIang Holdings\\n2026\\n-\\nLNG선\\nNew Times SB\\n2026\\n882,00\\n탱커, 컨테이너\\nHantong WinG HI\\n2026\\n37,000\\nUltramaxes\\nCMCS\\n2026\\n-\\n크루즈, 여객선\\nShanghai Waigaoqiao\\n2025\\n973,000\\n컨테이너, 탱커\\nCOSCO HI (Zhoushan)\\n2026\\n384,000\\n벌크\\nChizhou Guichi\\n2026\\n-\\n연안 소형선박\\n자료 : Clarkson, SK 증권\\n그림7 | 선종별 한-중 수주량 비교 ('24.9 YTD 기준)\\n16\\n(백만CGT)\\n■ 한국 ■ 중국\\n14\\n12\\n10\\n8\\n6\\n4\\n2\\n0\\n컨테이너\\n탱커\\n벌크\\nLNG선\\n기타\\n자료 : Clarkson, 하나금융연구소\\nㅎ 하나은행 하나금융연구소\\n6\\n\",\n",
       " 7: 'HIF 월간 산업 이슈\\nMonthly Industrial Issue.\\nG. 유통업\\n\"불황기, 고객은 떠나도 팬은 떠나지 않는다.\", 팬덤 경제 확산과 영향\\n연구위원 김문태\\n※ Summary : \\'팬덤 경제\\'는 특정 대상을 향한 유대감과 열정이 창출하는 경제적 가치를 의미. 팬덤\\n경제는 최근 디지털 플랫폼 및 인프라 발달, 가치 소비 확산 등에 따라 확대. 팬덤 경제 기반의 플랫\\n폼으로는 1 위버스, 버블 등 K-pop 관련 콘텐츠, 굿즈 등을 판매하는 팬덤 플랫폼, 2 유튜브 쇼핑\\n과 같이 인플루언서의 실시간 소통을 통해 판매가 이루어지는 라이브커머스, 3 무신사, 오늘의 집 등\\n특정 분야에 대한 관심과 유대감으로 형성된 커뮤니티형 커머스가 존재. 이러한 팬덤 경제는 경기에\\n비교적 덜 민감하여 소비 위축 시기에 소비재·유통업체에게 새로운 성장 기회를 제공할 것으로 기대\\n■ 디지털 발달, 가치 소비 등에 따라 특정 대상에 대한 호감에 기반을 둔 \\'팬덤 경제\\'가 확산\\n● \\'24년 4월, 최고 트래픽 960만번으로 콘서트 전석(약 9만석) 매진을 기록한 가수 임영웅\\n의 영향력은 가요계뿐만 아니라 자동차, 건강식품 등 산업계의 매출 신장에도 기여\\n- 2020년, 쌍용차의 \\'G4 렉스턴\\'은 임영웅을 모델로 내세우며 전월 대비 53%가 증가한 바 있으며,\\n건강식품 \\'정관장\\'은 \\'임영웅 효과\\'로 가정의 달 행사 7일 간 전년대비 신규 가입 고객이 72% 증가\\n● \\'팬덤 경제\\'는 이처럼 좋아하는 대상(아티스트, 스포츠, 캐릭터 등)에 열정을 가지고 커뮤니\\n티를 형성하는 팬덤이 실질적으로 창출하는 경제적 가치와 관련 소비 행위를 지칭\\n● 팬덤의 경제적 영향력은 최근 디지털 플랫폼 및 비대면 소통 인프라 발달, 개인적 취향에\\n중점을 둔 \\'가치 소비\\' 확산, 모바일 사용 보편화, 팬덤의 집단적 소비 등에 따라 확대\\n- 코로나19 시기, 모바일 활용 확대와 비대면 소통 인프라 증가가 특히 긍정적으로 작용\\n[G4 렉스턴 광고]\\n그림8 | 가수 임영웅 광고 및 효과\\n美\\n[정관장 가정의 달 행사]\\n- 전월 대비 53% 판매 증가 – 신규 가입 고객 72% 증가\\n자료 : 각 사, 언론자료\\n표2 | 팬덤 경제 확산의 배경\\n구분\\n내용\\n디지털 플랫폼\\n성장\\n- SNS, 스트리밍 서비스의 글로벌 확산\\n- 유튜브, 틱톡 등으로 글로벌 팬덤 형성\\n인프라 발달\\n- 팬과 아티스트 간 글로벌 실시간 소통 가능\\n- 촬영 장비, 스튜디오 등 인프라 확충\\n모바일 사용\\n보편화\\n- 스마트폰 활용 연령 확대(고령층, 저연령층)로\\n취향 공유를 위한 커뮤니티가 확장됨\\n소비 트렌드\\n변화\\n- 차별화된 소비 경험에 대한 수요 확대\\n- 개인적 취향에 중점을 둔 가치 소비 확산\\n팬덤의 집단적\\n소비 행태\\n- 자신이 속한 팬덤 커뮤니티의 목표나 가치에 따른\\n능동적인 경제 행위(대량 구매 등)를 나타냄\\n자료 : 하나금융연구소\\nHana Bank Hana Institute of Finance\\n7\\n',\n",
       " 8: 'HIF 월간 산업 이슈\\nMonthly Industrial Issue.\\n■ 팬덤 경제 기반의 플랫폼은 팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스 등이 존재\\n● 가장 직접적인 팬덤 기반 사업 모델은 K-pop 관련 ‘팬덤 플랫폼\\'으로, 과거 ‘팬클럽\\'\\n이 엔터 산업 고도화 및 모바일 기술 발달로 팬덤 경제에 특화된 플랫폼으로 변화\\n- 대표적으로 하이브 위버스, 디어유(SM) 버블이 있으며, 위버스는 아티스트 영상, 커뮤니티를\\n중심으로 굿즈 판매 연계, 버블은 아티스트와의 채팅을 유료 회원에게 제공하는 것이 특징\\n● 또한, 인플루언서와의 유대감이 중요한 라이브커머스 시장은 \\'20년 4천억원에서 \\'23년\\n10조원 규모로 성장했으며, 지난해 유튜브의 커머스 기능 추가 이후 생태계 확장 중\\n- \\'24.5월, 인스타그램은 크리에이터와 브랜드를 연결하는 \\'크리에이터 마켓플레이스\\'를 도입\\n- 네이버, 카카오, 쿠팡 등은 기존 자체 제작 중심 모델에 오픈형 모델을 추가·확장하며 대응\\n● \\'무신사\\', \\'오늘의 집\\' 등 콘텐츠를 통해 패션, 인테리어에 관심 많은 소비자를 확보한\\n\\'커뮤니티형 커머스\\'는 크리에이터 지원을 통해 콘텐츠 및 소비자 확대를 도모\\n- 무신사 : 패션 커뮤니티 \\'스냅\\'의 크리에이터 \\'스냅 크루\\'에게 혜택 제공(활동비, 화보 촬영 등)\\n- 오늘의 집 : 팬덤 및 창작자 커뮤니티 \\'오하우스\\'를 통해 크리에이터 활동을 지원\\n■ 소비 위축 시기, 팬덤 기반의 수요 창출은 소비재 및 유통 기업에게 성장 기회를 제공\\n● 글로벌 마케팅 전문가 데이비드 미어먼 스콧은 \"불황기, 고객은 떠나도 팬은 떠나지\\n않는다\"며 강력한 팬덤이 불황기에도 안정적인 사업 모델을 창출한다고 주장\\n- 이를 위해서는 정서적 유대감 유도로 커뮤니티를 만들고 그것을 \\'팬덤화\\'시키는 것이 중요\\n● 고금리, 고물가로 소비 시장이 위축된 상황에서 팬덤을 통한 새로운 수요의 창출은\\n소비재 및 유통 기업에게 불황기를 극복할 수 있는 가능성을 제공할 것으로 기대\\n- 팬덤 관련 커머스는 유대감과 소통을 통해 고객의 수요를 유발하는 \\'발견형 쇼핑\\'의 특성을\\n지녀 일반적인 \\'목적형 쇼핑\\' 대비 경기 민감도가 비교적 낮다는 특성을 지님\\nっ\\n그림9 | 국내 라이브커머스 시장 규모\\n12\\n(조원)\\n10\\n8\\n6\\n4\\n2\\n0\\n2020\\n2021\\n2022\\n2023\\n자료 : Statista, 삼정KPMG 재인용\\n표3 | 쇼핑의 2가지 유형 : 목적형 쇼핑과 발견형 쇼핑\\n구분\\n목적형 쇼핑\\n발견형 쇼핑\\n정의\\n- 결핍(부족)에 의한 쇼핑\\n- 필요를 충족하기 위해\\n\\'목적\\' 대상을 구매하는\\n행위\\n- 욕망, 감성에 의한 쇼핑\\n- (외부 자극에 의해) 수요와\\n욕망을 \\'발견\\'하게 되면서\\n이루어지는 구매 행위\\n예시\\n- 가격 검색 및 비교\\n- 생필품 구매\\n- 백화점 쇼윈도\\n- 추천 상품 구매\\n소비 유발\\n요인\\n- 검색의 정확성, 편의성\\n- 낮은 가격 및 할인 혜택\\n- 상품 비교 용이성\\n- 취향에 적합한 추천\\n- 공감을 유발하는 스토리\\n- 관심 기반 커뮤니티\\n특징\\n- 소비 시장 대부분을 차지\\n- 구매력 하락, 소비 성향\\n저하 시기 구매가 위축됨\\n- 목적형 대비 적은 규모\\n- 감성적 소비 특성 상 불황\\n기에도 성장 가능\\n자료 : 하나금융연구소\\nㅎ 하나은행 하나금융연구소\\n8\\n',\n",
       " 9: 'HIF 월간 산업 이슈\\nMonthly Industrial Issue.\\n하나은행 하나금융연구소\\n04538 서울특별시 중구 을지로 66\\n(을지로 2가, 하나금융그룹 명동사옥 8층)\\nTEL 02.2002.2200\\nE-MAIL hanaif@hanafn.com\\nhttp://www.hanaif.re.kr\\n'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_page_text(analyze_result: AnalyzeResult):\n",
    "    page_contents = dict()\n",
    "    for page in analyze_result.pages:\n",
    "        page_content = \"\"\n",
    "\n",
    "        for lineElement in page.lines:\n",
    "            page_content += f\"{lineElement.content}\\n\"\n",
    "    \n",
    "        page_contents[page.page_number] = page_content #페이지 번호 위치에 페이지 텍스트 저장\n",
    "\n",
    "    return page_contents\n",
    "\n",
    "page_content_list = extract_page_text(analyze_result)\n",
    "page_content_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 페이지 번호와 페이지 텍스트를 페이지 위치 기준으로 추출 - 페이지 내용을 통으로 추출하기 때문에 markdown 구조를 유지하면서 추출한다.\n",
    "- page_content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '<!-- PageHeader=\"HIF 월간 산업 이슈 Monthly Industrial Issue.\" -->\\n\\n2024년 8월 30일 제39호\\n\\n연\\n구 원이\\n예\\n린\\n연구 원 김종 현\\n\\n연구 위 원\\n김\\n문\\n태\\n\\n<!-- PageHeader=\"하나로여겨된 모두의ㄱㅇ.\" -->\\n\\n\\n# HIF 월간 산업 이슈(10월) Monthly Industrial Issue\\n\\n\\n# 산업별 주요 이슈\\n\\n\\n## 철강 철강업, 원가 부담 가중되고 업황 정체에 따른 실적 회복 시기 지연\\n\\n• 건설업 등 전방 수요 부진이 지속되는 가운데, 중국 경기 침체에 따른 밀어내기 수출 등으로 철강업\\n불황이 장기화되며 철강사들의 3분기 실적도 저하된 것으로 파악\\n\\n• 산업용 전기료 상승으로 철강사의 비용 부담이 증가하고 중국 정부의 경기 부양책에도 전방 산업\\n회복이 지연되며 \\'25년 철강사의 실적 개선폭은 제한적일 전망\\n\\n\\n## 조선 3Q 양호한 성장세, 그러나 중국 생산능력 확대에 따른 영향 우려\\n\\n• \\'24년 대량 수주에 의한 기저효과로 인해 내년 신조 수주는 둔화될 것으로 예상되는 가운데 중국\\n조선소의 증설로 글로벌 수주 경쟁이 심화되며 선가가 하락할 전망\\n\\n• 선가 하락으로 인해 \\'27년 이후 인도될 물량의 수익성 악화가 예상되며, 증설을 바탕으로 한 중국\\n조선소의 가격 우위 전략으로 인해 국내 조선소의 영업환경이 악화될 우려\\n\\n\\n## 유통 \"불황기, 고객은 떠나도 팬은 떠나지 않는다.\"\\', 팬덤 경제 확산과 영향\\n\\n• \\'팬덤 경제\\'는 특정 대상을 향한 유대감과 열정이 창출하는 경제적 가치를 의미하며, 최근 디지털\\n플랫폼 및 인프라 발달, 가치 소비 확산, 모바일 보편화, 팬덤의 집단적 소비 행태 등에 따라 확대\\n\\n• 팬덤 경제 기반의 커머스 플랫폼은 팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스 등이 존재하며, 팬덤\\n경제는 경기에 비교적 둔감한 특성을 지녀 소비 위축 시기에 새로운 성장 기회를 제공할 것으로 기대\\n\\n\\n<figure>\\n\\n<!-- PageFooter=\"ㅎ 하나은행 하나금융연구소\" -->\\n\\n</figure>\\n\\n\\n<!-- PageBreak -->\\n\\n',\n",
       " 2: '\\n# 산업 이슈\\n\\n철강\\n철강업, 원가 부담 가중되고 업황 정체에 따른 실적 회복 시기 지연\\n\\n조선\\n3Q 양호한 성장세, 그러나 중국 생산능력 확대에 따른 영향 우려\\n\\n유통\\n\"불황기, 고객은 떠나도 팬은 떠나지 않는다.\"\\n팬덤 경제 확산과 영향\\n\\n<!-- PageBreak -->\\n\\n',\n",
       " 3: '<!-- PageHeader=\"하나 산업정보 Hana Industry Info.\" -->\\n\\n\\n## C24. 철강 철강업, 원가 부담 가중되고 업황 정체에 따른 실적 회복 시기 지연\\n\\n연구원 이예린\\n\\n※ Summary : 장기화되는 건설 경기 침체와 중국발 철강 공급 과잉 문제가 지속되며 철강사들의\\n3분기 실적도 여전히 부진할 것으로 예상. 철강업의 대내외 리스크 요인이 해소되지 않은 가운데,\\n산업용 전기 요금 인상 조치로 전기로 투자를 확대해 운영하고 있는 철강사들의 재무 부담이 가중되며\\n4분기에도 수익성 개선은 어려울 것으로 예상. 자동차·건설업의 수요 둔화와 중국 정부의 적극적인 경기\\n부양책에도 중국 내수 수요 회복이 지연되며 공급 과잉이 지속될 것으로 예상되어 \\'25년 철강사의 실적\\n개선폭은 제한적일 전망\\n\\n■ 건설업 등 전방 수요 부진 및 중국 경기 침체로 철강업 불황 장기화되며 3분기 실적 저하\\n\\n● 건설 시장 침체가 지속되는 가운데, 중국 내수 부진 및 글로벌 대중 보호무역주의\\n확산 등으로 중국산 철강의 국내 시장 잠식이 심화되며 철강업 실적 회복이 지연\\n\\\\- \\'24.3Q 기준 중국 철강 수입량은 전년동기대비 4.8% 증가하며 국내 철강 가격 약세가 지속\\n\\n● 포스코, 현대제철 등 주요 철강 4개사의 3분기 합산 매출액은 전년 동기대비 7.4%\\n하락하였고 합산 영업이익률은 3%p 하락한 3.4%로 추정\\n\\n\\\\- 포스코홀딩스 철강 사업 부문의 3분기 영업이익은 전년동기대비 45.5% 하락하였고\\n현대제철의 영업이익은 전년동기대비 64%가 하락\\n\\n● 중국發 밀어내기 수출 영향이 지속되고 중국의 경기부양책에 따른 철광석 등 원자재\\n가격 상승과 산업용 전기 요금 인상 조치까지 더해지며 철강사의 재무 부담이 확대\\n\\n\\n<figure>\\n<figcaption>그림1 | 글로벌 철강 수요 추이 및 전망</figcaption>\\n\\n19\\n\\n(억톤)\\n\\n철강 수요(좌)\\n\\n(YoY, %)\\n\\n4\\n\\n2.8\\n\\nQ\\n\\n증가율(우)\\n\\n1.2\\n\\n2\\n\\n18\\n\\nO\\n\\n-0.8\\n\\n-0.9\\n\\n0\\n\\n·\\n\\n.\\n\\n17\\n\\n-3.1\\n\\n-2\\n\\nO\\n\\n16\\n\\n-4\\n\\n\\'21\\n\\n\\'22\\n\\n\\'23\\n\\n\\'24P\\n\\n\\'25E\\n\\n</figure>\\n\\n자료 : WSA\\n\\n\\n<figure>\\n<figcaption>그림2 | 주요 철강 3개사의 3분기 실적</figcaption>\\n\\n12,000\\n\\n(십억원)\\n\\n매출액(좌)\\n\\n영업이익률(우)\\n\\n(%)\\n\\n12\\n\\n10,000\\n\\n9.8\\n\\nO\\n\\n10\\n\\n8,000\\n\\n7.5\\n\\n8\\n\\n6,000\\n\\n4.6\\n\\n6\\n\\n4,000\\n\\n3.6\\n\\n2.6\\n\\n4\\n\\n2,000\\n\\n0.7\\n\\n2\\n\\n0\\n\\n0\\n\\n23.3Q\\n\\n24.3Q\\n\\n23.3Q\\n\\n24.3Q\\n\\n23.3Q\\n\\n24.3Q\\n\\n포스코\\n\\n현대제철\\n\\n동국제강\\n\\n</figure>\\n\\n\\n자료 : 각 사 IR 자료\\n\\n<!-- PageFooter=\"Hana Bank Hana institute of Finance\" -->\\n<!-- PageBreak -->\\n\\n',\n",
       " 4: '<!-- PageHeader=\"하나 산업정보 Hana Industry Info.\" -->\\n\\n■ 철강업계, 전기료 인상으로 비용 부담 증가하며 4분기 수익성 개선도 어려울 것으로 예상\\n\\n● 10월 24일부터 산업용 전기 평균 요금이 9.7% 인상되며 그린 철강 전환을 위해 전기로\\n투자를 확대·운영하고 있는 철강업계의 원가 부담이 크게 증가\\n\\n\\\\- 대기업 기준 전기요금이 16.9/1kWh 인상되며 철강업의 원가 부담은 약 3,400억원 증가할 것으로 예상\\n\\n● 4분기 전기료 인상으로 11월 철근 기준가격은 전월대비 1만원 상승할 예정이나 소폭\\n상승했던 유통시세 가격은 10월 하락하며 전기로 제강사들의 실적 부담이 가중\\n\\n\\\\- 철근 유통 가격이 철스크랩보다 큰 폭으로 하락하며 스프레드가 축소되어 제강사 수익성이 더욱 악화\\n\\n\\\\- 철근 유통가(원/kg): 855(\\'23.10) → 784(\\'24.1) → 743(\\'24.4) → 804(\\'24.9) → 754(\\'24.10)\\n\\n● 전기료 인상에 따른 생산비 부담이 제품 가격으로 전이되면 중국산 저가 철강재와의 가격 경쟁력이\\n하락해 철강사들의 수익성이 더욱 악화될 가능성도 존재\\n\\n■ 수요 산업 부진 및 중국발 리스크 요인이 해소되지 않으며 실적 정체가 \\'25년에도 지속될 전망\\n\\n● 미국, 유럽 등 주요국의 철강 수요 증가에도 철강 최대 소비국인 중국의 수요\\n역성장이 지속되며 \\'25년 세계 철강 산업은 1.2%의 저성장에 그칠 전망\\n\\n\\\\- 국가별 철강 수요 증가율 전망: (중국)-1.0% (미국)2.0% (한국)-0.6% (일본)1.7% (EU&UK)3.5%\\n\\n● 中정부가 잇달아 경기 부양책을 발표하고 있으나, 철강업의 구조적 문제와 부양 정책\\n규모(2.7조위안) 등을 고려할 때 실질적인 전방 수요 회복 효과는 제한적일 것으로 예상\\n\\n\\\\- 철강 수요 회복에 대한 기대감으로 철광석 및 철강재 가격이 반등했으나 단기 상승으로 그침\\n\\n● 견조한 조선향 후판 수요에도 불구하고 건설·자동차향 내수 부진과 중국 공급 과잉\\n이슈 지속 등으로 인해 \\'25년 철강사의 실적 개선폭은 매우 제한적 ㅎ\\n\\n\\n<figure>\\n<figcaption>그림3 | 철근 기준가격 및 유통가격 추이</figcaption>\\n\\n1,400\\n\\n(원/kg)\\n\\n기준가격\\n\\n유통가격\\n\\n1,200\\n\\n1,000\\n\\n800\\n\\n600\\n\\n400\\n\\n\\'20\\n\\n\\'21\\n\\n\\'22\\n\\n\\'23\\n\\n\\'24\\n\\n</figure>\\n\\n주 : 철근SD400 가격 기준, 유통가격은 도매 즉시현금가 기준\\n\\n자료 : 스틸데일리\\n\\n\\n<figure>\\n<figcaption>그림4 | 국내 철강업체 실적 전망</figcaption>\\n\\n150\\n\\n(조원)\\n\\n11.0\\n\\n––매출액(좌)\\n\\n(%)\\n\\n12\\n\\n영업이익률(우)\\n\\n130\\n\\n10\\n\\n8\\n\\n110\\n\\n6.3\\n\\n5.2\\n\\n5.4\\n\\n6\\n\\n4.4\\n\\n90\\n\\n2.7\\n\\n4\\n\\n70\\n\\n2\\n\\n\\'20\\n\\n\\'21\\n\\n\\'22\\n\\n\\'23\\n\\n\\'24P\\n\\n\\'25E\\n\\n</figure>\\n\\n주 : 1차 철강 제조업 외감 이상 합산 기준\\n\\n자료 : Value Search, 하나금융연구소\\n\\n\\n<!-- PageFooter=\"ㅎ 하나은행 하나금융연구소\" -->\\n<!-- PageBreak -->\\n\\n',\n",
       " 5: '<!-- PageHeader=\"HIF 월간 산업 이슈 Monthly Industrial Issue.\" -->\\n\\n\\n## C31. 조선 3Q 양호한 성장세, 그러나 중국 생산능력 확대에 따른 영향 우려\\n\\n연구원 김종현\\n\\n※ Summary : 환경규제에 따른 노후선 교체 수요로 인해 전 세계 \\'24년 9월 누적 신조선 수주\\n실적은 \\'08년 이후 최대치를 기록. \\'24년 대량 수주에 의한 기저효과로 인해 내년 신조 수주는 둔화될\\n것으로 예상되는 가운데 중국 조선소의 증설로 글로벌 수주 경쟁이 심화되며 선가가 하락할 전망. 수주 시점의\\n선가는 선박 인도시기의 실적에 영향을 미치므로 선가 하락이 단기 실적에 미칠 영향은 미미한 상황. 그러나\\n\\'27년 이후 중국 조선소의 가격 우위 전략으로 인해 수주 경쟁이 심화되며 국내 조선소의 영업 경쟁력이\\n하락할 우려가 있어 이에 대한 국내 조선소의 대응 전략을 모니터링할 필요\\n\\n\\n### ■ 환경규제에 따른 노후선 교체 수요로 인해 \\'24년 9월 누적 수주 실적은 \\'08년 이후 최대치\\n\\n● 환경규제에 따른 노후선 교체 수요를 바탕으로 \\'24년 9월 누적 수주 실적은 전년 동기\\n대비 40.4% 증가하였으며 \\'08년 이후 최대 수주 실적을 기록\\n\\n\\\\- \\'24년 9월 누적 선종별 수주 증가율 (%, YOY) : LNG선 96.3%, 컨테이너 84.3%, 탱커 48.7%\\n\\n● 동기간 중국은 조선소 설비 확장 및 저가 수주를 바탕으로 한 공격적 영업 활동을 통해\\n수주 점유율이 69.0%에 달하였고 한국은 LNG선을 중심으로 수주하며 점유율 18.6% 기록\\n\\\\- \\'24년 9월 누적 국가별 수주 증가율 (%, YOY) : 중국 68.4%, 한국 26.6%, 일본 - 53.1%\\n\\n● 한편, 국내 주요 조선사의 수주 점유율은 다소 약화되었으나 \\'24년 3분기 실적은 旣\\n수주 물량의 인도를 바탕으로 양호한 실적을 기록하였으며 내년도 실적도 긍정적일 전망\\n\\\\- 대형 조선3사의 \\'24년 3분기 누적 합산 실적은 YOY 기준 매출액 23.5%, 영업이익률은 1.5%p 증가\\n\\n\\n<figure>\\n<figcaption>그림5 | 글로벌 신조선 수주량 추이</figcaption>\\n\\n80\\n\\n(백만CGT)\\n\\n70\\n\\n\\'08.9\\n\\n\\'24.9\\n\\n60\\n\\n5,361만CGT\\n\\n4,976만CGT\\n\\n50\\n\\nㅇ\\n\\n40\\n\\n30\\n\\n20\\n\\n10\\n\\n0\\n\\n04.9\\n\\n\\'09.9\\n\\n\\'14.9\\n\\n\\'19.9\\n\\n\\'24.9\\n\\n</figure>\\n\\n주 : YTD 기준\\n\\n자료 : Clarkson, 하나금융연구소\\n\\n\\n<figure>\\n<figcaption>그림6 | 국내 조선사 실적 추이</figcaption>\\n\\n13\\n\\n(조원)\\n\\n매출액(좌)\\n\\n(%)\\n\\n6\\n\\n영업이익률(우)\\n\\n5\\n\\n11\\n\\n4\\n\\n3\\n\\n9\\n\\n2\\n\\n7\\n\\n1\\n\\n0\\n\\n5\\n\\n-1\\n\\n\\'23.1Q \\'23.2Q \\'23.3Q \\'23.4Q \\'24.1Q \\'24.2Q \\'24.3Q\\n\\n</figure>\\n\\n주:한국조선해양, 삼성중공업, 한화오션 합산 실적\\n\\n자료 : Valuesearch, 각사 IR, 하나금융연구소\\n\\n\\n<!-- PageNumber=\"5\" -->\\n<!-- PageFooter=\"Hana Bank Hana Institute of Finance\" -->\\n<!-- PageBreak -->\\n\\n',\n",
       " 6: '<!-- PageHeader=\"HIF 월간 산업 이슈 Monthly Industrial Issue.\" -->\\n\\n■ 기저효과에 따른 신조 수주 둔화와 中 조선소 증설로 수주 경쟁이 심화되며 선가 하락 전망\\n\\n● \\'24년 대량 수주에 따른 기저효과로 인해 수주 둔화가 예상되며 이에 더하여 신조선\\n대량 유입에 따른 선박 공급 과잉과 환경규제 영향으로 인해 향후 선가 하락이 불가피할 전망\\n\\\\- 신조선보다 중고선의 가격 변동성이 더 큰 가운데 신조가 하락은 중고가 하락으로 이어지\\n면서 중고선가 낙폭이 확대됨에 따라 중고선의 담보가치가 하락할 우려\\n\\n● \\'21년부터 \\'24년 3분기까지 발표된 글로벌 조선사들의 캐파 확대 계획 규모는 총 820만\\nCGT로, 이 중 재가동은 약 390만 CGT, 신규 증설은 약 440만 CGT (Clarksons)\\n\\n\\\\- \\'20년 글로벌 조선소 총 캐파는 약 4천만 CGT로, \\'30년까지 \\'20년 대비 약 11% 확대 예정\\n\\n● 이 중 중국이 약 77%를 차지하며 글로벌 조선소 증설의 대부분을 견인할 예정이며,\\n중국의 신규 증설 규모는 약 340만 CGT, 재가동 규모는 약 290만 CGT로 추정\\n\\n\\n### ■ 선가 하락의 단기 영향은 미미하나 \\'27년부터 중국과의 가격 경쟁 심화로 국내 조선소의 영업환경 악화 우려\\n\\n● 현재 국내 조선소의 수주잔량을 살펴보면 \\'25, \\'26년 물량은 모두 확보한 상황이므로\\n선가 하락에 따른 수익성 약화는 \\'27년도 수주 물량부터 본격화될 전망\\n\\\\- 국내 조선소의 연도별 수주잔량 (백만CGT) : 12.4(\\'25) → 10.2(\\'26) → 9.0+α (\\'27) → 3.0+α (\\'28)\\n\\n● 국내 조선소의 핵심 수주 선종은 컨테이너선과 LNG선으로 기술 우위 전략을 통해 시장을\\n선점하였으나 최근 중국과의 기술 격차 축소로 인해 해당 선종에서도 경쟁이 심화\\n\\n● 기술 격차 축소로 가격 경쟁력이 더욱 부각되며 中 조선소의 증설과 이에 따른 韓-中 간\\n가격 경쟁력 격차가 확대되면서 국내 조선소의 영업력 악화가 고착화될 우려\\n\\n● 국내 조선사의 주요 수주 선종인 LNG선, LPG선 등에 미치는 영향은 다소 제한적이나\\n중국의 주요 증설 계획이 집중된 벌크선, 탱커, 컨테이너선에서 영향이 클 전망\\nっ\\n\\n\\n<table>\\n<caption>표1 | 중국 조선소의 증설 동향</caption>\\n<tr>\\n<th>조선소</th>\\n<th>가동 예상일</th>\\n<th>생산규모 (CGT)</th>\\n<th>주요 선종</th>\\n</tr>\\n<tr>\\n<td>Hengli SB</td>\\n<td>2026</td>\\n<td>831,000</td>\\n<td>벌크, 탱커</td>\\n</tr>\\n<tr>\\n<td>Wison Qidong</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>해양플랜트</td>\\n</tr>\\n<tr>\\n<td>YangzijIang Holdings</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>LNG선</td>\\n</tr>\\n<tr>\\n<td>New Times SB</td>\\n<td>2026</td>\\n<td>882,00</td>\\n<td>탱커, 컨테이너</td>\\n</tr>\\n<tr>\\n<td>Hantong WinG HI</td>\\n<td>2026</td>\\n<td>37,000</td>\\n<td>Ultramaxes</td>\\n</tr>\\n<tr>\\n<td>CMCS</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>크루즈, 여객선</td>\\n</tr>\\n<tr>\\n<td>Shanghai Waigaoqiao</td>\\n<td>2025</td>\\n<td>973,000</td>\\n<td>컨테이너, 탱커</td>\\n</tr>\\n<tr>\\n<td>COSCO HI (Zhoushan)</td>\\n<td>2026</td>\\n<td>384,000</td>\\n<td>벌크</td>\\n</tr>\\n<tr>\\n<td>Chizhou Guichi</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>연안 소형선박</td>\\n</tr>\\n</table>\\n\\n자료 : Clarkson, SK 증권\\n\\n\\n<figure>\\n<figcaption>그림7 | 선종별 한-중 수주량 비교 (\\'24.9 YTD 기준)</figcaption>\\n\\n16\\n\\n(백만CGT)\\n\\n■ 한국 ■ 중국\\n\\n14\\n\\n12\\n\\n10\\n\\n8\\n\\n6\\n\\n4\\n\\n2\\n\\n0\\n\\n컨테이너\\n\\n탱커\\n\\n벌크\\n\\nLNG선\\n\\n기타\\n\\n</figure>\\n\\n\\n자료 : Clarkson, 하나금융연구소\\n\\n\\n<figure>\\n\\n<!-- PageFooter=\"ㅎ 하나은행 하나금융연구소\" -->\\n<!-- PageNumber=\"6\" -->\\n\\n</figure>\\n\\n\\n<!-- PageBreak -->\\n\\n',\n",
       " 7: '<!-- PageHeader=\"HIF 월간 산업 이슈 Monthly Industrial Issue.\" -->\\n\\n\\n### G. 유통업 \"불황기, 고객은 떠나도 팬은 떠나지 않는다.\", 팬덤 경제 확산과 영향\\n\\n연구위원 김문태\\n\\n※ Summary : \\'팬덤 경제\\'는 특정 대상을 향한 유대감과 열정이 창출하는 경제적 가치를 의미. 팬덤\\n경제는 최근 디지털 플랫폼 및 인프라 발달, 가치 소비 확산 등에 따라 확대. 팬덤 경제 기반의 플랫\\n폼으로는 1 위버스, 버블 등 K-pop 관련 콘텐츠, 굿즈 등을 판매하는 팬덤 플랫폼, 2 유튜브 쇼핑\\n과 같이 인플루언서의 실시간 소통을 통해 판매가 이루어지는 라이브커머스, 3 무신사, 오늘의 집 등\\n특정 분야에 대한 관심과 유대감으로 형성된 커뮤니티형 커머스가 존재. 이러한 팬덤 경제는 경기에\\n비교적 덜 민감하여 소비 위축 시기에 소비재·유통업체에게 새로운 성장 기회를 제공할 것으로 기대\\n\\n\\n#### ■ 디지털 발달, 가치 소비 등에 따라 특정 대상에 대한 호감에 기반을 둔 \\'팬덤 경제\\'가 확산\\n\\n● \\'24년 4월, 최고 트래픽 960만번으로 콘서트 전석(약 9만석) 매진을 기록한 가수 임영웅\\n의 영향력은 가요계뿐만 아니라 자동차, 건강식품 등 산업계의 매출 신장에도 기여\\n\\n\\\\- 2020년, 쌍용차의 \\'G4 렉스턴\\'은 임영웅을 모델로 내세우며 전월 대비 53%가 증가한 바 있으며,\\n건강식품 \\'정관장\\'은 \\'임영웅 효과\\'로 가정의 달 행사 7일 간 전년대비 신규 가입 고객이 72% 증가\\n\\n● \\'팬덤 경제\\'는 이처럼 좋아하는 대상(아티스트, 스포츠, 캐릭터 등)에 열정을 가지고 커뮤니\\n티를 형성하는 팬덤이 실질적으로 창출하는 경제적 가치와 관련 소비 행위를 지칭\\n\\n● 팬덤의 경제적 영향력은 최근 디지털 플랫폼 및 비대면 소통 인프라 발달, 개인적 취향에\\n중점을 둔 \\'가치 소비\\' 확산, 모바일 사용 보편화, 팬덤의 집단적 소비 등에 따라 확대\\n\\n\\\\- 코로나19 시기, 모바일 활용 확대와 비대면 소통 인프라 증가가 특히 긍정적으로 작용\\n\\n[G4 렉스턴 광고]\\n\\n\\n<figure>\\n<figcaption>그림8 | 가수 임영웅 광고 및 효과</figcaption>\\n\\n美\\n\\n</figure>\\n\\n\\n[정관장 가정의 달 행사]\\n\\n\\n<figure>\\n</figure>\\n\\n\\\\- 전월 대비 53% 판매 증가 – 신규 가입 고객 72% 증가\\n\\n\\n자료 : 각 사, 언론자료\\n\\n\\n<table>\\n<caption>표2 | 팬덤 경제 확산의 배경</caption>\\n<tr>\\n<th>구분</th>\\n<th>내용</th>\\n</tr>\\n<tr>\\n<td>디지털 플랫폼 성장</td>\\n<td>- SNS, 스트리밍 서비스의 글로벌 확산 - 유튜브, 틱톡 등으로 글로벌 팬덤 형성</td>\\n</tr>\\n<tr>\\n<td>인프라 발달</td>\\n<td>- 팬과 아티스트 간 글로벌 실시간 소통 가능 - 촬영 장비, 스튜디오 등 인프라 확충</td>\\n</tr>\\n<tr>\\n<td>모바일 사용 보편화</td>\\n<td>- 스마트폰 활용 연령 확대(고령층, 저연령층)로 취향 공유를 위한 커뮤니티가 확장됨</td>\\n</tr>\\n<tr>\\n<td>소비 트렌드 변화</td>\\n<td>- 차별화된 소비 경험에 대한 수요 확대 - 개인적 취향에 중점을 둔 가치 소비 확산</td>\\n</tr>\\n<tr>\\n<td>팬덤의 집단적 소비 행태</td>\\n<td>- 자신이 속한 팬덤 커뮤니티의 목표나 가치에 따른 능동적인 경제 행위(대량 구매 등)를 나타냄</td>\\n</tr>\\n</table>\\n\\n자료 : 하나금융연구소\\n\\n\\n<!-- PageFooter=\"Hana Bank Hana Institute of Finance\" -->\\n<!-- PageNumber=\"7\" -->\\n<!-- PageBreak -->\\n\\n',\n",
       " 8: '<!-- PageHeader=\"HIF 월간 산업 이슈 Monthly Industrial Issue.\" -->\\n\\n\\n#### ■ 팬덤 경제 기반의 플랫폼은 팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스 등이 존재\\n\\n● 가장 직접적인 팬덤 기반 사업 모델은 K-pop 관련 ‘팬덤 플랫폼\\'으로, 과거 ‘팬클럽\\'\\n이 엔터 산업 고도화 및 모바일 기술 발달로 팬덤 경제에 특화된 플랫폼으로 변화\\n\\n\\\\- 대표적으로 하이브 위버스, 디어유(SM) 버블이 있으며, 위버스는 아티스트 영상, 커뮤니티를\\n중심으로 굿즈 판매 연계, 버블은 아티스트와의 채팅을 유료 회원에게 제공하는 것이 특징\\n\\n● 또한, 인플루언서와의 유대감이 중요한 라이브커머스 시장은 \\'20년 4천억원에서 \\'23년\\n10조원 규모로 성장했으며, 지난해 유튜브의 커머스 기능 추가 이후 생태계 확장 중\\n\\n\\\\- \\'24.5월, 인스타그램은 크리에이터와 브랜드를 연결하는 \\'크리에이터 마켓플레이스\\'를 도입\\n\\n\\\\- 네이버, 카카오, 쿠팡 등은 기존 자체 제작 중심 모델에 오픈형 모델을 추가·확장하며 대응\\n\\n● \\'무신사\\', \\'오늘의 집\\' 등 콘텐츠를 통해 패션, 인테리어에 관심 많은 소비자를 확보한\\n\\'커뮤니티형 커머스\\'는 크리에이터 지원을 통해 콘텐츠 및 소비자 확대를 도모\\n\\n\\\\- 무신사 : 패션 커뮤니티 \\'스냅\\'의 크리에이터 \\'스냅 크루\\'에게 혜택 제공(활동비, 화보 촬영 등)\\n\\n\\\\- 오늘의 집 : 팬덤 및 창작자 커뮤니티 \\'오하우스\\'를 통해 크리에이터 활동을 지원\\n\\n\\n#### ■ 소비 위축 시기, 팬덤 기반의 수요 창출은 소비재 및 유통 기업에게 성장 기회를 제공\\n\\n● 글로벌 마케팅 전문가 데이비드 미어먼 스콧은 \"불황기, 고객은 떠나도 팬은 떠나지\\n않는다\"며 강력한 팬덤이 불황기에도 안정적인 사업 모델을 창출한다고 주장\\n\\\\- 이를 위해서는 정서적 유대감 유도로 커뮤니티를 만들고 그것을 \\'팬덤화\\'시키는 것이 중요\\n\\n● 고금리, 고물가로 소비 시장이 위축된 상황에서 팬덤을 통한 새로운 수요의 창출은\\n소비재 및 유통 기업에게 불황기를 극복할 수 있는 가능성을 제공할 것으로 기대\\n\\n\\\\- 팬덤 관련 커머스는 유대감과 소통을 통해 고객의 수요를 유발하는 \\'발견형 쇼핑\\'의 특성을\\n지녀 일반적인 \\'목적형 쇼핑\\' 대비 경기 민감도가 비교적 낮다는 특성을 지님\\nっ\\n\\n\\n<figure>\\n<figcaption>그림9 | 국내 라이브커머스 시장 규모</figcaption>\\n\\n12\\n\\n(조원)\\n\\n10\\n\\n8\\n\\n6\\n\\n4\\n\\n2\\n\\n0\\n\\n2020\\n\\n2021\\n\\n2022\\n\\n2023\\n\\n</figure>\\n\\n\\n자료 : Statista, 삼정KPMG 재인용\\n\\n\\n<table>\\n<caption>표3 | 쇼핑의 2가지 유형 : 목적형 쇼핑과 발견형 쇼핑</caption>\\n<tr>\\n<th>구분</th>\\n<th>목적형 쇼핑</th>\\n<th>발견형 쇼핑</th>\\n</tr>\\n<tr>\\n<td>정의</td>\\n<td>- 결핍(부족)에 의한 쇼핑 - 필요를 충족하기 위해 \\'목적\\' 대상을 구매하는 행위</td>\\n<td>- 욕망, 감성에 의한 쇼핑 - (외부 자극에 의해) 수요와 욕망을 \\'발견\\'하게 되면서 이루어지는 구매 행위</td>\\n</tr>\\n<tr>\\n<td>예시</td>\\n<td>- 가격 검색 및 비교 - 생필품 구매</td>\\n<td>- 백화점 쇼윈도 - 추천 상품 구매</td>\\n</tr>\\n<tr>\\n<td>소비 유발 요인</td>\\n<td>- 검색의 정확성, 편의성 - 낮은 가격 및 할인 혜택 - 상품 비교 용이성</td>\\n<td>- 취향에 적합한 추천 - 공감을 유발하는 스토리 - 관심 기반 커뮤니티</td>\\n</tr>\\n<tr>\\n<td>특징</td>\\n<td>- 소비 시장 대부분을 차지 - 구매력 하락, 소비 성향 저하 시기 구매가 위축됨</td>\\n<td>- 목적형 대비 적은 규모 - 감성적 소비 특성 상 불황 기에도 성장 가능</td>\\n</tr>\\n</table>\\n\\n자료 : 하나금융연구소\\n\\n\\n<figure>\\n\\n<!-- PageFooter=\"ㅎ 하나은행 하나금융연구소\" -->\\n<!-- PageNumber=\"8\" -->\\n\\n</figure>\\n\\n\\n<!-- PageBreak -->\\n\\n',\n",
       " 9: 'HIF 월간 산업 이슈\\nMonthly Industrial Issue.\\n\\n하나은행 하나금융연구소\\n\\n04538 서울특별시 중구 을지로 66\\n(을지로 2가, 하나금융그룹 명동사옥 8층)\\nTEL 02.2002.2200\\nE-MAIL hanaif@hanafn.com\\nhttp://www.hanaif.re.kr\\n'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_page_markdown(analyze_result: AnalyzeResult):\n",
    "    page_contents = dict()\n",
    "    for page in analyze_result.pages:\n",
    "\n",
    "        content = analyze_result.content[page.spans[0]['offset']: page.spans[0]['offset'] + page.spans[0]['length']]\n",
    "    \n",
    "        page_contents[page.page_number] = content\n",
    "\n",
    "    return page_contents\n",
    "\n",
    "page_content_list = extract_page_markdown(analyze_result)\n",
    "page_content_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM 모델 호출 함수 정의\n",
    "- llm_gpt4o_mini\n",
    "- llm_gpt4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "def llm_gpt4o_mini(temperature=0.0, streaming=False):\n",
    "    # os.environ['OPENAI_API_VERSION'] = os.getenv('AZURE_OPENAI_API_VERSION')\n",
    "    # print(f\"AZURE_OPENAI_API_VERSION: {os.getenv('AZURE_OPENAI_API_VERSION')}\")\n",
    "    # print(f\"OPENAI_API_VERSION: {os.getenv('OPENAI_API_VERSION')}\") #OPENAI_API_VERSION\n",
    "    \n",
    "    llm = AzureChatOpenAI(\n",
    "        api_key = os.getenv('AZURE_OPENAI_API_KEY'), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "        api_version = os.getenv('AZURE_OPENAI_API_VERSION'), # OpenAI API 버전을 설정합니다.\n",
    "        azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "        model= os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_GPT4MINI'), # 사용할 모델을 설정합니다.\n",
    "        streaming=streaming, # 스트리밍\n",
    "        temperature=temperature,\n",
    "    )    \n",
    "    return llm\n",
    "\n",
    "def llm_gpt4o(temperature=0.0, streaming=False):\n",
    "\n",
    "    # print(f\"AZURE_OPENAI_API_VERSION: {os.getenv('AZURE_OPENAI_API_VERSION')}\")\n",
    "    # print(f\"OPENAI_API_VERSION: {os.getenv('OPENAI_API_VERSION')}\") #OPENAI_API_VERSION\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        api_key = os.getenv('AZURE_OPENAI_API_KEY'), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "        api_version = os.getenv('AZURE_OPENAI_API_VERSION'), # OpenAI API 버전을 설정합니다.\n",
    "        azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT'), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "        model= os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME_GPT4O'), # 사용할 모델을 설정합니다.\n",
    "        streaming=streaming, # 스트리밍\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "페이지별 요약 정보 생성\n",
    "- summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: \"- 철강업:\\n  - 전방 수요 부진과 중국 경기 침체로 철강업 불황 장기화\\n  - 3분기 실적 저하, 산업용 전기료 상승으로 비용 부담 증가\\n  - '25년 실적 개선폭 제한적 전망\\n\\n- 조선업:\\n  - 3분기 양호한 성장세, 그러나 중국 조선소 증설로 글로벌 수주 경쟁 심화\\n  - 선가 하락으로 '27년 이후 인도 물량 수익성 악화 우려\\n  - 중국 조선소의 가격 우위 전략으로 국내 조선소 영업환경 악화 가능성\\n\\n- 유통업:\\n  - '팬덤 경제' 확산, 디지털 플랫폼 및 가치 소비 확산에 기인\\n  - 팬덤 경제 기반 커머스 플랫폼 존재, 경기 둔감 특성으로 소비 위축 시 성장 기회 제공 기대\",\n",
       " 2: '- 철강업: 원가 부담 증가, 업황 정체로 실적 회복 시기 지연\\n- 조선업: 3분기 양호한 성장세, 중국 생산능력 확대 영향 우려\\n- 유통업: 불황기에도 팬덤 경제 확산 및 영향',\n",
       " 3: \"- 철강업의 불황이 장기화되며 3분기 실적 저하 예상\\n  - 건설 경기 침체와 중국발 철강 공급 과잉 지속\\n  - '24.3Q 중국 철강 수입량 전년 동기 대비 4.8% 증가\\n  - 국내 철강 가격 약세 지속\\n\\n- 주요 철강사들의 3분기 실적 부진\\n  - 포스코, 현대제철 등 4개사 매출액 전년 동기 대비 7.4% 하락\\n  - 합산 영업이익률 3%p 하락하여 3.4%로 추정\\n  - 포스코홀딩스 영업이익 전년 동기 대비 45.5% 하락\\n  - 현대제철 영업이익 전년 동기 대비 64% 하락\\n\\n- 중국의 밀어내기 수출과 경기부양책 영향\\n  - 철광석 등 원자재 가격 상승\\n  - 산업용 전기 요금 인상으로 철강사 재무 부담 확대\\n\\n- '25년 철강사 실적 개선폭 제한적 전망\",\n",
       " 4: \"- 10월 24일부터 산업용 전기 평균 요금이 9.7% 인상되어 철강업계의 원가 부담이 증가.\\n  - 대기업 기준 전기요금이 16.9/1kWh 인상, 철강업의 원가 부담 약 3,400억원 증가 예상.\\n  \\n- 4분기 전기료 인상으로 11월 철근 기준가격 1만원 상승 예정, 유통시세 가격은 10월 하락.\\n  - 철근 유통 가격 하락으로 제강사 수익성 악화.\\n  - 철근 유통가(원/kg): 855('23.10) → 754('24.10).\\n\\n- 전기료 인상으로 중국산 저가 철강재와의 가격 경쟁력 하락 가능성.\\n\\n- 중국의 철강 수요 역성장 지속, '25년 세계 철강 산업 1.2% 저성장 전망.\\n  - 국가별 철강 수요 증가율 전망: 중국 -1.0%, 미국 2.0%, 한국 -0.6%, 일본 1.7%, EU&UK 3.5%.\\n\\n- 중국 정부의 경기 부양책에도 철강업의 구조적 문제로 실질적 수요 회복 효과 제한적.\\n\\n- '25년 철강사의 실적 개선폭 매우 제한적.\",\n",
       " 5: \"- 환경규제로 인한 노후선 교체 수요로 '24년 9월 누적 신조선 수주 실적이 '08년 이후 최대치 기록\\n- '24년 9월 누적 선종별 수주 증가율: LNG선 96.3%, 컨테이너 84.3%, 탱커 48.7%\\n- 중국 조선소의 수주 점유율 69.0%, 한국은 LNG선 중심으로 18.6% 기록\\n- '24년 9월 누적 국가별 수주 증가율: 중국 68.4%, 한국 26.6%, 일본 -53.1%\\n- 국내 대형 조선3사의 '24년 3분기 누적 합산 실적: 매출액 23.5% 증가, 영업이익률 1.5%p 증가\\n- 중국 조선소의 증설로 글로벌 수주 경쟁 심화, 선가 하락 전망\\n- '27년 이후 중국의 가격 우위 전략으로 국내 조선소의 영업 경쟁력 하락 우려\",\n",
       " 6: \"- '24년 대량 수주에 따른 기저효과로 수주 둔화 및 선가 하락 전망\\n- 글로벌 조선사들의 캐파 확대 계획: 총 820만 CGT ('21-'24년 3분기)\\n  - 재가동: 약 390만 CGT, 신규 증설: 약 440만 CGT\\n- 중국이 글로벌 조선소 증설의 77% 차지, 신규 증설: 약 340만 CGT, 재가동: 약 290만 CGT\\n- 국내 조선소의 수주잔량: '25년 12.4백만CGT, '26년 10.2백만CGT, '27년 9.0+α백만CGT, '28년 3.0+α백만CGT\\n- 기술 격차 축소로 韓-中 간 가격 경쟁 심화, 국내 조선소 영업환경 악화 우려\\n- 중국의 증설 계획이 집중된 벌크선, 탱커, 컨테이너선에서 영향 클 전망\\n- 주요 중국 조선소 증설 동향: Hengli SB, Wison Qidong, YangzijIang Holdings 등 2026년 가동 예정\",\n",
       " 7: \"- '팬덤 경제'는 특정 대상을 향한 유대감과 열정이 창출하는 경제적 가치를 의미하며, 디지털 플랫폼 및 인프라 발달, 가치 소비 확산 등에 따라 확대되고 있음.\\n- 팬덤 경제 기반의 플랫폼으로는 K-pop 관련 콘텐츠를 판매하는 위버스, 버블, 인플루언서의 실시간 소통을 통한 유튜브 쇼핑, 무신사, 오늘의 집 등 커뮤니티형 커머스가 있음.\\n- 팬덤 경제는 경기 불황 시에도 소비재·유통업체에게 새로운 성장 기회를 제공할 것으로 기대됨.\\n- 2024년 4월, 가수 임영웅은 최고 트래픽 960만번으로 콘서트 전석(약 9만석) 매진을 기록하며, 자동차, 건강식품 등 산업계의 매출 신장에 기여.\\n- 2020년, 쌍용차의 'G4 렉스턴'은 임영웅을 모델로 내세워 전월 대비 53% 판매 증가, 건강식품 '정관장'은 '임영웅 효과'로 신규 가입 고객이 72% 증가.\\n- 팬덤 경제의 확산 배경에는 디지털 플랫폼 성장, 인프라 발달, 모바일 사용 보편화, 소비 트렌드 변화, 팬덤의 집단적 소비 행태 등이 있음.\",\n",
       " 8: \"- 팬덤 경제 기반 플랫폼에는 팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스가 포함됨.\\n- K-pop 관련 팬덤 플랫폼으로는 하이브 위버스와 디어유(SM) 버블이 있으며, 위버스는 아티스트 영상 및 커뮤니티 중심으로 굿즈 판매를 연계하고, 버블은 아티스트와의 유료 채팅을 제공.\\n- 라이브커머스 시장은 2020년 4천억원에서 2023년 10조원 규모로 성장, 유튜브의 커머스 기능 추가로 생태계 확장 중.\\n- 2024년 5월, 인스타그램은 크리에이터와 브랜드를 연결하는 '크리에이터 마켓플레이스' 도입 예정.\\n- 네이버, 카카오, 쿠팡 등은 오픈형 모델을 추가·확장하여 대응.\\n- '무신사', '오늘의 집' 등은 커뮤니티형 커머스를 통해 패션, 인테리어에 관심 많은 소비자를 확보하고 크리에이터 지원을 통해 콘텐츠 및 소비자 확대를 도모.\\n- 글로벌 마케팅 전문가 데이비드 미어먼 스콧은 불황기에도 팬덤이 안정적인 사업 모델을 창출한다고 주장.\\n- 고금리, 고물가로 소비 시장이 위축된 상황에서 팬덤을 통한 새로운 수요 창출은 소비재 및 유통 기업에게 성장 기회를 제공.\\n- 팬덤 관련 커머스는 유대감과 소통을 통해 고객의 수요를 유발하는 '발견형 쇼핑'의 특성을 지님.\",\n",
       " 9: '- 발행 기관: 하나은행 하나금융연구소\\n- 위치: 서울특별시 중구 을지로 66, 하나금융그룹 명동사옥 8층\\n- 연락처: 전화번호 02.2002.2200, 이메일 hanaif@hanafn.com\\n- 웹사이트: http://www.hanaif.re.kr'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.documents import Document # LangChain 코어의 Document 클래스를 가져옵니다.\n",
    "\n",
    "\"\"\"\n",
    "문장을 아래의 요청에 따라 요약해 주십시오.\n",
    "\n",
    "요청:\n",
    "\n",
    "1. 주요 내용을 bullet point로 요약하십시오.\n",
    "2. 요약은 본문의 언어와 동일하게 작성하십시오.\n",
    "3. 기술 용어는 번역하지 마십시오.\n",
    "4. 불필요한 정보를 포함하지 마십시오.\n",
    "5. 요약에는 중요한 엔터티와 수치 정보를 포함해야 합니다.\n",
    "본문: {context}\n",
    "\n",
    "요약:\n",
    "\"\"\"\n",
    "\n",
    "# 문서 요약 체인 생성\n",
    "def create_text_summary_chain():\n",
    "    # 요약을 위한 프롬프트 템플릿을 정의합니다.\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"Please summarize the sentence according to the following REQUEST.\n",
    "        \n",
    "    REQUEST:\n",
    "    1. Summarize the main points in bullet points.\n",
    "    2. Write the summary in same language as the context.\n",
    "    3. DO NOT translate any technical terms.\n",
    "    4. DO NOT include any unnecessary information.\n",
    "    5. Summary must include important entities, numerical values.\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "\n",
    "    SUMMARY:\"\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # ChatOpenAI 모델의 또 다른 인스턴스를 생성합니다. (이전 인스턴스와 동일한 설정)\n",
    "    llm = llm_gpt4o()\n",
    "\n",
    "    # 문서 요약을 위한 체인을 생성합니다.\n",
    "    # 이 체인은 여러 문서를 입력받아 하나의 요약된 텍스트로 결합합니다.\n",
    "    text_summary_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    return text_summary_chain\n",
    "\n",
    "# 페이지별 문서 요약 생성\n",
    "def create_page_summary(page_contents):\n",
    "    content_summary = dict()\n",
    "\n",
    "    inputs = [\n",
    "        {\"context\": [Document(page_content=text)]}\n",
    "        for page_num, text in page_contents.items()\n",
    "    ]\n",
    "\n",
    "    # 요약 체인 생성\n",
    "    content_summary_chain = create_text_summary_chain()\n",
    "\n",
    "    # text_summary_chain을 사용하여 일괄 처리로 요약을 생성합니다.\n",
    "    summaries = content_summary_chain.batch(inputs)\n",
    "\n",
    "    # 생성된 요약을 페이지 번호와 함께 딕셔너리에 저장합니다.\n",
    "    for page_num, summary in enumerate(summaries):\n",
    "        content_summary[page_num+1] = summary\n",
    "\n",
    "    return content_summary\n",
    "\n",
    "summary_list = create_page_summary(page_content_list)\n",
    "summary_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서에서 이미지를 추출하여 이미지 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF # PyMuPDF 모듈을 가져옵니다. PDF 처리에 사용됩니다.\n",
    "import mimetypes # MIME 타입을 추측하기 위한 모듈을 가져옵니다.\n",
    "from mimetypes import guess_type # 파일의 MIME 타입을 추측하는 함수를 가져옵니다.\n",
    "from PIL import Image # 이미지 처리를 위한 PIL 모듈을 가져옵니다.\n",
    "\n",
    "\n",
    "# 이미지 출력 폴더 생성\n",
    "def ensure_output_folder(output_folder):\n",
    "    \"\"\"\n",
    "    출력 폴더가 존재하지 않으면 생성하고, 쓰기 권한을 확인합니다.\n",
    "\n",
    "    Args:\n",
    "        output_folder (str): 출력 폴더 경로.\n",
    "\n",
    "    Raises:\n",
    "        PermissionError: 폴더에 대한 쓰기 권한이 없는 경우.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        try:\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "            print(f\"Created output folder: {output_folder}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating output folder {output_folder}: {e}\")\n",
    "            raise\n",
    "    if not os.access(output_folder, os.W_OK):\n",
    "        raise PermissionError(f\"No write permission for the output folder: {output_folder}\")\n",
    "    \n",
    "def crop_image_from_image(image_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops an image based on a bounding box.\n",
    "\n",
    "    :param image_path: Path to the image file.\n",
    "    :param page_number: The page number of the image to crop (for TIFF format).\n",
    "    :param bounding_box: A tuple of (left, upper, right, lower) coordinates for the bounding box.\n",
    "    :return: A cropped image.\n",
    "    :rtype: PIL.Image.Image\n",
    "    \"\"\"\n",
    "    with Image.open(image_path) as img:\n",
    "        if img.format == \"TIFF\":\n",
    "            # Open the TIFF image\n",
    "            img.seek(page_number)\n",
    "            img = img.copy()\n",
    "            \n",
    "        # The bounding box is expected to be in the format (left, upper, right, lower).\n",
    "        cropped_image = img.crop(bounding_box)\n",
    "        return cropped_image\n",
    "    \n",
    "def crop_image_from_pdf_page(pdf_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops a region from a given page in a PDF and returns it as an image.\n",
    "\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param page_number: The page number to crop from (0-indexed).\n",
    "    :param bounding_box: A tuple of (x0, y0, x1, y1) coordinates for the bounding box.\n",
    "    :return: A PIL Image of the cropped area.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    \n",
    "    # Cropping the page. The rect requires the coordinates in the format (x0, y0, x1, y1).\n",
    "    # PDF 좌표계에서 1포인트는 1/72인치로 정의됩니다. \n",
    "    # 따라서, PDF의 경계 상자 좌표는 72 DPI(Dots Per Inch) 해상도를 기준으로 합니다.\n",
    "    bbx = [x * 72 for x in bounding_box]\n",
    "    rect = fitz.Rect(bbx)\n",
    "\n",
    "    # 이미지를 처리할 때는 더 높은 해상도, 예를 들어 300 DPI를 사용하는 경우가 많습니다. \n",
    "    # 이러한 해상도 차이를 보정하기 위해 경계 상자의 좌표를 변환해야 합니다.\n",
    "    # 예를 들어, 300 DPI 해상도로 이미지를 렌더링할 경우, 좌표를 변환하기 위해 300/72, 즉 약 4.17을 곱합니다. \n",
    "    # 이렇게 하면 PDF 좌표계의 포인트 단위가 이미지의 픽셀 단위와 정확히 일치하게 되어, 경계 상자가 올바른 위치와 크기로 적용됩니다.\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72), clip=rect)\n",
    "    \n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    doc.close()\n",
    "\n",
    "    return img\n",
    "\n",
    "def crop_image_from_file(file_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crop an image from a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "        page_number (int): The page number (for PDF and TIFF files, 0-indexed).\n",
    "        bounding_box (tuple): The bounding box coordinates in the format (x0, y0, x1, y1).\n",
    "\n",
    "    Returns:\n",
    "        A PIL Image of the cropped area.\n",
    "    \"\"\"\n",
    "    mime_type = mimetypes.guess_type(file_path)[0]\n",
    "    \n",
    "    if mime_type == \"application/pdf\":\n",
    "        return crop_image_from_pdf_page(file_path, page_number, bounding_box)\n",
    "    else:\n",
    "        return crop_image_from_image(file_path, page_number, bounding_box)\n",
    "    \n",
    "\n",
    "def image_cropp(image_region, image_idx, input_file_path, output_folder, file_name):\n",
    "    boundingbox = (\n",
    "        image_region.polygon[0],  # x0 (left)\n",
    "        image_region.polygon[1],  # y0 (top)\n",
    "        image_region.polygon[4],  # x1 (right)\n",
    "        image_region.polygon[5]   # y1 (bottom)\n",
    "    )\n",
    "    cropped_image = crop_image_from_file(input_file_path, image_region.page_number - 1, boundingbox) # page_number is 1-indexed\n",
    "    \n",
    "    # Get the base name of the file\n",
    "    base_name = os.path.basename(input_file_path)\n",
    "    # Remove the file extension\n",
    "    file_name_without_extension = os.path.splitext(base_name)[0]\n",
    "    \n",
    "    output_file = f\"{file_name_without_extension}_cropped_{file_name}_{image_idx}.png\"\n",
    "    # output_file = f\"{file_name_without_extension}_cropped_image_{image_idx}.png\"\n",
    "    cropped_image_filename = os.path.join(output_folder, output_file)\n",
    "    cropped_image.save(cropped_image_filename)\n",
    "    return cropped_image_filename\n",
    "\n",
    "\n",
    "#이미지 자르고 저장, 이미지 경로, 이미지 캡션 정보, 이미지가 속한 페이지 정보 저장\n",
    "def create_image_cropp_info(analyze_result_info: AnalyzeResult, input_file_path, output_folder):\n",
    "    image_cropped_info = []\n",
    "    ensure_output_folder(output_folder)\n",
    "    for idx, figure in enumerate(analyze_result_info.figures):\n",
    "        caption_content = \"\"\n",
    "        page_num = 0\n",
    "        if figure.caption: # 이미지의 캡션 정보가 있으면 추출\n",
    "            caption_content = figure.caption.content\n",
    "            caption_region = figure.caption.bounding_regions\n",
    "            \n",
    "            for region in figure.bounding_regions:\n",
    "                if region not in caption_region and len(region.polygon) >= 6: # 너무 작은 이미지는 제외\n",
    "                    page_num = region.page_number                    \n",
    "                    cropped_image_filename = image_cropp(region, idx, input_file_path, output_folder, \"image\")                    \n",
    "                    print(f\"cropped_image_filename: {cropped_image_filename}\")\n",
    "        else:\n",
    "            for region in figure.bounding_regions:\n",
    "                if len(region.polygon) >= 6:\n",
    "                    page_num = region.page_number\n",
    "                    cropped_image_filename = image_cropp(region, idx, input_file_path, output_folder, \"image\")\n",
    "                    print(f\"cropped_image_filename: {cropped_image_filename}\")\n",
    "\n",
    "        image_data = {\n",
    "            \"id\": idx, # 이미지 인덱스\n",
    "            \"page_number\": page_num, # 이미지가 속한 페이지 번호\n",
    "            \"image\": cropped_image_filename, # 이미지 경로와 파일명\n",
    "            \"caption\": caption_content # 이미지 캡션\n",
    "        }\n",
    "        image_cropped_info.append(image_data)\n",
    "    return image_cropped_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서에서 추출한 이미지를 'data\\image_cropped' 폴더에 저장 (차트 등의 표를 제외한 모든 이미지)\n",
    "- image_cropped_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output folder: data\\image_cropped\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_0.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_1.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_2.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_3.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_4.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_5.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_6.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_7.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_8.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_9.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_10.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_11.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_12.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'page_number': 1,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_0.png',\n",
       "  'caption': ''},\n",
       " {'id': 1,\n",
       "  'page_number': 3,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_1.png',\n",
       "  'caption': '그림1 | 글로벌 철강 수요 추이 및 전망'},\n",
       " {'id': 2,\n",
       "  'page_number': 3,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_2.png',\n",
       "  'caption': '그림2 | 주요 철강 3개사의 3분기 실적'},\n",
       " {'id': 3,\n",
       "  'page_number': 4,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_3.png',\n",
       "  'caption': '그림3 | 철근 기준가격 및 유통가격 추이'},\n",
       " {'id': 4,\n",
       "  'page_number': 4,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_4.png',\n",
       "  'caption': '그림4 | 국내 철강업체 실적 전망'},\n",
       " {'id': 5,\n",
       "  'page_number': 5,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_5.png',\n",
       "  'caption': '그림5 | 글로벌 신조선 수주량 추이'},\n",
       " {'id': 6,\n",
       "  'page_number': 5,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_6.png',\n",
       "  'caption': '그림6 | 국내 조선사 실적 추이'},\n",
       " {'id': 7,\n",
       "  'page_number': 6,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_7.png',\n",
       "  'caption': \"그림7 | 선종별 한-중 수주량 비교 ('24.9 YTD 기준)\"},\n",
       " {'id': 8,\n",
       "  'page_number': 6,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_8.png',\n",
       "  'caption': ''},\n",
       " {'id': 9,\n",
       "  'page_number': 7,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_9.png',\n",
       "  'caption': '그림8 | 가수 임영웅 광고 및 효과'},\n",
       " {'id': 10,\n",
       "  'page_number': 7,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_10.png',\n",
       "  'caption': ''},\n",
       " {'id': 11,\n",
       "  'page_number': 8,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_11.png',\n",
       "  'caption': '그림9 | 국내 라이브커머스 시장 규모'},\n",
       " {'id': 12,\n",
       "  'page_number': 8,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_image_12.png',\n",
       "  'caption': ''}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputfolder = os.path.join(\"data\", \"image_cropped\")\n",
    "image_cropped_list = create_image_cropp_info(analyze_result, _filePath, outputfolder)\n",
    "image_cropped_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테이블 이미지를 추출하여 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테이블 이미지 자르고 저장, 이미지 경로, 테이블 캡션 정보, 테이블이 속한 페이지 정보 저장\n",
    "def create_table_cropp_info(analyze_result_info: AnalyzeResult, input_file_path, output_folder):\n",
    "    table_cropped_info = []\n",
    "    ensure_output_folder(output_folder)\n",
    "    for idx, table in enumerate(analyze_result_info.tables):\n",
    "        caption_content = \"\"\n",
    "        page_num = 0\n",
    "        if table.caption: # 테이블 캡션이 있으면 추출\n",
    "            caption_content = table.caption.content\n",
    "            caption_region = table.caption.bounding_regions\n",
    "            \n",
    "            for region in table.bounding_regions:\n",
    "                if region not in caption_region and len(region.polygon) >= 6: # 너무 작은 이미지는 제외\n",
    "                    page_num = region.page_number                    \n",
    "                    cropped_image_filename = image_cropp(region, idx, input_file_path, output_folder, \"table\")                    \n",
    "                    print(f\"cropped_image_filename: {cropped_image_filename}\")\n",
    "        else:\n",
    "            for region in table.bounding_regions:\n",
    "                if len(region.polygon) >= 6:\n",
    "                    page_num = region.page_number\n",
    "                    cropped_image_filename = image_cropp(region, idx, input_file_path, output_folder, \"table\")\n",
    "                    print(f\"cropped_image_filename: {cropped_image_filename}\")\n",
    "        \n",
    "        table_markdown = analyze_result_info.content[table.spans[0]['offset']: table.spans[0]['offset']+table.spans[0]['length']]\n",
    "\n",
    "        table_data = {\n",
    "            \"id\": idx, # 테이블 이미지 인덱스\n",
    "            \"page_number\": page_num, # 테이블이 속한 페이지 번호\n",
    "            \"image\": cropped_image_filename, # 테이블 이미지 경로와 파일명\n",
    "            \"caption\": caption_content, # 테이블 캡션\n",
    "            \"markdown\": table_markdown # markdown 으로 작성된 테이블 내용 \n",
    "        }\n",
    "        table_cropped_info.append(table_data)\n",
    "    return table_cropped_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서에서 추출한 테이블 이미지를 'data\\image_cropped' 폴더에 저장 (모든 테이블 이미지)\n",
    "- table_cropped_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_table_0.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_table_1.png\n",
      "cropped_image_filename: data\\image_cropped\\[HIF 월간 산업이슈] 24년 10월호_cropped_table_2.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'page_number': 6,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_table_0.png',\n",
       "  'caption': '표1 | 중국 조선소의 증설 동향',\n",
       "  'markdown': '<table>\\n<caption>표1 | 중국 조선소의 증설 동향</caption>\\n<tr>\\n<th>조선소</th>\\n<th>가동 예상일</th>\\n<th>생산규모 (CGT)</th>\\n<th>주요 선종</th>\\n</tr>\\n<tr>\\n<td>Hengli SB</td>\\n<td>2026</td>\\n<td>831,000</td>\\n<td>벌크, 탱커</td>\\n</tr>\\n<tr>\\n<td>Wison Qidong</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>해양플랜트</td>\\n</tr>\\n<tr>\\n<td>YangzijIang Holdings</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>LNG선</td>\\n</tr>\\n<tr>\\n<td>New Times SB</td>\\n<td>2026</td>\\n<td>882,00</td>\\n<td>탱커, 컨테이너</td>\\n</tr>\\n<tr>\\n<td>Hantong WinG HI</td>\\n<td>2026</td>\\n<td>37,000</td>\\n<td>Ultramaxes</td>\\n</tr>\\n<tr>\\n<td>CMCS</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>크루즈, 여객선</td>\\n</tr>\\n<tr>\\n<td>Shanghai Waigaoqiao</td>\\n<td>2025</td>\\n<td>973,000</td>\\n<td>컨테이너, 탱커</td>\\n</tr>\\n<tr>\\n<td>COSCO HI (Zhoushan)</td>\\n<td>2026</td>\\n<td>384,000</td>\\n<td>벌크</td>\\n</tr>\\n<tr>\\n<td>Chizhou Guichi</td>\\n<td>2026</td>\\n<td>-</td>\\n<td>연안 소형선박</td>\\n</tr>\\n</table>\\n\\n자료 : Clarkson, SK 증권'},\n",
       " {'id': 1,\n",
       "  'page_number': 7,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_table_1.png',\n",
       "  'caption': '표2 | 팬덤 경제 확산의 배경',\n",
       "  'markdown': '<table>\\n<caption>표2 | 팬덤 경제 확산의 배경</caption>\\n<tr>\\n<th>구분</th>\\n<th>내용</th>\\n</tr>\\n<tr>\\n<td>디지털 플랫폼 성장</td>\\n<td>- SNS, 스트리밍 서비스의 글로벌 확산 - 유튜브, 틱톡 등으로 글로벌 팬덤 형성</td>\\n</tr>\\n<tr>\\n<td>인프라 발달</td>\\n<td>- 팬과 아티스트 간 글로벌 실시간 소통 가능 - 촬영 장비, 스튜디오 등 인프라 확충</td>\\n</tr>\\n<tr>\\n<td>모바일 사용 보편화</td>\\n<td>- 스마트폰 활용 연령 확대(고령층, 저연령층)로 취향 공유를 위한 커뮤니티가 확장됨</td>\\n</tr>\\n<tr>\\n<td>소비 트렌드 변화</td>\\n<td>- 차별화된 소비 경험에 대한 수요 확대 - 개인적 취향에 중점을 둔 가치 소비 확산</td>\\n</tr>\\n<tr>\\n<td>팬덤의 집단적 소비 행태</td>\\n<td>- 자신이 속한 팬덤 커뮤니티의 목표나 가치에 따른 능동적인 경제 행위(대량 구매 등)를 나타냄</td>\\n</tr>\\n</table>\\n\\n자료 : 하나금융연구소'},\n",
       " {'id': 2,\n",
       "  'page_number': 8,\n",
       "  'image': 'data\\\\image_cropped\\\\[HIF 월간 산업이슈] 24년 10월호_cropped_table_2.png',\n",
       "  'caption': '표3 | 쇼핑의 2가지 유형 : 목적형 쇼핑과 발견형 쇼핑',\n",
       "  'markdown': \"<table>\\n<caption>표3 | 쇼핑의 2가지 유형 : 목적형 쇼핑과 발견형 쇼핑</caption>\\n<tr>\\n<th>구분</th>\\n<th>목적형 쇼핑</th>\\n<th>발견형 쇼핑</th>\\n</tr>\\n<tr>\\n<td>정의</td>\\n<td>- 결핍(부족)에 의한 쇼핑 - 필요를 충족하기 위해 '목적' 대상을 구매하는 행위</td>\\n<td>- 욕망, 감성에 의한 쇼핑 - (외부 자극에 의해) 수요와 욕망을 '발견'하게 되면서 이루어지는 구매 행위</td>\\n</tr>\\n<tr>\\n<td>예시</td>\\n<td>- 가격 검색 및 비교 - 생필품 구매</td>\\n<td>- 백화점 쇼윈도 - 추천 상품 구매</td>\\n</tr>\\n<tr>\\n<td>소비 유발 요인</td>\\n<td>- 검색의 정확성, 편의성 - 낮은 가격 및 할인 혜택 - 상품 비교 용이성</td>\\n<td>- 취향에 적합한 추천 - 공감을 유발하는 스토리 - 관심 기반 커뮤니티</td>\\n</tr>\\n<tr>\\n<td>특징</td>\\n<td>- 소비 시장 대부분을 차지 - 구매력 하락, 소비 성향 저하 시기 구매가 위축됨</td>\\n<td>- 목적형 대비 적은 규모 - 감성적 소비 특성 상 불황 기에도 성장 가능</td>\\n</tr>\\n</table>\\n\\n자료 : 하나금융연구소\"}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_cropped_list = create_table_cropp_info(analyze_result, _filePath, outputfolder)\n",
    "table_cropped_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 요약정보 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from cls_multi_modal import MultiModal\n",
    "\n",
    "# 프롬프트와 체인을 생성하여 이미지 요약 정보 생성\n",
    "\"\"\"\n",
    "이미지에서 유용한 정보를 추출하는 전문가로서, 주어진 이미지를 분석하여 핵심 요소를 식별하고 요약합니다. \n",
    "이를 통해 추후 검색이나 활용이 가능하도록 정보를 정리합니다.\n",
    "숫자 데이터가 포함된 경우, 중요한 통찰을 도출합니다. \n",
    "또한, 해당 이미지와 관련하여 사용자가 질문할 수 있는 다섯 가지 가상의 질문을 제공합니다.\n",
    "\n",
    "\n",
    "Output must be written in {language}.\n",
    "Please provide the output in {language} without any additional commentary or annotations.\n",
    "\"\"\"\n",
    "@chain\n",
    "def extract_image_summary(data_batches):\n",
    "    # 객체 생성\n",
    "    llm = llm_gpt4o()\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert in extracting useful information from IMAGE.\n",
    "With a given image, your task is to extract key entities, summarize them, and write useful information that can be used later for retrieval.\n",
    "If the numbers are present, summarize important insights from the numbers.\n",
    "Also, provide five hypothetical questions based on the image that users can ask.\n",
    "\"\"\"\n",
    "\n",
    "    image_paths = []\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for data_batch in data_batches:\n",
    "        context = data_batch[\"text\"] + \"\\n\\n<caption>\" + data_batch[\"caption\"] + \"</caption>\"\n",
    "        image_path = data_batch[\"image\"]\n",
    "        language = data_batch[\"language\"]\n",
    "        user_prompt_template = f\"\"\"Here is the context related to the image: {context}\n",
    "        \n",
    "###\n",
    "\n",
    "Output Format:\n",
    "\n",
    "<image>\n",
    "<title>\n",
    "[title]\n",
    "</title>\n",
    "<summary>\n",
    "[summary]\n",
    "</summary>\n",
    "<entities> \n",
    "[entities]\n",
    "</entities>\n",
    "<data_insights>\n",
    "[data_insights]\n",
    "</data_insights>\n",
    "<hypothetical_questions>\n",
    "[hypothetical_questions]\n",
    "</hypothetical_questions>\n",
    "</image>\n",
    "\n",
    "Please provide the output in {language} without any additional commentary or annotations.\n",
    "\"\"\"\n",
    "        image_paths.append(image_path)\n",
    "        system_prompts.append(system_prompt)\n",
    "        user_prompts.append(user_prompt_template)\n",
    "\n",
    "    # 멀티모달 객체 생성\n",
    "    multimodal_llm = MultiModal(llm)\n",
    "\n",
    "    # 이미지 파일로 부터 질의\n",
    "    answer = multimodal_llm.batch(\n",
    "        image_paths, system_prompts, user_prompts, display_image=False\n",
    "    )\n",
    "    return answer\n",
    "\n",
    "\n",
    "# 프롬프트에 삽입할 이미지 정보 생성\n",
    "def create_image_summary_data_batches(pagecontentlist, summaryList, imageCroppedList):\n",
    "    data_batchs=[]\n",
    "    for page_num in summaryList.keys():\n",
    "        \n",
    "        imageinfo_page_items = [imageinfo for imageinfo in imageCroppedList if imageinfo[\"page_number\"] == page_num]\n",
    "        for imageItem in imageinfo_page_items:\n",
    "            #print(f\"page: {page_num}, image item: {imageItem[\"image\"]}\")\n",
    "            data_batchs.append(\n",
    "                {\n",
    "                    \"image\": imageItem[\"image\"],\n",
    "                    \"text\": pagecontentlist[page_num], # 페이지 전체 내용\n",
    "                    # \"text\": summaryList[page_num], # 페이지 요약 내용\n",
    "                    \"page\": page_num,\n",
    "                    \"id\": imageItem[\"id\"],\n",
    "                    \"caption\": imageItem[\"caption\"],\n",
    "                    \"language\": _language,\n",
    "                }\n",
    "            )\n",
    "    return data_batchs\n",
    "\n",
    "# 이미지별 요약 정보 생성 \n",
    "def create_image_summary(pageocntentlist, summaryList, imageCroppedList):\n",
    "    image_summary_data_batches = create_image_summary_data_batches(pageocntentlist, summaryList, imageCroppedList)\n",
    "\n",
    "    image_summaries = extract_image_summary.invoke(\n",
    "        image_summary_data_batches,\n",
    "    )\n",
    "\n",
    "    image_summary_output = dict()\n",
    "\n",
    "    for data_batch, image_summary in zip(\n",
    "        image_summary_data_batches, image_summaries\n",
    "    ):\n",
    "        image_summary_output[data_batch[\"id\"]] = image_summary\n",
    "    \n",
    "    return image_summary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 요약정보 생성\n",
    "- image_summary_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<image>\\n<title>\\nHIF 월간 산업 이슈(10월)\\n</title>\\n<summary>\\n2024년 8월 30일 발행된 제39호 HIF 월간 산업 이슈에서는 철강, 조선, 유통 산업의 주요 이슈를 다루고 있다. 철강업은 원가 부담 증가와 업황 정체로 실적 회복이 지연되고 있으며, 조선업은 중국의 생산능력 확대에 따른 글로벌 경쟁 심화로 선가 하락이 예상된다. 유통업에서는 팬덤 경제의 확산이 새로운 성장 기회를 제공할 것으로 기대된다.\\n</summary>\\n<entities> \\n철강업, 조선업, 유통업, 중국, 팬덤 경제\\n</entities>\\n<data_insights>\\n- 철강업은 전방 수요 부진과 중국 경기 침체로 인해 불황이 장기화되고 있으며, 2025년 실적 개선폭이 제한적일 것으로 전망된다.\\n- 조선업은 2024년 대량 수주에 따른 기저효과로 신조 수주가 둔화될 것으로 예상되며, 중국 조선소의 증설로 인해 글로벌 수주 경쟁이 심화될 전망이다.\\n- 유통업에서는 팬덤 경제가 경기에 둔감한 특성을 지녀 소비 위축 시기에 새로운 성장 기회를 제공할 것으로 기대된다.\\n</data_insights>\\n<hypothetical_questions>\\n1. 철강업의 원가 부담 증가 요인은 무엇인가요?\\n2. 중국 조선소의 증설이 글로벌 시장에 미치는 영향은 무엇인가요?\\n3. 팬덤 경제가 유통업에 미치는 긍정적인 영향은 무엇인가요?\\n4. 2025년 철강업의 실적 개선이 제한적인 이유는 무엇인가요?\\n5. 팬덤 경제의 확산이 소비자 행동에 미치는 영향은 무엇인가요?\\n</hypothetical_questions>\\n</image>',\n",
       " 1: '<image>\\n<title>\\n글로벌 철강 수요 추이 및 전망\\n</title>\\n<summary>\\n글로벌 철강 수요는 2021년 2.8% 증가했으나, 2022년에는 -3.1% 감소했다. 2023년과 2024년에는 각각 -0.8%와 -0.9%로 감소세가 지속될 것으로 예상되며, 2025년에는 1.2% 증가할 것으로 전망된다.\\n</summary>\\n<entities>\\n글로벌 철강 수요, 증가율, 2021년, 2022년, 2023년, 2024년, 2025년\\n</entities>\\n<data_insights>\\n- 2021년 철강 수요 증가율은 2.8%로 긍정적이었다.\\n- 2022년에는 -3.1%로 큰 감소를 보였다.\\n- 2023년과 2024년에도 감소세가 지속될 것으로 보인다.\\n- 2025년에는 1.2% 증가할 것으로 예상된다.\\n</data_insights>\\n<hypothetical_questions>\\n- 2022년 철강 수요가 감소한 주요 원인은 무엇인가요?\\n- 2025년 철강 수요 증가의 요인은 무엇인가요?\\n- 철강 수요 감소가 철강업계에 미치는 영향은 무엇인가요?\\n- 2023년과 2024년의 철강 수요 감소를 극복하기 위한 전략은 무엇인가요?\\n- 글로벌 철강 수요 변화가 지역별로 어떻게 다른가요?\\n</hypothetical_questions>\\n</image>',\n",
       " 2: '<image>\\n<title>\\n주요 철강 3개사의 3분기 실적\\n</title>\\n<summary>\\n포스코, 현대제철, 동국제강의 2023년 3분기와 2024년 3분기 실적 비교. 매출액과 영업이익률 모두 감소.\\n</summary>\\n<entities> \\n포스코, 현대제철, 동국제강, 매출액, 영업이익률\\n</entities>\\n<data_insights>\\n- 포스코: 매출액은 약 10,000십억원에서 9,000십억원으로 감소, 영업이익률은 7.5%에서 4.6%로 감소.\\n- 현대제철: 매출액은 약 6,000십억원에서 5,000십억원으로 감소, 영업이익률은 3.6%에서 0.7%로 감소.\\n- 동국제강: 매출액은 약 2,000십억원에서 2,000십억원으로 유지, 영업이익률은 9.8%에서 2.6%로 감소.\\n</data_insights>\\n<hypothetical_questions>\\n1. 포스코의 매출 감소 원인은 무엇인가요?\\n2. 현대제철의 영업이익률이 급감한 이유는 무엇인가요?\\n3. 동국제강의 매출이 유지된 이유는 무엇인가요?\\n4. 철강업계의 전반적인 실적 부진의 주요 요인은 무엇인가요?\\n5. 중국의 철강 수출이 한국 시장에 미치는 영향은 무엇인가요?\\n</hypothetical_questions>\\n</image>',\n",
       " 3: '<image>\\n<title>\\n철근 기준가격 및 유통가격 추이\\n</title>\\n<summary>\\n2020년부터 2024년까지 철근의 기준가격과 유통가격의 변동 추이를 보여주는 그래프입니다. 두 가격 모두 2021년과 2022년에 급격히 상승한 후, 2023년과 2024년에는 하락세를 보이고 있습니다.\\n</summary>\\n<entities>\\n철근, 기준가격, 유통가격, 2020년, 2021년, 2022년, 2023년, 2024년\\n</entities>\\n<data_insights>\\n- 2021년과 2022년에 철근 가격이 급격히 상승.\\n- 2023년과 2024년에는 가격이 하락세.\\n- 기준가격과 유통가격의 변동 패턴이 유사.\\n</data_insights>\\n<hypothetical_questions>\\n1. 철근 가격이 급격히 상승한 이유는 무엇인가요?\\n2. 2023년과 2024년의 가격 하락 원인은 무엇인가요?\\n3. 기준가격과 유통가격의 차이는 어떻게 발생하나요?\\n4. 철근 가격 변동이 산업에 미치는 영향은 무엇인가요?\\n5. 향후 철근 가격의 전망은 어떻게 되나요?\\n</hypothetical_questions>\\n</image>',\n",
       " 4: '<image>\\n<title>\\n국내 철강업체 실적 전망\\n</title>\\n<summary>\\n국내 철강업체의 매출액과 영업이익률 추이를 보여주는 그래프입니다. 2020년부터 2025년까지의 데이터를 포함하고 있으며, 매출액은 2021년에 최고치를 기록한 후 감소세를 보이고 있습니다. 영업이익률은 2022년 이후 하락세를 보이다가 2025년에 소폭 회복될 것으로 예상됩니다.\\n</summary>\\n<entities> \\n철강업체, 매출액, 영업이익률, 2020년, 2021년, 2022년, 2023년, 2024년, 2025년\\n</entities>\\n<data_insights>\\n- 2021년 매출액은 11.0조원으로 최고치를 기록.\\n- 영업이익률은 2022년 6.3%에서 2024년 4.4%로 감소.\\n- 2025년 영업이익률은 5.4%로 소폭 회복 예상.\\n</data_insights>\\n<hypothetical_questions>\\n- 2021년 매출액이 최고치를 기록한 이유는 무엇인가요?\\n- 2024년 영업이익률이 감소한 원인은 무엇인가요?\\n- 2025년 영업이익률 회복의 주요 요인은 무엇인가요?\\n- 철강업체의 매출액 감소가 산업 전반에 미치는 영향은 무엇인가요?\\n- 2020년부터 2025년까지의 영업이익률 변동 요인은 무엇인가요?\\n</hypothetical_questions>\\n</image>',\n",
       " 5: '<image>\\n<title>\\n글로벌 신조선 수주량 추이\\n</title>\\n<summary>\\n2008년 9월과 2024년 9월의 글로벌 신조선 수주량을 비교한 그래프. 2008년 9월에는 5,361만 CGT, 2024년 9월에는 4,976만 CGT를 기록.\\n</summary>\\n<entities> \\n- 글로벌 신조선 수주량\\n- 2008년 9월\\n- 2024년 9월\\n- CGT (Compensated Gross Tonnage)\\n</entities>\\n<data_insights>\\n- 2008년 9월 수주량: 5,361만 CGT\\n- 2024년 9월 수주량: 4,976만 CGT\\n- 2008년 이후 최대 수주량 기록\\n</data_insights>\\n<hypothetical_questions>\\n- 2008년과 2024년의 수주량 차이는 무엇인가요?\\n- CGT란 무엇을 의미하나요?\\n- 2024년 수주량이 증가한 이유는 무엇인가요?\\n- 2008년 이후 수주량이 가장 높았던 시기는 언제인가요?\\n- 수주량 증가가 조선업에 미치는 영향은 무엇인가요?\\n</hypothetical_questions>\\n</image>',\n",
       " 6: '<image>\\n<title>\\n국내 조선사 실적 추이\\n</title>\\n<summary>\\n2023년 1분기부터 2024년 3분기까지 국내 조선사의 매출액과 영업이익률 추이를 보여주는 그래프입니다. 매출액은 꾸준히 증가하고 있으며, 영업이익률도 상승세를 보이고 있습니다.\\n</summary>\\n<entities>\\n국내 조선사, 매출액, 영업이익률, 2023년 1분기, 2024년 3분기\\n</entities>\\n<data_insights>\\n- 매출액은 2023년 1분기부터 2024년 3분기까지 지속적으로 증가.\\n- 영업이익률은 2023년 1분기 이후 상승세를 보이며 2024년 3분기까지 증가.\\n</data_insights>\\n<hypothetical_questions>\\n- 2023년 1분기와 2024년 3분기의 매출액 차이는 얼마인가요?\\n- 영업이익률이 가장 높았던 분기는 언제인가요?\\n- 매출액 증가에 영향을 미친 주요 요인은 무엇인가요?\\n- 2024년 3분기의 영업이익률은 몇 퍼센트인가요?\\n- 매출액과 영업이익률의 상관관계는 어떻게 되나요?\\n</hypothetical_questions>\\n</image>',\n",
       " 7: \"<image>\\n<title>\\n선종별 한-중 수주량 비교 ('24.9 YTD 기준)\\n</title>\\n<summary>\\n2024년 9월까지의 한국과 중국의 선종별 수주량을 비교한 그래프입니다. 컨테이너, 탱커, 벌크, LNG선, 기타 선종에 대한 수주량이 표시되어 있습니다.\\n</summary>\\n<entities>\\n한국, 중국, 컨테이너, 탱커, 벌크, LNG선, 기타\\n</entities>\\n<data_insights>\\n- 컨테이너 선종에서 한국이 중국보다 더 많은 수주량을 기록.\\n- 탱커 선종에서는 중국이 한국보다 더 많은 수주량을 보임.\\n- 벌크 선종에서도 중국이 우세.\\n- LNG선에서는 한국이 중국보다 더 많은 수주량을 기록.\\n- 기타 선종에서는 중국이 한국보다 더 많은 수주량을 보임.\\n</data_insights>\\n<hypothetical_questions>\\n1. 2024년 9월까지 한국과 중국의 컨테이너 수주량 차이는 얼마나 되나요?\\n2. LNG선에서 한국이 중국보다 우세한 이유는 무엇인가요?\\n3. 중국이 벌크 선종에서 우세한 이유는 무엇인가요?\\n4. 탱커 선종에서 중국의 수주량이 높은 이유는 무엇인가요?\\n5. 기타 선종에서 한국의 수주량을 늘리기 위한 전략은 무엇인가요?\\n</hypothetical_questions>\\n</image>\",\n",
       " 8: '<image>\\n<title>\\nHIF 월간 산업 이슈 Monthly Industrial Issue\\n</title>\\n<summary>\\n기저효과와 중국 조선소 증설로 인한 수주 경쟁 심화 및 선가 하락 전망. 국내 조선소의 수익성 약화 우려.\\n</summary>\\n<entities> \\n- 기저효과\\n- 중국 조선소\\n- 신조선\\n- 중고선\\n- 환경규제\\n- 국내 조선소\\n- LNG선\\n- 컨테이너선\\n- 벌크선\\n- 탱커\\n</entities>\\n<data_insights>\\n- 2024년 대량 수주로 인한 기저효과로 수주 둔화 예상.\\n- 중국 조선소의 증설로 인해 선가 하락 전망.\\n- 2021년부터 2024년 3분기까지 글로벌 조선사들의 캐파 확대 계획은 총 820만 CGT.\\n- 중국이 글로벌 조선소 증설의 77% 차지.\\n- 국내 조선소의 수주잔량은 2025년, 2026년 물량 확보.\\n- 2027년부터 중국과의 가격 경쟁 심화로 수익성 약화 우려.\\n</data_insights>\\n<hypothetical_questions>\\n- 기저효과가 조선업에 미치는 영향은 무엇인가요?\\n- 중국 조선소의 증설이 글로벌 시장에 미치는 영향은?\\n- 국내 조선소의 수익성 약화에 대한 대책은 무엇인가요?\\n- LNG선과 컨테이너선의 기술 격차는 어떻게 변화하고 있나요?\\n- 2027년 이후 국내 조선소의 경쟁력 강화를 위한 전략은?\\n</hypothetical_questions>\\n</image>',\n",
       " 9: '```markdown\\n<image>\\n<title>\\n가수 임영웅 광고 및 효과\\n</title>\\n<summary>\\n팬덤 경제의 확산과 그 경제적 영향력을 설명하며, 가수 임영웅의 광고 효과를 통해 팬덤 경제가 산업계에 미치는 긍정적 영향을 강조한다.\\n</summary>\\n<entities> \\n- 팬덤 경제\\n- 가수 임영웅\\n- G4 렉스턴\\n- 정관장\\n- 디지털 플랫폼\\n- 모바일 사용\\n</entities>\\n<data_insights>\\n- 팬덤 경제는 특정 대상에 대한 유대감과 열정이 창출하는 경제적 가치로, 디지털 플랫폼과 가치 소비의 확산에 따라 확대되고 있다.\\n- 가수 임영웅의 팬덤은 자동차와 건강식품 산업의 매출 증가에 기여하며, 팬덤 경제의 실질적 경제적 가치를 보여준다.\\n- 디지털 플랫폼의 성장, 인프라 발달, 모바일 사용의 보편화, 소비 트렌드 변화 등이 팬덤 경제 확산의 배경으로 작용하고 있다.\\n</data_insights>\\n<hypothetical_questions>\\n- 팬덤 경제가 다른 산업에 미치는 영향은 무엇인가요?\\n- 가수 임영웅의 팬덤이 산업계에 미친 구체적인 사례는 무엇인가요?\\n- 디지털 플랫폼의 성장이 팬덤 경제에 어떤 영향을 미쳤나요?\\n- 팬덤 경제의 확산이 소비 트렌드에 어떤 변화를 가져왔나요?\\n- 팬덤 경제가 불황기에 어떻게 새로운 성장 기회를 제공하나요?\\n</hypothetical_questions>\\n</image>\\n```',\n",
       " 10: '<image>\\n<title>\\n유통업 \"불황기, 고객은 떠나도 팬은 떠나지 않는다.\"\\n</title>\\n<summary>\\n팬덤 경제는 특정 대상을 향한 유대감과 열정이 창출하는 경제적 가치를 의미하며, 디지털 플랫폼과 가치 소비의 확산에 따라 확대되고 있다. 팬덤 경제는 경기 불황 시에도 소비재 및 유통업체에 새로운 성장 기회를 제공할 수 있다.\\n</summary>\\n<entities> \\n- 팬덤 경제\\n- 디지털 플랫폼\\n- 가치 소비\\n- 임영웅\\n- 쌍용차 \\'G4 렉스턴\\'\\n- 정관장\\n</entities>\\n<data_insights>\\n- 임영웅의 영향력으로 쌍용차 \\'G4 렉스턴\\'의 판매가 전월 대비 53% 증가.\\n- 정관장의 가정의 달 행사에서 신규 가입 고객이 72% 증가.\\n- 팬덤 경제는 디지털 플랫폼 성장, 인프라 발달, 모바일 사용 보편화, 소비 트렌드 변화, 팬덤의 집단적 소비 행태에 의해 확산.\\n</data_insights>\\n<hypothetical_questions>\\n- 팬덤 경제가 유통업에 미치는 영향은 무엇인가요?\\n- 임영웅의 팬덤이 산업계에 미친 구체적인 사례는 무엇인가요?\\n- 팬덤 경제의 확산 배경에는 어떤 요소들이 있나요?\\n- 디지털 플랫폼이 팬덤 경제에 어떻게 기여하나요?\\n- 팬덤 경제가 불황기에 어떻게 새로운 기회를 제공하나요?\\n</hypothetical_questions>\\n</image>',\n",
       " 11: '<image>\\n<title>\\n국내 라이브커머스 시장 규모\\n</title>\\n<summary>\\n국내 라이브커머스 시장은 2020년부터 2023년까지 급격한 성장을 보이며, 2023년에는 약 10조 원 규모에 도달했다.\\n</summary>\\n<entities> \\n팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스, 하이브 위버스, 디어유 버블, 인스타그램, 네이버, 카카오, 쿠팡, 무신사, 오늘의 집\\n</entities>\\n<data_insights>\\n- 2020년: 약 0.4조 원\\n- 2021년: 약 2조 원\\n- 2022년: 약 6조 원\\n- 2023년: 약 10조 원\\n</data_insights>\\n<hypothetical_questions>\\n1. 팬덤 경제 기반의 플랫폼에는 어떤 것들이 있나요?\\n2. 라이브커머스 시장의 성장 요인은 무엇인가요?\\n3. 팬덤 기반의 수요 창출이 기업에 어떤 기회를 제공하나요?\\n4. 목적형 쇼핑과 발견형 쇼핑의 차이점은 무엇인가요?\\n5. 팬덤 경제가 불황기에 강한 이유는 무엇인가요?\\n</hypothetical_questions>\\n</image>',\n",
       " 12: '<image>\\n<title>\\nHIF 월간 산업 이슈 Monthly Industrial Issue\\n</title>\\n<summary>\\n팬덤 경제 기반의 플랫폼은 팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스 등이 있으며, 팬덤 기반의 수요 창출은 소비재 및 유통 기업에게 성장 기회를 제공합니다. 라이브커머스 시장은 급성장 중이며, 팬덤을 통한 새로운 수요 창출이 불황기 극복에 기여할 수 있습니다.\\n</summary>\\n<entities> \\n팬덤 플랫폼, 라이브커머스, 커뮤니티형 커머스, 하이브 위버스, 디어유 버블, 인스타그램 크리에이터 마켓플레이스, 무신사, 오늘의 집\\n</entities>\\n<data_insights>\\n- 2020년부터 2023년까지 라이브커머스 시장은 4천억원에서 10조원 규모로 성장.\\n- 목적형 쇼핑과 발견형 쇼핑의 차이점: 목적형은 필요 충족, 발견형은 욕망과 감성에 의한 쇼핑.\\n- 팬덤 기반 커머스는 경기 민감도가 낮아 불황기에도 성장 가능.\\n</data_insights>\\n<hypothetical_questions>\\n1. 팬덤 플랫폼의 주요 기능은 무엇인가요?\\n2. 라이브커머스 시장의 성장 요인은 무엇인가요?\\n3. 목적형 쇼핑과 발견형 쇼핑의 차이점은 무엇인가요?\\n4. 팬덤 경제가 불황기에 어떻게 기여할 수 있나요?\\n5. 커뮤니티형 커머스의 성공 사례는 무엇인가요?\\n</hypothetical_questions>\\n</image>'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_summary_data_list = create_image_summary(page_content_list, summary_list, image_cropped_list)\n",
    "image_summary_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테이블 요약정보 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "주어진 표에서 유용한 정보를 추출하는 전문가로서, 이미지로 제공된 표를 분석하여 핵심 엔터티를 식별하고 요약합니다. \n",
    "숫자 데이터가 포함된 경우, 중요한 통찰을 도출합니다. \n",
    "또한, 사용자가 이미지 기반으로 질문할 수 있는 다섯 가지 가상의 질문을 제공합니다.\n",
    "\n",
    "Output must be written in {language}.\n",
    "\"\"\"\n",
    "# 프롬프트와 체인을 생성하여 테이블 요약 정보 생성\n",
    "@chain\n",
    "def extract_table_summary(data_batches):\n",
    "    # 객체 생성\n",
    "    llm = llm_gpt4o()\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert in extracting useful information from TABLE. \n",
    "With a given image, your task is to extract key entities, summarize them, and write useful information that can be used later for retrieval.\n",
    "If the numbers are present, summarize important insights from the numbers.\n",
    "Also, provide five hypothetical questions based on the image that users can ask.\n",
    "\"\"\"\n",
    "\n",
    "    image_paths = []\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for data_batch in data_batches:\n",
    "        context = data_batch[\"text\"] + \"\\n\\n<caption>\" + data_batch[\"caption\"] + \"</caption>\"\n",
    "        image_path = data_batch[\"table\"]\n",
    "        language = data_batch[\"language\"]\n",
    "        user_prompt_template = f\"\"\"Here is the context related to the image of table: {context}\n",
    "        \n",
    "###\n",
    "\n",
    "Output Format:\n",
    "\n",
    "<table>\n",
    "<title>\n",
    "[title]\n",
    "</title>\n",
    "<summary>\n",
    "[summary]\n",
    "</summary>\n",
    "<entities> \n",
    "[entities]\n",
    "</entities>\n",
    "<data_insights>\n",
    "[data_insights]\n",
    "</data_insights>\n",
    "<hypothetical_questions>\n",
    "[hypothetical_questions]\n",
    "</hypothetical_questions>\n",
    "</table>\n",
    "\n",
    "Please provide the output in {language} without any additional commentary or annotations.\n",
    "\"\"\"\n",
    "        image_paths.append(image_path)\n",
    "        system_prompts.append(system_prompt)\n",
    "        user_prompts.append(user_prompt_template)\n",
    "\n",
    "    # 멀티모달 객체 생성\n",
    "    multimodal_llm = MultiModal(llm)\n",
    "\n",
    "    # 이미지 파일로 부터 질의\n",
    "    answer = multimodal_llm.batch(\n",
    "        image_paths, system_prompts, user_prompts, display_image=False\n",
    "    )\n",
    "    return answer\n",
    "\n",
    "\n",
    "def create_table_summary_data_batches(pagecontentlist, summaryList, tableCroppedList):\n",
    "    data_batchs=[]\n",
    "    for page_num in summaryList.keys():\n",
    "        \n",
    "        tableinfo_page_items = [tableinfo for tableinfo in tableCroppedList if tableinfo[\"page_number\"] == page_num]\n",
    "        for tableItem in tableinfo_page_items:\n",
    "            #print(f\"page: {page_num}, image item: {imageItem[\"image\"]}\")\n",
    "            data_batchs.append(\n",
    "                {\n",
    "                    \"table\": tableItem[\"image\"],\n",
    "                    \"text\": pagecontentlist[page_num],\n",
    "                    # \"text\": summaryList[page_num],\n",
    "                    \"page\": page_num,\n",
    "                    \"id\": tableItem[\"id\"],\n",
    "                    \"caption\": tableItem[\"caption\"],\n",
    "                    \"language\": _language,\n",
    "                }\n",
    "            )\n",
    "    return data_batchs\n",
    "   \n",
    "\n",
    "def create_table_summary(pagecontentlist, summaryList, tableCroppedList):\n",
    "    table_summary_data_batches = create_table_summary_data_batches(pagecontentlist, summaryList, tableCroppedList)\n",
    "\n",
    "    table_summaries = extract_table_summary.invoke(\n",
    "        table_summary_data_batches,\n",
    "    )\n",
    "\n",
    "    table_summary_output = dict()\n",
    "\n",
    "    for data_batch, table_summary in zip(\n",
    "        table_summary_data_batches, table_summaries\n",
    "    ):\n",
    "        table_summary_output[data_batch[\"id\"]] = table_summary\n",
    "    \n",
    "    return table_summary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테이블 이미지 요약정보 생성\n",
    "- table_summary_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '```html\\n<table>\\n<title>\\n중국 조선소의 증설 동향\\n</title>\\n<summary>\\n중국 조선소의 증설 계획에 대한 정보로, 2025년과 2026년에 걸쳐 다양한 선종의 생산이 예정되어 있다.\\n</summary>\\n<entities> \\n조선소, 가동 예상일, 생산규모 (CGT), 주요 선종\\n</entities>\\n<data_insights>\\n- Shanghai Waigaoqiao는 2025년에 가장 큰 생산규모인 973,000 CGT를 계획하고 있다.\\n- 2026년에는 Hengli SB와 New Times SB가 각각 831,000 CGT와 882,000 CGT의 생산을 계획 중이다.\\n- 주요 선종으로는 벌크, 탱커, 컨테이너, LNG선 등이 포함되어 있다.\\n</data_insights>\\n<hypothetical_questions>\\n1. 2026년에 가동 예정인 조선소 중 가장 큰 생산규모를 가진 곳은 어디인가요?\\n2. Shanghai Waigaoqiao의 주요 선종은 무엇인가요?\\n3. 2025년과 2026년의 생산규모 차이는 어떻게 되나요?\\n4. LNG선을 생산하는 조선소는 어디인가요?\\n5. 중국 조선소의 증설이 한국 조선소에 미치는 영향은 무엇인가요?\\n</hypothetical_questions>\\n</table>\\n```',\n",
       " 1: '```markdown\\n<table>\\n<title>\\n팬덤 경제 확산의 배경\\n</title>\\n<summary>\\n팬덤 경제는 특정 대상을 향한 유대감과 열정이 창출하는 경제적 가치를 의미하며, 디지털 플랫폼의 성장, 인프라 발달, 모바일 사용 보편화, 소비 트렌드 변화, 팬덤의 집단적 소비 행태에 의해 확산되고 있다.\\n</summary>\\n<entities> \\n디지털 플랫폼 성장, 인프라 발달, 모바일 사용 보편화, 소비 트렌드 변화, 팬덤의 집단적 소비 행태\\n</entities>\\n<data_insights>\\n1. 디지털 플랫폼의 글로벌 확산은 팬덤 경제의 성장을 촉진한다.\\n2. 팬과 아티스트 간의 실시간 소통이 가능해지면서 팬덤 경제가 강화된다.\\n3. 스마트폰 사용의 보편화로 다양한 연령층이 팬덤 커뮤니티에 참여하고 있다.\\n4. 차별화된 소비 경험과 가치 소비의 확산이 팬덤 경제를 뒷받침한다.\\n5. 팬덤 커뮤니티의 집단적 소비 행태는 경제적 가치를 창출한다.\\n</data_insights>\\n<hypothetical_questions>\\n1. 팬덤 경제가 유통업에 미치는 영향은 무엇인가요?\\n2. 디지털 플랫폼의 성장이 팬덤 경제에 어떤 기여를 하나요?\\n3. 모바일 사용의 보편화가 팬덤 경제에 미치는 영향은 무엇인가요?\\n4. 팬덤의 집단적 소비 행태는 어떻게 경제적 가치를 창출하나요?\\n5. 소비 트렌드 변화가 팬덤 경제에 미치는 영향은 무엇인가요?\\n</hypothetical_questions>\\n</table>\\n```',\n",
       " 2: '```html\\n<table>\\n<title>\\n쇼핑의 2가지 유형 : 목적형 쇼핑과 발견형 쇼핑\\n</title>\\n<summary>\\n쇼핑은 목적형과 발견형으로 나뉘며, 각각의 정의, 예시, 소비 유발 요인, 특징이 다르다.\\n</summary>\\n<entities>\\n- 목적형 쇼핑\\n- 발견형 쇼핑\\n- 결핍\\n- 욕망\\n- 가격 검색\\n- 백화점 쇼윈도\\n- 생필품\\n- 추천 상품\\n</entities>\\n<data_insights>\\n- 목적형 쇼핑은 필요를 충족하기 위한 구매로, 가격 검색 및 비교가 중요하다.\\n- 발견형 쇼핑은 욕망과 감성에 의해 이루어지며, 추천 상품 구매가 주를 이룬다.\\n- 목적형 쇼핑은 소비 시장 대부분을 차지하지만, 경제 상황에 민감하다.\\n- 발견형 쇼핑은 감성적 소비 특성으로 불황기에도 성장 가능성이 있다.\\n</data_insights>\\n<hypothetical_questions>\\n- 목적형 쇼핑과 발견형 쇼핑의 차이점은 무엇인가요?\\n- 발견형 쇼핑이 불황기에도 성장 가능한 이유는 무엇인가요?\\n- 목적형 쇼핑의 소비 유발 요인은 무엇인가요?\\n- 발견형 쇼핑의 예시로 어떤 것들이 있나요?\\n- 쇼핑 유형에 따라 소비자 행동이 어떻게 달라지나요?\\n</hypothetical_questions>\\n</table>\\n```'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_summary_data_list = create_table_summary(page_content_list, summary_list, table_cropped_list)\n",
    "table_summary_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image, Table 에서 추출된 데이터 Vector DB 생성을 위한 문서 생성\n",
    "\n",
    "- Title, Summary, Entities 는 임베딩 검색에 걸리기 위한 문서로 생성\n",
    "- hypothetical_questions 는 임베딩 검색에 걸리기 위한 문서로 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 요소 추출 또는 제외 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 특정 태그의 내용을 반환\n",
    "def extract_tag_content(content, tag):\n",
    "    pattern = rf\"<{tag}>(.*?)</{tag}>\"\n",
    "    match = re.search(pattern, content, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 특정 태그를 제외한 내용을 반환\n",
    "def extract_non_tag_content(content, tag):\n",
    "    pattern = rf\"<{tag}>.*?</{tag}>\"\n",
    "    result = re.sub(pattern, \"\", content, flags=re.DOTALL)\n",
    "    return result.strip()\n",
    "\n",
    "# 특정 태그의 내용을 반환 - 태그 포함\n",
    "def extract_include_tag_content(content, tag):\n",
    "    pattern = rf\"(<{tag}>.*?</{tag}>)\"\n",
    "    match = re.search(pattern, content, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 팬덤 경제가 다른 산업에 미치는 영향은 무엇인가요?\n",
      "- 가수 임영웅의 팬덤이 산업계에 미친 구체적인 사례는 무엇인가요?\n",
      "- 디지털 플랫폼의 성장이 팬덤 경제에 어떤 영향을 미쳤나요?\n",
      "- 팬덤 경제의 확산이 소비 트렌드에 어떤 변화를 가져왔나요?\n",
      "- 팬덤 경제가 불황기에 어떻게 새로운 성장 기회를 제공하나요?\n"
     ]
    }
   ],
   "source": [
    "print(extract_tag_content(image_summary_data_list[9], \"hypothetical_questions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```markdown\n",
      "<image>\n",
      "<title>\n",
      "가수 임영웅 광고 및 효과\n",
      "</title>\n",
      "<summary>\n",
      "팬덤 경제의 확산과 그 경제적 영향력을 설명하며, 가수 임영웅의 광고 효과를 통해 팬덤 경제가 산업계에 미치는 긍정적 영향을 강조한다.\n",
      "</summary>\n",
      "<entities> \n",
      "- 팬덤 경제\n",
      "- 가수 임영웅\n",
      "- G4 렉스턴\n",
      "- 정관장\n",
      "- 디지털 플랫폼\n",
      "- 모바일 사용\n",
      "</entities>\n",
      "<data_insights>\n",
      "- 팬덤 경제는 특정 대상에 대한 유대감과 열정이 창출하는 경제적 가치로, 디지털 플랫폼과 가치 소비의 확산에 따라 확대되고 있다.\n",
      "- 가수 임영웅의 팬덤은 자동차와 건강식품 산업의 매출 증가에 기여하며, 팬덤 경제의 실질적 경제적 가치를 보여준다.\n",
      "- 디지털 플랫폼의 성장, 인프라 발달, 모바일 사용의 보편화, 소비 트렌드 변화 등이 팬덤 경제 확산의 배경으로 작용하고 있다.\n",
      "</data_insights>\n",
      "\n",
      "</image>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(extract_non_tag_content(image_summary_data_list[9], \"hypothetical_questions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테이블 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML 파싱을 위해 import 문을 추가합니다\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# 테이블의 요약 정보를 정규화 하여 벡터DB에 저장 \n",
    "def convert_to_markdown_table(table_summary):\n",
    "    html = \"<table>\\n\"\n",
    "\n",
    "    # table_summary가 문자열인 경우를 처리합니다\n",
    "    if isinstance(table_summary, str):\n",
    "        # XML 파싱을 사용하여 문자열에서 데이터를 추출합니다\n",
    "        root = ET.fromstring(table_summary)\n",
    "        for child in root:\n",
    "            html += f\"  <tr>\\n    <th>{child.tag}</th>\\n    <td>\"\n",
    "\n",
    "            if child.tag in [\"entities\", \"data_insights\"]:\n",
    "                html += \"<ul>\\n\"\n",
    "                for item in child.text.strip().split(\"\\n- \"):\n",
    "                    if item.strip():\n",
    "                        html += f\"      <li>{item.strip()}</li>\\n\"\n",
    "                html += \"    </ul>\"\n",
    "            elif child.tag == \"hypothetical_questions\":\n",
    "                html += \"<ol>\\n\"\n",
    "                for item in child.text.strip().split(\"\\n\"):\n",
    "                    if item.strip():\n",
    "                        html += f\"      <li>{item.strip()}</li>\\n\"\n",
    "                html += \"    </ol>\"\n",
    "            else:\n",
    "                html += child.text.strip()\n",
    "\n",
    "            html += \"</td>\\n  </tr>\\n\"\n",
    "    else:\n",
    "        # 기존의 딕셔너리 처리 로직을 유지합니다\n",
    "        for key, value in table_summary.items():\n",
    "            html += f\"  <tr>\\n    <th>{key}</th>\\n    <td>\"\n",
    "\n",
    "            if key in [\"entities\", \"data_insights\"]:\n",
    "                html += \"<ul>\\n\"\n",
    "                for item in value.split(\"\\n- \"):\n",
    "                    if item.strip():\n",
    "                        html += f\"      <li>{item.strip()}</li>\\n\"\n",
    "                html += \"    </ul>\"\n",
    "            elif key == \"hypothetical_questions\":\n",
    "                html += \"<ol>\\n\"\n",
    "                for item in value.split(\"\\n\"):\n",
    "                    if item.strip():\n",
    "                        html += f\"      <li>{item.strip()}</li>\\n\"\n",
    "                html += \"    </ol>\"\n",
    "            else:\n",
    "                html += value\n",
    "\n",
    "            html += \"</td>\\n  </tr>\\n\"\n",
    "\n",
    "    html += \"</table>\"\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table_summary_data_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_table = extract_include_tag_content(table_summary_data_list[1], \"table\")\n",
    "print(extract_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_table = convert_to_markdown_table(extract_table)\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown의 제목을 기준으로 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter # 마크다운 헤더를 기준으로 텍스트를 분할하는 클래스입니다.\n",
    "\n",
    "def markdown_header_text_splitter(stripheaders=False):\n",
    "    # 마크다운 헤더 레벨에 따라 분할할 기준을 정의합니다.\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\"),\n",
    "        (\"#####\", \"Header 5\"),\n",
    "        (\"######\", \"Header 6\"),  \n",
    "        (\"#######\", \"Header 7\"), \n",
    "        (\"########\", \"Header 8\")\n",
    "    ]\n",
    "    return MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=stripheaders) # 텍스트 분할기를 초기화합니다.\n",
    "\n",
    "docs_string = page_content_list[1] # 첫 번째 문서의 내용을 문자열로 저장합니다.\n",
    "docs_result = markdown_header_text_splitter().split_text(docs_string) # 텍스트를 헤더 기준으로 분할합니다.\n",
    "\n",
    "print(\"Length of splits: \" + str(len(docs_result))) # 분할된 청크의 개수를 출력합니다.\n",
    "docs_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터 DB 저장 형식으로 문서 구조 변환 및 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document(content, metadata):\n",
    "    \"\"\"\n",
    "    문서 객체를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        content (str): 문서의 내용\n",
    "        metadata (dict): 문서의 메타데이터\n",
    "\n",
    "    Returns:\n",
    "        Document: 생성된 문서 객체\n",
    "    \"\"\"\n",
    "    return Document(page_content=content, metadata=metadata)\n",
    "\n",
    "\n",
    "def process_image_element(image_cropped_item, image_summary_list, page_number):\n",
    "    \"\"\"\n",
    "    이미지 요소를 처리합니다.\n",
    "\n",
    "    Args:\n",
    "        element (dict): 이미지 요소 정보\n",
    "        state (dict): 현재 상태\n",
    "        page_number (str): 페이지 번호\n",
    "\n",
    "    Returns:\n",
    "        tuple: 마크다운 문자열과 문서 객체 리스트\n",
    "    \"\"\"\n",
    "    image_id = image_cropped_item[\"id\"]\n",
    "    image_summary = image_summary_list[image_id]\n",
    "    image_path = image_cropped_item[\"image\"]\n",
    "    image_path_md = f\"![{image_path}]({image_path})\"\n",
    "\n",
    "    image_summary = extract_include_tag_content(image_summary, \"image\") # LLM에서 추가된 주석 제거\n",
    "\n",
    "    # image_summary_md = convert_to_markdown_table(image_summary)    \n",
    "    markdown = f\"{image_path_md}\"\n",
    "\n",
    "    image_summary_clean = extract_non_tag_content(\n",
    "        image_summary, \"hypothetical_questions\"\n",
    "    )\n",
    "\n",
    "    docs = [\n",
    "        create_document(\n",
    "            image_summary_clean,\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image_path,\n",
    "                \"page\": page_number,\n",
    "                \"source\": _filePath,\n",
    "                # \"id\": image_id, # id가 중복될 경우 azure ai search에 저장 시 누락됨\n",
    "                \"doc_name\": _file_name,\n",
    "            },\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    hypo_docs = []\n",
    "\n",
    "    hypothetical_questions = extract_tag_content(\n",
    "        image_summary, \"hypothetical_questions\"\n",
    "    )\n",
    "    if hypothetical_questions != None:\n",
    "        hypo_docs.append(\n",
    "            create_document(\n",
    "                hypothetical_questions,\n",
    "                {\n",
    "                    \"type\": \"hypothetical_questions\",\n",
    "                    \"image\": image_path,\n",
    "                    \"summary\": image_summary_clean,\n",
    "                    \"page\": page_number,\n",
    "                    \"source\": _filePath,\n",
    "                    # \"id\": image_id,\n",
    "                    \"doc_name\": _file_name,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return markdown, docs, hypo_docs\n",
    "\n",
    "\n",
    "def process_table_element(table_cropped_item, table_summary_list, page_number):\n",
    "    \"\"\"\n",
    "    테이블 요소를 처리합니다.\n",
    "\n",
    "    Args:\n",
    "        element (dict): 테이블 요소 정보\n",
    "        state (dict): 현재 상태\n",
    "        page_number (str): 페이지 번호\n",
    "\n",
    "    Returns:\n",
    "        tuple: 마크다운 문자열과 문서 객체\n",
    "    \"\"\"\n",
    "    table_id = table_cropped_item[\"id\"]\n",
    "    table_summary = table_summary_list[table_id]\n",
    "    table_markdown = table_cropped_item[\"markdown\"]\n",
    "    table_path = table_cropped_item[\"image\"]\n",
    "    table_path_md = f\"![{table_path}]({table_path})\"\n",
    "\n",
    "    table_summary = extract_include_tag_content(table_summary, \"table\") # LLM에서 추가된 주석 제거\n",
    "\n",
    "    # table_summary_md = convert_to_markdown_table(table_summary)\n",
    "    markdown = f\"{table_path_md}\\n{table_markdown}\"\n",
    "\n",
    "    table_summary_clean = extract_non_tag_content(\n",
    "        table_summary, \"hypothetical_questions\"\n",
    "    )\n",
    "\n",
    "    docs = [\n",
    "        create_document(\n",
    "            table_summary_clean,\n",
    "            {\n",
    "                \"type\": \"table\",\n",
    "                \"table\": table_path,\n",
    "                \"markdown\": table_markdown,\n",
    "                \"page\": page_number,\n",
    "                \"source\": _filePath,\n",
    "                # \"id\": table_id,\n",
    "                \"doc_name\": _file_name,\n",
    "            },\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    hypo_docs = []\n",
    "\n",
    "    hypothetical_questions = extract_tag_content(\n",
    "        table_summary, \"hypothetical_questions\"\n",
    "    )\n",
    "    if hypothetical_questions != None:\n",
    "        hypo_docs.append(\n",
    "            create_document(\n",
    "                hypothetical_questions,\n",
    "                {\n",
    "                    \"type\": \"hypothetical_questions\",\n",
    "                    \"table\": table_path,\n",
    "                    \"summary\": table_summary_clean,\n",
    "                    \"markdown\": table_markdown,\n",
    "                    \"page\": page_number,\n",
    "                    \"source\": _filePath,\n",
    "                    # \"id\": table_id,\n",
    "                    \"doc_name\": _file_name,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return markdown, docs, hypo_docs\n",
    "\n",
    "\n",
    "def process_text_element(page):\n",
    "    \"\"\"\n",
    "    텍스트 요소를 처리합니다.\n",
    "\n",
    "    Args:\n",
    "        element (dict): 텍스트 요소 정보\n",
    "\n",
    "    Returns:\n",
    "        str: 텍스트 내용\n",
    "    \"\"\"\n",
    "    return page\n",
    "\n",
    "\n",
    "def process_page(page, page_number, summarylist, image_cropped_list, table_cropped_list, image_summary_data_list, table_summary_data_list, text_splitter):\n",
    "    \"\"\"\n",
    "    페이지를 처리합니다.\n",
    "\n",
    "    Args:\n",
    "        page (dict): 페이지 정보\n",
    "        state (dict): 현재 상태\n",
    "        page_number (str): 페이지 번호\n",
    "        text_splitter (RecursiveCharacterTextSplitter): 텍스트 분할기\n",
    "\n",
    "    Returns:\n",
    "        tuple: 마크다운 문자열 리스트와 문서 객체 리스트\n",
    "    \"\"\"\n",
    "    markdowns = []\n",
    "    docs = []\n",
    "    hypo_docs = []\n",
    "    page_texts = []\n",
    "\n",
    "    imageinfo_page_items = [imageinfo for imageinfo in image_cropped_list if imageinfo[\"page_number\"] == page_number]\n",
    "    for imageitem in imageinfo_page_items:\n",
    "        markdown, element_docs, hypo_doc = process_image_element(\n",
    "            imageitem, image_summary_data_list, page_number\n",
    "        )\n",
    "        markdowns.append(markdown)\n",
    "        docs.extend(element_docs)\n",
    "        hypo_docs.extend(hypo_doc)\n",
    "\n",
    "    tableinfo_page_items = [tableinfo for tableinfo in table_cropped_list if tableinfo[\"page_number\"] == page_number]\n",
    "    for tableitem in tableinfo_page_items:\n",
    "        markdown, element_docs, hypo_doc = process_table_element(\n",
    "            tableitem, table_summary_data_list, page_number\n",
    "        )\n",
    "        markdowns.append(markdown)\n",
    "        docs.extend(element_docs)\n",
    "        hypo_docs.extend(hypo_doc)\n",
    "\n",
    "    text = process_text_element(page)\n",
    "    markdowns.append(text)\n",
    "    page_texts.append(text)\n",
    "\n",
    "    page_text = \"\\n\".join(page_texts)\n",
    "    split_texts = text_splitter.split_text(page_text)\n",
    "\n",
    "    text_summary = summarylist[page_number]\n",
    "    docs.append(\n",
    "        create_document(\n",
    "            text_summary,\n",
    "            metadata={\n",
    "                \"type\": \"page_summary\",\n",
    "                \"page\": page_number,\n",
    "                \"source\": _filePath,\n",
    "                \"text\": page_text,\n",
    "                \"doc_name\": _file_name,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for text in split_texts:\n",
    "        docs.append(\n",
    "            create_document(\n",
    "                text.page_content,\n",
    "                metadata={\n",
    "                    \"type\": \"text\",\n",
    "                    \"page\": page_number,\n",
    "                    \"source\": _filePath,\n",
    "                    \"summary\": text_summary,\n",
    "                    \"doc_name\": _file_name,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return markdowns, docs, hypo_docs\n",
    "\n",
    "\n",
    "def process_document(pageContentList, pageSummaryList, imageCroppedList, tableCroppedList, imageSummaryList, tableSummaryList):\n",
    "    \"\"\"\n",
    "    전체 문서를 처리합니다.\n",
    "\n",
    "    Args:\n",
    "        state (dict): 현재 상태\n",
    "\n",
    "    Returns:\n",
    "        tuple: 마크다운 문자열 리스트와 문서 객체 리스트\n",
    "    \"\"\"\n",
    "    markdowns = []\n",
    "    docs = []\n",
    "    hypo_docs = []\n",
    "    # text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    markdown_splitter = markdown_header_text_splitter()\n",
    "\n",
    "    for page_number, page in pageContentList.items():\n",
    "        # print(f\"{page_number, page}\")\n",
    "        page_markdowns, page_docs, page_hypo_docs = process_page(\n",
    "            page, \n",
    "            page_number, \n",
    "            pageSummaryList, \n",
    "            imageCroppedList, \n",
    "            tableCroppedList, \n",
    "            imageSummaryList, \n",
    "            tableSummaryList, \n",
    "            markdown_splitter,\n",
    "        )\n",
    "        markdowns.extend(page_markdowns)\n",
    "        docs.extend(page_docs)\n",
    "        hypo_docs.extend(page_hypo_docs)\n",
    "\n",
    "    return markdowns, docs, hypo_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdowns, docs, hypo_docs = process_document(\n",
    "    page_content_list, \n",
    "    summary_list,\n",
    "    image_cropped_list,\n",
    "    table_cropped_list,\n",
    "    image_summary_data_list,\n",
    "    table_summary_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown 파일로 텍스트 저장\n",
    "with open(_filePath.replace(\".pdf\", \".md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(markdowns))\n",
    "\n",
    "print(f\"텍스트가 '{_filePath.replace('.pdf', '.md')}' 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hypo_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hypo_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "벡터 DB에 저장할 문서 범위 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = docs + hypo_docs\n",
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 데이터가 string 타입이 아닐 경우 azure ai search에 저장 시 타입 오류가 발생\n",
    "for doc in all_docs:\n",
    "    # 모든 메타데이터 필드를 문자열로 변환\n",
    "    for key, value in doc.metadata.items():\n",
    "        if not isinstance(value, str):\n",
    "            doc.metadata[key] = str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(all_docs):\n",
    "    print(i, d.metadata[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_docs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_docs[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_docs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_docs[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch # AzureSearch 벡터 저장소 클래스를 임포트합니다.\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ScoringProfile,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    TextWeights\n",
    ") # Azure Search 인덱스 모델 클래스를 임포트합니다.\n",
    "\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME'), # 사용할 Azure 배포 모델을 설정합니다.\n",
    "    openai_api_version=os.getenv('AZURE_OPENAI_ADA_DEPLOYMENT_VERSION'), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint =os.getenv('AZURE_OPENAI_ENDPOINT') # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    ")  # OpenAI 임베딩을 사용합니다.\n",
    "\n",
    "embedding_function = embedding.embed_query # 임베딩 함수 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "azure ai search 인덱스 필드 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    # 문서의 고유 ID 필드 정의\n",
    "    SimpleField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "    ),\n",
    "    # 검색 가능한 콘텐츠 필드 정의\n",
    "    SearchableField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        analyzer_name='ko.microsoft',\n",
    "        #search_analyzer_name='ko.microsoft',\n",
    "    ),\n",
    "    # 콘텐츠 벡터 필드 정의\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")), # 임베딩 벡터의 차원 수 설정\n",
    "        vector_search_profile_name=\"myHnswProfile\", # 벡터 검색 프로파일 이름 설정\n",
    "    ),\n",
    "    # 메타데이터 필드 정의\n",
    "    SearchableField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        analyzer_name='ko.microsoft',\n",
    "    ),\n",
    "    # 메타데이터 벡터 필드 정의\n",
    "    SearchField(\n",
    "        name=\"metadata_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(embedding_function(\"Text\")), # 임베딩 벡터의 차원 수 설정\n",
    "        vector_search_profile_name=\"myHnswProfile\", # 벡터 검색 프로파일 이름 설정\n",
    "    ),\n",
    "    # 파일명을 저장하기 위한 필드\n",
    "    SearchableField(\n",
    "        name=\"doc_name\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        filterable=True,        \n",
    "        analyzer_name='ko.microsoft',\n",
    "    ),\n",
    "    # 파일 경로를 저장하기 위한 필드\n",
    "    SearchableField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        analyzer_name='ko.microsoft',\n",
    "    ),\n",
    "    # 이미지 경로를 저장하기 위한 필드\n",
    "    SearchableField(\n",
    "        name=\"image\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        analyzer_name='ko.microsoft',\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "azure ai search 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AzureSearch 객체를 생성하여 다중 모달 벡터 저장소를 초기화합니다.\n",
    "vector_store_multi_modal: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv('AZURE_SEARCH_ENDPOINT'), # Azure Search 엔드포인트 설정\n",
    "    azure_search_key=os.getenv('AZURE_SEARCH_API_KEY'), # Azure Search 키 설정\n",
    "    index_name=_index_name, # 인덱스 이름 설정\n",
    "    embedding_function=embedding_function, # 임베딩 함수 설정\n",
    "    semantic_configuration_name='default',\n",
    "    fields=fields, # 인덱스 필드 설정\n",
    "    # **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "azure ai search 인덱스에 문서 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_multi_modal.add_documents(documents=all_docs) # 문서 리스트를 Azure Search 인덱스에 추가합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriever 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "# bm25 retriever와 faiss retriever를 초기화합니다.\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    all_docs,\n",
    ")\n",
    "bm25_retriever.k = 5  # BM25Retriever의 검색 결과 개수를 1로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ai search retriever 생성\n",
    "# vector_retriever = vector_store_multi_modal.as_retriever(search_kwargs={\"k\": 5})\n",
    "vector_retriever = vector_store_multi_modal.as_retriever(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 retriever를 초기화합니다.\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.7, 0.3],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevance Checker 로직을 활용한 중요 정보 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 데이터 모델\n",
    "class GradeRetrievalQuestion(BaseModel):\n",
    "    \"\"\"A binary score to determine the relevance of the retrieved documents to the question.\"\"\"\n",
    "\n",
    "    score: str = Field(\n",
    "        description=\"Whether the retrieved context is relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# 데이터 모델\n",
    "class GradeRetrievalAnswer(BaseModel):\n",
    "    \"\"\"A binary score to determine the relevance of the retrieved documents to the answer.\"\"\"\n",
    "\n",
    "    score: str = Field(\n",
    "        description=\"Whether the retrieved context is relevant to the answer, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "당신은 {target_variable}와(과) 관련된 검색된 문서의 적합성을 평가하는 평가자입니다. \n",
    "이는 엄격한 검사가 필요하지 않습니다. \n",
    "목표는 잘못된 검색 결과를 걸러내는 것입니다. \n",
    "문서에 {target_variable}와(과) 관련된 키워드나 의미가 포함되어 있다면, 이를 적합한 것으로 평가하세요. \n",
    "문서가 {target_variable}와(과) 관련이 있는지 여부를 나타내기 위해 '예' 또는 '아니오'로 이진 점수를 부여하세요.\n",
    "\"\"\"\n",
    "def azure_openai_relevance_grader(target=\"retrieval-question\"):\n",
    "    llm = llm_gpt4o_mini()\n",
    "\n",
    "    if target == \"retrieval-question\":\n",
    "        structured_llm_grader = llm.with_structured_output(\n",
    "            GradeRetrievalQuestion\n",
    "        )\n",
    "    elif target == \"retrieval-answer\":\n",
    "        structured_llm_grader = llm.with_structured_output(\n",
    "            GradeRetrievalAnswer\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid target: {target}\")\n",
    "    \n",
    "    # 프롬프트\n",
    "    target_variable = (\n",
    "        \"user question\" if target == \"retrieval-question\" else \"answer\"\n",
    "    )\n",
    "    system = f\"\"\"You are a grader assessing relevance of a retrieved document to a {target_variable}. \\n \n",
    "        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "        If the document contains keyword(s) or semantic meaning related to the {target_variable}, grade it as relevant. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to {target_variable}.\"\"\"\n",
    "\n",
    "    grade_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system),\n",
    "            (\n",
    "                \"human\",\n",
    "                f\"Retrieved document: \\n\\n {{context}} \\n\\n {target_variable}: {{input}}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    grader_prompt = grade_prompt\n",
    "\n",
    "    retrieval_grader_oai = grader_prompt | structured_llm_grader\n",
    "    return retrieval_grader_oai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groundness Checker 생성\n",
    "groundedness_check = azure_openai_relevance_grader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = ensemble_retriever.invoke(\n",
    "    \"K팝 경제를 설명해줘\"\n",
    ")\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_retrieved_documents(retrieved_documents):\n",
    "    clean_docs = []\n",
    "\n",
    "    for doc in retrieved_documents:\n",
    "        metadata = doc.metadata\n",
    "        new_metadata = {}\n",
    "        content = doc.page_content\n",
    "\n",
    "        # 문서 타입이 'page_summary' 또는 'text'인 경우\n",
    "        if metadata[\"type\"] in [\"page_summary\", \"text\"]:\n",
    "            # 페이지 번호와 소스 정보를 새 메타데이터에 추가\n",
    "            if \"page\" in metadata:\n",
    "                new_metadata[\"page\"] = metadata[\"page\"]\n",
    "            if \"source\" in metadata:\n",
    "                new_metadata[\"source\"] = metadata[\"source\"]\n",
    "            # 'text' 타입인 경우 요약 정보도 추가\n",
    "            if metadata[\"type\"] == \"text\":\n",
    "                # content += f'\\n\\n<summary>{metadata[\"summary\"]}</summary>'\n",
    "                new_metadata[\"summary\"] = metadata[\"summary\"]\n",
    "            clean_docs.append(Document(page_content=content, metadata=new_metadata))\n",
    "\n",
    "        # 문서 타입이 'image'인 경우\n",
    "        elif metadata[\"type\"] == \"image\":\n",
    "            image_path = metadata[\"image\"]\n",
    "            # 페이지 번호와 소스 정보를 새 메타데이터에 추가\n",
    "            if \"page\" in metadata:\n",
    "                new_metadata[\"page\"] = metadata[\"page\"]\n",
    "            if \"source\" in metadata:\n",
    "                new_metadata[\"source\"] = metadata[\"source\"]\n",
    "            # 내용을 마크다운 테이블 형식으로 변환\n",
    "            # content = content\n",
    "            content = convert_to_markdown_table(content)\n",
    "\n",
    "            clean_docs.append(Document(page_content=content, metadata=new_metadata))\n",
    "\n",
    "        # 문서 타입이 'table'인 경우\n",
    "        elif metadata[\"type\"] == \"table\":\n",
    "            table_path = metadata[\"table\"]\n",
    "            table_markdown = metadata[\"markdown\"]\n",
    "            # 페이지 번호와 소스 정보를 새 메타데이터에 추가\n",
    "            if \"page\" in metadata:\n",
    "                new_metadata[\"page\"] = metadata[\"page\"]\n",
    "            if \"source\" in metadata:\n",
    "                new_metadata[\"source\"] = metadata[\"source\"]\n",
    "            # 내용을 마크다운 테이블 형식으로 변환하고 원본 마크다운과 결합\n",
    "            # content = f\"{content}\\n\\n{table_markdown}\"\n",
    "            content = f\"{convert_to_markdown_table(content)}\\n\\n{table_markdown}\"\n",
    "\n",
    "            clean_docs.append(Document(page_content=content, metadata=new_metadata))\n",
    "\n",
    "        # 문서 타입이 'hypothetical_questions'인 경우\n",
    "        elif metadata[\"type\"] == \"hypothetical_questions\":\n",
    "            # 내용을 요약 정보로 대체\n",
    "            content = metadata[\"summary\"]\n",
    "            # 페이지 번호와 소스 정보를 새 메타데이터에 추가\n",
    "            if \"page\" in metadata:\n",
    "                new_metadata[\"page\"] = metadata[\"page\"]\n",
    "            if \"source\" in metadata:\n",
    "                new_metadata[\"source\"] = metadata[\"source\"]\n",
    "            clean_docs.append(Document(page_content=content, metadata=new_metadata))\n",
    "\n",
    "    return clean_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 사용 예시\n",
    "# 앙상블 리트리버를 사용하여 질문에 대한 문서 검색\n",
    "retrieved_documents = ensemble_retriever.invoke(\n",
    "    \"K팝 경제를 설명해줘\"\n",
    ")\n",
    "# 검색된 문서를 정제하여 깨끗한 형태로 변환\n",
    "cleaned_documents = clean_retrieved_documents(retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in cleaned_documents:\n",
    "    print(doc.page_content)\n",
    "    print(\"---\" * 30)\n",
    "    print(doc.metadata)\n",
    "    print(\"===\" * 30, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_check(question, use_checker=True):\n",
    "    # 질문에 대한 문서를 검색합니다.\n",
    "    retrieved_documents = ensemble_retriever.invoke(question)\n",
    "\n",
    "    # 검색된 문서를 정제합니다.\n",
    "    cleaned_documents = clean_retrieved_documents(retrieved_documents)\n",
    "\n",
    "    filtered_documents = []\n",
    "    if use_checker:\n",
    "        # 검사기를 사용하는 경우, 각 문서의 내용과 질문을 입력으로 준비합니다.\n",
    "        checking_inputs = [\n",
    "            {\"context\": doc.page_content, \"input\": question}\n",
    "            for doc in cleaned_documents\n",
    "        ]\n",
    "\n",
    "        # 준비된 입력을 사용하여 일괄 검사를 수행합니다.\n",
    "        checked_results = groundedness_check.batch(checking_inputs)\n",
    "\n",
    "        # 검사 결과가 'yes'인 문서만 필터링합니다.\n",
    "        filtered_documents = [\n",
    "            doc\n",
    "            for doc, result in zip(cleaned_documents, checked_results)\n",
    "            if result.score == \"yes\"\n",
    "        ]\n",
    "    else:\n",
    "        # 검사기를 사용하지 않는 경우, 모든 정제된 문서를 그대로 사용합니다.\n",
    "        filtered_documents = cleaned_documents\n",
    "\n",
    "    # 필터링된 문서를 반환합니다.\n",
    "    return filtered_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_and_check(\"K팝 경제를 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "\n",
    "\"\"\"\n",
    "당신은 질문에 답하는 작업을 지원하는 도우미입니다.\n",
    "다음 제공된 검색된 컨텍스트를 사용하여 질문에 답하세요.\n",
    "답을 모를 경우, \"모르겠습니다\"라고 답하세요.\n",
    "답변은 한국어로 작성해야 합니다.\n",
    "\n",
    "지침:\n",
    "1. 질문의 의도를 이해하고 가장 적절한 답변을 제공하세요.\n",
    "2. 질문의 맥락과 질문자가 왜 이를 물었는지 스스로에게 물어보고, 이를 기반으로 적절한 답변을 작성하세요.\n",
    "3. 검색된 컨텍스트 중에서 질문과 직접적으로 관련된 가장 중요한 내용을 선택하여 답변을 작성하세요.\n",
    "4. 간결하고 논리적인 답변을 만드세요. 답변을 작성할 때, 단순히 선택된 내용을 나열하지 말고, 문맥에 맞게 자연스럽게 문단으로 재구성하세요.\n",
    "5. 질문에 대한 컨텍스트를 검색하지 않았거나, 검색된 문서의 내용이 질문과 관련이 없을 경우, \"제가 가진 자료에서는 해당 질문에 대한 답을 찾을 수 없습니다.\"라고 답하세요.\n",
    "6. 답변은 주요 내용을 요약한 표 형식으로 작성하세요.\n",
    "7. 답변에는 모든 출처와 페이지 번호를 포함해야 합니다.\n",
    "8. 답변은 최대한 상세하게 작성해야 합니다.\n",
    "9. 답변은 \"📚 문서에서 검색한 내용기반 답변입니다\"로 시작하고, \"📌 출처\"로 끝내야 합니다.\n",
    "10. 페이지 번호는 정수로 표기해야 합니다.\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "예시 형식:\n",
    "📚 문서에서 검색한 내용기반 답변입니다\n",
    "\n",
    "(답변의 간단한 요약)\n",
    "(질문과 관련된 문맥에 표가 포함되어 있을 경우 표를 포함)\n",
    "(질문과 관련된 문맥에 이미지 설명이 있을 경우 설명 포함)\n",
    "(질문에 대한 상세한 답변)\n",
    "\n",
    "📌 출처\n",
    "[여기에 파일명(.pdf만 허용)과 페이지 번호를 작성합니다.]\n",
    "\n",
    "파일명.pdf, 192쪽\n",
    "파일명.pdf, 192쪽\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "# Direction:\n",
    "Make sure you understand the intent of the question and provide the most appropriate answer.\n",
    "1. Ask yourself the context of the question and why the questioner asked it, think about the question, and provide an appropriate answer based on your understanding.\n",
    "2. Select the most relevant content (the key content that directly relates to the question) from the context in which it was retrieved to write your answer.\n",
    "3. Create a concise and logical answer. When creating your answer, don't just list your selections, but rearrange them to fit the context so they flow naturally into paragraphs.\n",
    "4. If you haven't searched for context for the question, or if you've searched for a document but its content isn't relevant to the question, you should say ‘I can't find an answer to that question in the materials I have’.\n",
    "5. Write your answer in a table of key points.\n",
    "6. Your answer must include all sources and page numbers.\n",
    "7. Your answer must be written in Korean.\n",
    "8. Be as detailed as possible in your answer.\n",
    "9. Begin your answer with ‘This answer is based on content found in the document **📚’ and end with ‘**📌 source**’.\n",
    "10. Page numbers should be whole numbers.\n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "###\n",
    "\n",
    "#Example Format:\n",
    "**📚 문서에서 검색한 내용기반 답변입니다**\n",
    "\n",
    "(brief summary of the answer)\n",
    "(include table if there is a table in the context related to the question)\n",
    "(include image explanation if there is a image in the context related to the question)\n",
    "(detailed answer to the question)\n",
    "\n",
    "**📌 출처**\n",
    "[here you only write filename(.pdf only), page]\n",
    "\n",
    "- 파일명.pdf, 192쪽\n",
    "- 파일명.pdf, 192쪽\n",
    "- ...\n",
    "\n",
    "###\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = llm_gpt4o()\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": RunnableLambda(retrieve_and_check), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke(\"K팝 경제를 설명해줘\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
