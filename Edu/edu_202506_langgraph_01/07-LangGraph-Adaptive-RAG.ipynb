{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {},
   "source": [
    "# Adaptive RAG\n",
    "\n",
    "이 튜토리얼은 Adaptive RAG(Adaptive Retrieval-Augmented Generation)의 구현을 다룹니다. \n",
    "\n",
    "Adaptive RAG는 쿼리 분석과 능동적/자기 수정 RAG를 결합하여 다양한 데이터 소스에서 정보를 검색하고 생성하는 전략입니다. \n",
    "\n",
    "이 튜토리얼에서는 LangGraph를 사용하여 웹 검색과 자기 수정 RAG 간의 라우팅을 구현합니다.\n",
    "\n",
    "**주로 다루는 내용**\n",
    "\n",
    "- **Create Index**: 인덱스 생성 및 문서 로드\n",
    "- **LLMs**: LLM을 사용한 쿼리 라우팅 및 문서 평가\n",
    "- **Web Search Tool**: 웹 검색 도구 설정\n",
    "- **Construct the Graph**: 그래프 상태 및 흐름 정의\n",
    "- **Compile Graph**: 그래프 컴파일 및 워크플로우 구축\n",
    "- **Use Graph**: 그래프 실행 및 결과 확인\n",
    "\n",
    "----\n",
    "\n",
    "**Adaptive RAG**는 **RAG**의 전략으로, (1) [쿼리 분석](https://blog.langchain.dev/query-construction/)과 (2) [Self-Reflective RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)을 결합합니다.\n",
    "\n",
    "[논문: Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](https://arxiv.org/abs/2403.14403) 에서는 쿼리 분석을 통해 다음과 같은 라우팅을 수행합니다.\n",
    "\n",
    "- `No Retrieval`\n",
    "- `Single-shot RAG`\n",
    "- `Iterative RAG`\n",
    "\n",
    "LangGraph를 사용하여 이를 구현합니다.\n",
    "\n",
    "이 구현에서는 다음과 같은 라우팅을 수행합니다.\n",
    "\n",
    "- **웹 검색**: 최신 이벤트와 관련된 질문에 사용\n",
    "- **자기 수정 RAG**: 인덱스와 관련된 질문에 사용\n",
    "\n",
    "![adaptive-rag.png](./assets/langgraph-adaptive-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ec196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9065ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "# from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "# logging.langsmith(\"CH17-LangGraph-Structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c3f4",
   "metadata": {},
   "source": [
    "## 기본 PDF 기반 Retrieval Chain 생성\n",
    "\n",
    "여기서는 PDF 문서를 기반으로 Retrieval Chain 을 생성합니다. 가장 단순한 구조의 Retrieval Chain 입니다.\n",
    "\n",
    "단, LangGraph 에서는 Retirever 와 Chain 을 따로 생성합니다. 그래야 각 노드별로 세부 처리를 할 수 있습니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이전 튜토리얼에서 다룬 내용이므로, 자세한 설명은 생략합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69cb77da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from rag.pdf import PDFRetrievalChain\n",
    "\n",
    "# PDF 문서를 로드합니다.\n",
    "pdf = PDFRetrievalChain([\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"]).create_chain()\n",
    "\n",
    "# retriever 생성\n",
    "pdf_retriever = pdf.retriever\n",
    "\n",
    "# chain 생성\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2fc536",
   "metadata": {},
   "source": [
    "## 쿼리 라우팅과 문서 평가\n",
    "\n",
    "**LLMs** 단계에서는 **쿼리 라우팅**과 **문서 평가**를 수행합니다. 이 과정은 **Adaptive RAG**의 중요한 부분으로, 효율적인 정보 검색과 생성에 기여합니다.\n",
    "\n",
    "- **쿼리 라우팅**: 사용자의 쿼리를 분석하여 적절한 정보 소스로 라우팅합니다. 이를 통해 쿼리의 목적에 맞는 최적의 검색 경로를 설정할 수 있습니다.\n",
    "- **문서 평가**: 검색된 문서의 품질과 관련성을 평가하여 최종 결과의 정확성을 높입니다. 이 과정은 **LLMs**의 성능을 극대화하는 데 필수적입니다.\n",
    "\n",
    "이 단계는 **Adaptive RAG**의 핵심 기능을 지원하며, 정확하고 신뢰할 수 있는 정보 제공을 목표로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b78d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain_teddynote.models import get_model_name, LLMs\n",
    "import os\n",
    "\n",
    "# 최신 LLM 모델 이름 가져오기\n",
    "MODEL_NAME = get_model_name(LLMs.GPT4)\n",
    "\n",
    "\n",
    "# 사용자 쿼리를 가장 관련성 높은 데이터 소스로 라우팅하는 데이터 모델\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    # 데이터 소스 선택을 위한 리터럴 타입 필드\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성 - function calling\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "    model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "    # streaming=False, # 스트리밍\n",
    "    temperature=0,\n",
    "    # max_tokens=4096,\n",
    ")\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# 당신은 사용자 질문을 벡터스토어 또는 웹 검색으로 적절하게 라우팅하는 전문가입니다.\n",
    "# 벡터스토어는 Samsung Gause, Anthropic 등을 포함한 “DEC 2023 AI Brief Report (SPRI)” 관련 문서를 보유하고 있습니다.\n",
    "# 이 주제에 대한 질문에는 벡터스토어를 사용하세요. 그렇지 않은 경우에는 웹 검색을 활용하세요.\n",
    "\n",
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to DEC 2023 AI Brief Report(SPRI) with Samsung Gause, Anthropic, etc.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "\n",
    "# Routing 을 위한 프롬프트 템플릿 생성\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 라우터를 결합하여 질문 라우터 생성\n",
    "question_router = route_prompt | structured_llm_router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4d831",
   "metadata": {},
   "source": [
    "다음은 쿼리 라우팅 결과를 테스트 해본 뒤 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0874c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "# 문서 검색이 필요한 질문\n",
    "print(\n",
    "    question_router.invoke(\n",
    "        {\"question\": \"AI Brief 에서 삼성전자가 만든 생성형 AI 의 이름은?\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2d22b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='web_search'\n"
     ]
    }
   ],
   "source": [
    "# 웹 검색이 필요한 질문\n",
    "print(question_router.invoke({\"question\": \"역삼역에서 가장 맛있는 순대국집 찾아줘\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc43b99",
   "metadata": {},
   "source": [
    "### 검색 평가기(Retrieval Grader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1221d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# 문서 평가를 위한 데이터 모델 정의\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM 초기화 및 함수 호출을 통한 구조화된 출력 생성\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "    model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "    # streaming=False, # 스트리밍\n",
    "    temperature=0,\n",
    "    # max_tokens=4096,\n",
    ")\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "\n",
    "# 당신은 검색된 문서가 사용자 질문과 얼마나 관련이 있는지 평가하는 채점자입니다.\n",
    "# 만약 문서에 사용자 질문과 관련된 키워드나 의미가 포함되어 있다면, 해당 문서를 관련 있음으로 평가하세요.\n",
    "# 너무 엄격할 필요는 없습니다. 목적은 잘못된 검색 결과만 걸러내는 것입니다.\n",
    "# 문서가 질문과 관련이 있다고 판단되면 'yes', 아니면 'no'로 이진 점수를 부여하세요.\n",
    "\n",
    "\n",
    "# 시스템 메시지와 사용자 질문을 포함한 프롬프트 템플릿 생성\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 검색결과 평가기 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927cac10",
   "metadata": {},
   "source": [
    "생성한 `retrieval_grader` 를 사용하여 문서 검색결과를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa5e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 질문 설정\n",
    "question = \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    "\n",
    "# 질문에 대한 관련 문서 검색\n",
    "docs = pdf_retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4943e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\\n▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\\n▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 18, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='<구글 딥마인드의 범용 AI 분류 프레임워크>\\n성능 특수 AI 예시 범용 AI 예시\\n0단계: AI 아님 계산기 소프트웨어, 컴파일러 아마존 메커니컬 터크\\n1단계: 신진(숙련되지 않은 인간) GOFAI(Good Old Fashioned Artificial Intelligence) 챗GPT, 바드, 라마2\\n스마트 스피커(애플 시리, 아마존 알렉사, 구글\\n2단계: 유능(숙련된 인간의 50% 이상) 미달성\\n어시스턴트), IBM 왓슨\\n3단계: 전문가(숙련된 인간의 90% 이상) 문법 교정기(그래머리), 생성 이미지 모델(달리2) 미달성'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 11, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='제작을 포함\\nn 알리바바 클라우드는 급증하는 생성 AI 수요에 대응해 모델 개발과 애플리케이션 구축 절차를\\n간소화하는 올인원 AI 모델 구축 플랫폼 ‘젠AI(GenAI)’도 공개\\n∙ 이 플랫폼은 데이터 관리, 모델 배포와 평가, 신속한 엔지니어링을 위한 종합 도구 모음을 제공하여\\n다양한 기업들이 맞춤형 AI 모델을 한층 쉽게 개발할 수 있도록 지원\\n∙ 생성 AI 개발에 필요한 컴퓨팅과 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼(PAI),\\n데이터베이스 솔루션, 컨테이너 서비스와 같은 클라우드 신제품도 발표'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\\n이미지 모델의 3개 모델로 구성\\n∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\\n처리를 지원'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\\n▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\\n3. 기술/연구\\n▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································15'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 6, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='제출하지 않았다는 점을 지적했으며, 사라 앤더슨은 고소장에 인용된 수백 개의 작품 중 16개 작품에\\n대해서만 저작권을 보유\\nn 판결문은 또한 생성 AI 모델 훈련에 사용된 모든 이미지에 저작권이 있다거나, 생성 AI로 만든\\n이미지가 저작물을 이용해 훈련되었으므로 저작물의 파생 이미지라는 주장은 개연성이 부족하다고\\n지적\\n∙ AI는 새로운 이미지를 생성할 때 다양한 예술가의 작품을 참조하므로, 생성된 이미지와 저작권을 가진\\n특정 작품과의 실질적 유사성을 입증할 수 없다면 저작권 침해를 인정받기 어려움')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13393f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n",
      "binary_score='yes'\n",
      "binary_score='yes'\n",
      "binary_score='no'\n",
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(\n",
    "        retrieval_grader.invoke({\"document\": doc.page_content, \"question\": question})\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef397b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "# 검색된 문서의 내용 가져오기\n",
    "retrieved_doc = docs[1].page_content\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": retrieved_doc}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dce41bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링 하는 코드 예시\n",
    "filtered_docs = []\n",
    "for doc in docs:\n",
    "    result = retrieval_grader.invoke(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"document\": doc.page_content,\n",
    "        }\n",
    "    )\n",
    "    if result.binary_score == \"yes\":\n",
    "        filtered_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd56830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 1, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\\n▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\\n▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='SPRi AI Brief |\\n2023-12월호\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nKEY Contents\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\n£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\\n‘삼성 가우스’를 최초 공개\\n∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\\n최적화된 크기의 모델 선택이 가능\\n∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\\n10'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='처리를 지원\\n∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\\n사내 소프트웨어 개발에 최적화\\n∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\\n저해상도 이미지의 고해상도 전환도 지원\\nn IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\\n2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글'),\n",
       " Document(metadata={'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'page': 12, 'total_pages': 23, 'Author': 'dj', 'Creator': 'Hwp 2018 10.0.0.13462', 'Producer': 'Hancom PDF 1.3.0.542', 'CreationDate': \"D:20231208132838+09'00'\", 'ModDate': \"D:20231208132838+09'00'\", 'PDFVersion': '1.4'}, page_content='온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\\n이미지 모델의 3개 모델로 구성\\n∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\\n처리를 지원')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dce7a1",
   "metadata": {},
   "source": [
    "### 답변 생성을 위한 RAG 체인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "992ef15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhkim\\AppData\\Local\\miniconda3\\envs\\azure_analy\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain Hub에서 프롬프트 가져오기(RAG 프롬프트는 자유롭게 수정 가능)\n",
    "prompt = hub.pull(\"teddynote/rag-prompt\")\n",
    "\n",
    "# LLM 초기화\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "    model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "    # streaming=False, # 스트리밍\n",
    "    temperature=0,\n",
    "    # max_tokens=4096,\n",
    ")\n",
    "\n",
    "# RAG 체인 생성\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc96e3",
   "metadata": {},
   "source": [
    "이제 생성한 `rag_chain` 에 질문을 전달하여 답변을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8d16e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자가 만든 생성형 AI의 이름은 ‘삼성 가우스’이다.\n",
      "\n",
      "**Source**  \n",
      "- data/SPRI_AI_Brief_2023년12월호_F.pdf (p.13)\n"
     ]
    }
   ],
   "source": [
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# RAG 체인에 질문을 전달하여 답변 생성\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9f601",
   "metadata": {},
   "source": [
    "### 답변의 Hallucination 체커 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ec0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할루시네이션 체크를 위한 데이터 모델 정의\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "    model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "    # streaming=False, # 스트리밍\n",
    "    temperature=0,\n",
    "    # max_tokens=4096,\n",
    ")\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "\n",
    "# 당신은 LLM이 생성한 답변이 검색된 사실 집합에 근거하거나 지원되는지 평가하는 채점자입니다.\n",
    "# 이진 점수 'yes' 또는 'no'로 평가하세요.  \n",
    "# 'yes'는 답변이 해당 사실 집합에 근거하거나 지원된다는 의미입니다.\n",
    "\n",
    "\n",
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 환각 평가기 생성\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550b7cf",
   "metadata": {},
   "source": [
    "생성한 `hallucination_grader` 를 사용하여 생성된 답변의 환각 여부를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb593684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가기를 사용하여 생성된 답변의 환각 여부 평가\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110eb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 대한 답변의 적절성을 평가하기 위한 이진 점수화\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary scoring to evaluate the appropriateness of answers to questions\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Indicate 'yes' or 'no' whether the answer solves the question\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 함수 호출을 통한 LLM 초기화\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "    model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "    # streaming=False, # 스트리밍\n",
    "    temperature=0,\n",
    "    # max_tokens=4096,\n",
    ")\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "\n",
    "# 당신은 답변이 질문을 해결하거나 답하고 있는지 평가하는 채점자입니다.\n",
    "# 이진 점수 'yes' 또는 'no'로 평가하세요.  \n",
    "# 'yes'는 답변이 질문을 해결한다는 의미입니다.\n",
    "\n",
    "\n",
    "# 프롬프트 설정\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿과 구조화된 LLM 평가기를 결합하여 답변 평가기 생성\n",
    "answer_grader = answer_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66a26ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가기를 사용하여 생성된 답변이 질문을 해결하는지 여부 평가\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc11dd",
   "metadata": {},
   "source": [
    "### 쿼리 재작성(Query Rewriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9df325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM 초기화\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"), # Azure OpenAI API 키를 환경 변수에서 가져옵니다.\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"), # OpenAI API 버전을 설정합니다.\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), # Azure OpenAI 엔드포인트를 환경 변수에서 가져옵니다.\n",
    "    model= os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_GPT41_MINI\"), # 사용할 모델을 설정합니다.\n",
    "    # streaming=False, # 스트리밍\n",
    "    temperature=0,\n",
    "    # max_tokens=4096,\n",
    ")\n",
    "\n",
    "\n",
    "# 당신은 입력된 질문을 벡터스토어 검색에 최적화된 더 나은 버전으로 변환하는 질문 재작성자입니다.  \n",
    "# 입력을 보고 그 근본적인 의미나 의도를 추론해 보세요.\n",
    "\n",
    "\n",
    "# Query Rewriter 프롬프트 정의(자유롭게 수정이 가능합니다)\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "\n",
    "# Query Rewriter 프롬프트 템플릿 생성\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Query Rewriter 생성\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd3e83",
   "metadata": {},
   "source": [
    "생성한 `question_rewriter` 에 질문을 전달하여 개선된 질문을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6eb92e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'삼성전자가 개발한 생성형 인공지능(AI)의 공식 명칭은 무엇인가요?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문 재작성기에 질문을 전달하여 개선된 질문 생성\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5ee42",
   "metadata": {},
   "source": [
    "### 웹 검색 도구\n",
    "\n",
    "**웹 검색 도구**는 **Adaptive RAG**의 중요한 구성 요소로, 최신 정보를 검색하는 데 사용됩니다. 이 도구는 사용자가 최신 이벤트와 관련된 질문에 대해 신속하고 정확한 답변을 얻을 수 있도록 지원합니다.\n",
    "\n",
    "- **설정**: 웹 검색 도구를 설정하여 최신 정보를 검색할 수 있도록 준비합니다.\n",
    "- **검색 수행**: 사용자의 쿼리를 기반으로 웹에서 관련 정보를 검색합니다.\n",
    "- **결과 분석**: 검색된 결과를 분석하여 사용자의 질문에 가장 적합한 정보를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e004263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 웹 검색 도구 생성\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d60abe",
   "metadata": {},
   "source": [
    "웹 검색 도구를 실행하여 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c13be8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.youtube.com/watch?v=mVu6Wj8Z7C0', 'title': '랭체인 한국어 튜토리얼 업데이트 소식 처음 사용자를 위한 친절한 ...', 'content': '#랭체인 한국어 튜토리얼🇰🇷 업데이트 소식🔥 처음 사용자를 위한 친절한 환경설치(Windows, Mac)\\n\\n테디노트 TeddyNote\\n317 likes\\n16451 views\\n19 Jun 2024\\n📝 환경설정(Windows)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Windows)/\\n\\n📝 환경설정(Mac)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Mac)/\\n\\n📍[패스트캠퍼스] \"테디노트의 RAG 비법노트\" 강의\\n링크: https://bit.ly/4e1h8zO\\n\\n🤖 디스코드 채널\\nhttps://discord.gg/q3RvQZ5CfK\\n\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\nhttps://wikidocs.net/book/14314\\n\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\nhttps://github.com/teddylee777/langchain-kr\\n\\n✅ 줄거리\\n00:00 랭체인 한국어 튜토리얼 공지사항\\n01:59 langchain-teddynote 패키지\\n08:25 감사인사\\n09:15 Windows 환경설치\\n21:48 Mac 환경설치\\n\\n#rag #langchain\\n---\\n📍 \"테디노트의 RAG 비법노트\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\\n77 comments', 'score': 0.76888984, 'raw_content': '# #랭체인 한국어 튜토리얼🇰🇷 업데이트 소식🔥 처음 사용자를 위한 친절한 환경설치(Windows, Mac)\\n\\n테디노트 TeddyNote\\n317 likes\\n16451 views\\n19 Jun 2024\\n📝 환경설정(Windows)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Windows)/\\n\\n📝 환경설정(Mac)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Mac)/\\n\\n📍[패스트캠퍼스] \"테디노트의 RAG 비법노트\" 강의\\n링크: https://bit.ly/4e1h8zO\\n\\n🤖 디스코드 채널\\nhttps://discord.gg/q3RvQZ5CfK\\n\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\nhttps://wikidocs.net/book/14314\\n\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\nhttps://github.com/teddylee777/langchain-kr\\n\\n✅ 줄거리\\n00:00 랭체인 한국어 튜토리얼 공지사항\\n01:59 langchain-teddynote 패키지\\n08:25 감사인사\\n09:15 Windows 환경설치\\n21:48 Mac 환경설치\\n\\n#rag #langchain\\n---\\n📍 \"테디노트의 RAG 비법노트\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\\n77 comments'}, {'url': 'https://wikidocs.net/book/14314', 'title': '<랭체인LangChain 노트> - LangChain 한국어 튜토리얼 - 위키독스', 'content': '추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \"추천\" 한 번씩만 부탁 드리겠습니다 . ✓ 랭체인 한국어 튜토리얼 강의', 'score': 0.4075462, 'raw_content': None}, {'url': 'https://wikidocs.net/267814', 'title': '07. Adaptive RAG - <랭체인LangChain 노트> - 위키독스', 'content': 'Adaptive RAG는 쿼리 분석과 능동적/자기 수정 RAG를 결합하여 다양한 데이터 소스에서 정보를 검색하고 생성하는 전략입니다. 이 튜토리얼에서는 LangGraph를 사용하여 웹', 'score': 0.2966191, 'raw_content': None}]\n"
     ]
    }
   ],
   "source": [
    "# 웹 검색 도구 호출\n",
    "result = web_search_tool.search(\"테디노트 위키독스 랭체인 튜토리얼 URL 을 알려주세요\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1904c95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.youtube.com/watch?v=mVu6Wj8Z7C0',\n",
       " 'title': '랭체인 한국어 튜토리얼 업데이트 소식 처음 사용자를 위한 친절한 ...',\n",
       " 'content': '#랭체인 한국어 튜토리얼🇰🇷 업데이트 소식🔥 처음 사용자를 위한 친절한 환경설치(Windows, Mac)\\n\\n테디노트 TeddyNote\\n317 likes\\n16451 views\\n19 Jun 2024\\n📝 환경설정(Windows)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Windows)/\\n\\n📝 환경설정(Mac)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Mac)/\\n\\n📍[패스트캠퍼스] \"테디노트의 RAG 비법노트\" 강의\\n링크: https://bit.ly/4e1h8zO\\n\\n🤖 디스코드 채널\\nhttps://discord.gg/q3RvQZ5CfK\\n\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\nhttps://wikidocs.net/book/14314\\n\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\nhttps://github.com/teddylee777/langchain-kr\\n\\n✅ 줄거리\\n00:00 랭체인 한국어 튜토리얼 공지사항\\n01:59 langchain-teddynote 패키지\\n08:25 감사인사\\n09:15 Windows 환경설치\\n21:48 Mac 환경설치\\n\\n#rag #langchain\\n---\\n📍 \"테디노트의 RAG 비법노트\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\\n77 comments',\n",
       " 'score': 0.76888984,\n",
       " 'raw_content': '# #랭체인 한국어 튜토리얼🇰🇷 업데이트 소식🔥 처음 사용자를 위한 친절한 환경설치(Windows, Mac)\\n\\n테디노트 TeddyNote\\n317 likes\\n16451 views\\n19 Jun 2024\\n📝 환경설정(Windows)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Windows)/\\n\\n📝 환경설정(Mac)\\nhttps://teddynote.com/10-RAG%EB%B9%84%EB%B2%95%EB%85%B8%ED%8A%B8/%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95%20(Mac)/\\n\\n📍[패스트캠퍼스] \"테디노트의 RAG 비법노트\" 강의\\n링크: https://bit.ly/4e1h8zO\\n\\n🤖 디스코드 채널\\nhttps://discord.gg/q3RvQZ5CfK\\n\\n📘 랭체인 튜토리얼 무료 전자책(wikidocs)\\nhttps://wikidocs.net/book/14314\\n\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub)\\nhttps://github.com/teddylee777/langchain-kr\\n\\n✅ 줄거리\\n00:00 랭체인 한국어 튜토리얼 공지사항\\n01:59 langchain-teddynote 패키지\\n08:25 감사인사\\n09:15 Windows 환경설치\\n21:48 Mac 환경설치\\n\\n#rag #langchain\\n---\\n📍 \"테디노트의 RAG 비법노트\" 랭체인 강의: https://fastcampus.co.kr/data_online_teddy\\n📘 랭체인 한국어 튜토리얼(무료 전자책): https://wikidocs.net/book/14314\\n📝 테디노트(깃헙 블로그) : https://teddylee777.github.io\\n💻 GitHub 소스코드 저장소: https://github.com/teddylee777\\n77 comments'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 웹 검색 결과의 첫 번째 결과 확인\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac37855",
   "metadata": {},
   "source": [
    "## 그래프 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab91c2",
   "metadata": {},
   "source": [
    "### 그래프 상태 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d23ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "# 그래프의 상태 정의\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    그래프의 상태를 나타내는 데이터 모델\n",
    "\n",
    "    Attributes:\n",
    "        question: 질문\n",
    "        generation: LLM 생성된 답변\n",
    "        documents: 도큐먼트 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    question: Annotated[str, \"User question\"]\n",
    "    generation: Annotated[str, \"LLM generated answer\"]\n",
    "    documents: Annotated[List[str], \"List of documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266cc42",
   "metadata": {},
   "source": [
    "## 그래프 흐름 정의\n",
    "\n",
    "**그래프 흐름**을 정의하여 **Adaptive RAG**의 작동 방식을 명확히 합니다. 이 단계에서는 그래프의 상태와 전환을 설정하여 쿼리 처리의 효율성을 높입니다.\n",
    "\n",
    "- **상태 정의**: 그래프의 각 상태를 명확히 정의하여 쿼리의 진행 상황을 추적합니다.\n",
    "- **전환 설정**: 상태 간의 전환을 설정하여 쿼리가 적절한 경로를 따라 진행되도록 합니다.\n",
    "- **흐름 최적화**: 그래프의 흐름을 최적화하여 정보 검색과 생성의 정확성을 향상시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633bf00c",
   "metadata": {},
   "source": [
    "### 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "# 문서 검색 노드\n",
    "def retrieve(state):\n",
    "    print(\"==== [RETRIEVE] ====\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 문서 검색 수행\n",
    "    documents = pdf_retriever.invoke(question)\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "\n",
    "# 답변 생성 노드\n",
    "def generate(state):\n",
    "    print(\"==== [GENERATE] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG 답변 생성\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def grade_documents(state):\n",
    "    print(\"==== [CHECK DOCUMENT RELEVANCE TO QUESTION] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 각 문서에 대한 관련성 점수 계산\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            # 관련성이 있는 문서 추가\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            # 관련성이 없는 문서는 건너뛰기\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs}\n",
    "\n",
    "\n",
    "# 질문 재작성 노드\n",
    "def transform_query(state):\n",
    "    print(\"==== [TRANSFORM QUERY] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    # documents = state[\"documents\"]\n",
    "\n",
    "    # 질문 재작성\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}\n",
    "\n",
    "\n",
    "# 웹 검색 노드\n",
    "def web_search(state):\n",
    "    print(\"==== [WEB SEARCH] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 웹 검색 수행\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    web_results_docs = [\n",
    "        Document(\n",
    "            page_content=web_result[\"content\"],\n",
    "            metadata={\"source\": web_result[\"url\"]},\n",
    "        )\n",
    "        for web_result in web_results\n",
    "    ]\n",
    "\n",
    "    return {\"documents\": web_results_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec62cc",
   "metadata": {},
   "source": [
    "## 추가 노드 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33976b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 라우팅 노드\n",
    "def route_question(state):\n",
    "    print(\"==== [ROUTE QUESTION] ====\")\n",
    "    # 질문 가져오기\n",
    "    question = state[\"question\"]\n",
    "    # 질문 라우팅\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    # 질문 라우팅 결과에 따른 노드 라우팅\n",
    "    if source.datasource == \"web_search\":\n",
    "        print(\"==== [ROUTE QUESTION TO WEB SEARCH] ====\")\n",
    "        return \"web_search\"\n",
    "    elif source.datasource == \"vectorstore\":\n",
    "        print(\"==== [ROUTE QUESTION TO VECTORSTORE] ====\")\n",
    "        return \"vectorstore\"\n",
    "\n",
    "\n",
    "# 문서 관련성 평가 노드\n",
    "def decide_to_generate(state):\n",
    "    print(\"==== [DECISION TO GENERATE] ====\")\n",
    "    # 문서 검색 결과 가져오기\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # 모든 문서가 관련성 없는 경우 질문 재작성\n",
    "        print(\n",
    "            \"==== [DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY] ====\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # 관련성 있는 문서가 있는 경우 답변 생성\n",
    "        print(\"==== [DECISION: GENERATE] ====\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def hallucination_check(state):\n",
    "    print(\"==== [CHECK HALLUCINATIONS] ====\")\n",
    "    # 질문과 문서 검색 결과 가져오기\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    # 환각 평가\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Hallucination 여부 확인\n",
    "    if grade == \"yes\":\n",
    "        print(\"==== [DECISION: GENERATION IS GROUNDED IN DOCUMENTS] ====\")\n",
    "\n",
    "        # 답변의 관련성(Relevance) 평가\n",
    "        print(\"==== [GRADE GENERATED ANSWER vs QUESTION] ====\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "\n",
    "        # 관련성 평가 결과에 따른 처리\n",
    "        if grade == \"yes\":\n",
    "            print(\"==== [DECISION: GENERATED ANSWER ADDRESSES QUESTION] ====\")\n",
    "            return \"relevant\"\n",
    "        else:\n",
    "            print(\"==== [DECISION: GENERATED ANSWER DOES NOT ADDRESS QUESTION] ====\")\n",
    "            return \"not relevant\"\n",
    "    else:\n",
    "        print(\"==== [DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY] ====\")\n",
    "        return \"hallucination\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412119d",
   "metadata": {},
   "source": [
    "### 그래프 컴파일\n",
    "\n",
    "**그래프 컴파일** 단계에서는 **Adaptive RAG**의 워크플로우를 구축하고 실행 가능한 상태로 만듭니다. 이 과정은 그래프의 각 노드와 엣지를 연결하여 쿼리 처리의 전체 흐름을 정의합니다.\n",
    "\n",
    "- **노드 정의**: 각 노드를 정의하여 그래프의 상태와 전환을 명확히 합니다.\n",
    "- **엣지 설정**: 노드 간의 엣지를 설정하여 쿼리가 적절한 경로를 따라 진행되도록 합니다.\n",
    "- **워크플로우 구축**: 그래프의 전체 흐름을 구축하여 정보 검색과 생성의 효율성을 극대화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 그래프 상태 초기화\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"web_search\", web_search)  # 웹 검색\n",
    "workflow.add_node(\"retrieve\", retrieve)  # 문서 검색\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # 문서 평가\n",
    "workflow.add_node(\"generate\", generate)  # 답변 생성\n",
    "workflow.add_node(\"transform_query\", transform_query)  # 쿼리 변환\n",
    "\n",
    "# 그래프 빌드\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    route_question,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",  # 웹 검색으로 라우팅\n",
    "        \"vectorstore\": \"retrieve\",  # 벡터스토어로 라우팅\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")  # 웹 검색 후 답변 생성\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")  # 문서 검색 후 평가\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",  # 쿼리 변환 필요\n",
    "        \"generate\": \"generate\",  # 답변 생성 가능\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")  # 쿼리 변환 후 문서 검색\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    hallucination_check,\n",
    "    {\n",
    "        \"hallucination\": \"generate\",  # Hallucination 발생 시 재생성\n",
    "        \"relevant\": END,  # 답변의 관련성 여부 통과\n",
    "        \"not relevant\": \"transform_query\",  # 답변의 관련성 여부 통과 실패 시 쿼리 변환\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "app = workflow.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f4505",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2739b",
   "metadata": {},
   "source": [
    "## 그래프 사용\n",
    "\n",
    "**그래프 사용** 단계에서는 **Adaptive RAG**의 실행을 통해 쿼리 처리 결과를 확인합니다. 이 과정은 그래프의 각 노드와 엣지를 따라 쿼리를 처리하여 최종 결과를 생성합니다.\n",
    "\n",
    "- **그래프 실행**: 정의된 그래프를 실행하여 쿼리의 흐름을 따라갑니다.\n",
    "- **결과 확인**: 그래프 실행 후 생성된 결과를 검토하여 쿼리가 적절히 처리되었는지 확인합니다.\n",
    "- **결과 분석**: 생성된 결과를 분석하여 쿼리의 목적에 부합하는지 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# config 설정(재귀 최대 횟수, thread_id)\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"삼성전자가 개발한 생성형 AI 의 이름은?\",\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 입력\n",
    "inputs = {\n",
    "    \"question\": \"2024년 노벨 문학상 수상자는 누구인가요?\",\n",
    "}\n",
    "\n",
    "# 그래프 실행\n",
    "stream_graph(app, inputs, config, [\"agent\", \"rewrite\", \"generate\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-lwwSZlnu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
